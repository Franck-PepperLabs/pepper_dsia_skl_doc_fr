{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [**Tracer la régression logistique multinomiale et un contre tous (OVR)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_1_linear_model/plot_logistic_multinomial.ipynb)<br/>([_Plot multinomial and One-vs-Rest Logistic Regression_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_multinomial.html))\n",
    "\n",
    "Tracé de la surface de décision de la régression logistique multinomiale et un contre tous. Les hyperplans correspondant aux trois classificateurs un contre tous (OvR) sont représentés par les lignes en pointillé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Tom Dupre la Tour <tom.dupre-la-tour@m4x.org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# make 3-class dataset for classification\n",
    "centers = [[-5, 0], [0, 1.5], [5, -1]]\n",
    "X, y = make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
    "transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
    "X = np.dot(X, transformation)\n",
    "\n",
    "for multi_class in (\"multinomial\", \"ovr\"):\n",
    "    clf = LogisticRegression(\n",
    "        solver=\"sag\", max_iter=100, random_state=42, multi_class=multi_class\n",
    "    ).fit(X, y)\n",
    "\n",
    "    # print the training scores\n",
    "    print(\"training score : %.3f (%s)\" % (clf.score(X, y), multi_class))\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        clf, X, response_method=\"predict\", cmap=plt.cm.Paired, ax=ax\n",
    "    )\n",
    "    plt.title(\"Decision surface of LogisticRegression (%s)\" % multi_class)\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    # Plot also the training points\n",
    "    colors = \"bry\"\n",
    "    for i, color in zip(clf.classes_, colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(\n",
    "            X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired, edgecolor=\"black\", s=20\n",
    "        )\n",
    "\n",
    "    # Plot the three one-against-all classifiers\n",
    "    xmin, xmax = plt.xlim()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    coef = clf.coef_\n",
    "    intercept = clf.intercept_\n",
    "\n",
    "    def plot_hyperplane(c, color):\n",
    "        def line(x0):\n",
    "            return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
    "\n",
    "        plt.plot([xmin, xmax], [line(xmin), line(xmax)], ls=\"--\", color=color)\n",
    "\n",
    "    for i, color in zip(clf.classes_, colors):\n",
    "        plot_hyperplane(i, color)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
