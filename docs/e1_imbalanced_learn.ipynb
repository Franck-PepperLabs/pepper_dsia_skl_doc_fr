{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='skl-ext'></a> 1. **Extensions de Scikit-learn**</br>(*Scikit-learn extension*)\n",
    "\n",
    "# E1. [**..**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/e1_imbalanced_learn.ipynb)<br/>([*Imbalanced Learn*](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : . pages, . exemples, . papiers\n",
    "- E1.1 Introduction\n",
    "    - 1.1. API’s of imbalanced-learn samplers\n",
    "    - 1.2. Problem statement regarding imbalanced data sets\n",
    "- E1.2. Over-sampling\n",
    "    - 2.1. A practical guide\n",
    "        - 2.1.1. Naive random over-sampling\n",
    "        - 2.1.2. From random over-sampling to SMOTE and ADASYN\n",
    "        - 2.1.3. Ill-posed examples\n",
    "        - 2.1.4. SMOTE variants\n",
    "    - 2.2. Mathematical formulation\n",
    "        - 2.2.1. Sample generation\n",
    "        - 2.2.2. Multi-class management\n",
    "- E1.3. Under-sampling\n",
    "    - 3.1. Prototype generation\n",
    "    - 3.2. Prototype selection\n",
    "        - 3.2.1. Controlled under-sampling techniques\n",
    "            - 3.2.1.1. Mathematical formulation\n",
    "        - 3.2.2. Cleaning under-sampling techniques\n",
    "            - 3.2.2.1. Tomek’s links\n",
    "            - 3.2.2.2. Edited data set using nearest neighbours\n",
    "            - 3.2.2.3. Condensed nearest neighbors and derived algorithms\n",
    "            - 3.2.2.4. Instance hardness threshold\n",
    "- E1.4. Combination of over- and under-sampling\n",
    "- E1.5. Ensemble of samplers\n",
    "    - 5.1. Classifier including inner balancing samplers\n",
    "        - 5.1.1. Bagging classifier\n",
    "        - 5.1.2. Forest of randomized trees\n",
    "        - 5.1.3. Boosting\n",
    "- E1.6. Miscellaneous samplers\n",
    "    - 6.1. Custom samplers\n",
    "    - 6.2. Custom generators\n",
    "        - 6.2.1. TensorFlow generator\n",
    "        - 6.2.2. Keras generator\n",
    "- E1.7. Metrics\n",
    "    - 7.1. Classification metrics\n",
    "        - 7.1.1. Sensitivity and specificity metrics\n",
    "        - 7.1.2. Additional metrics specific to imbalanced datasets\n",
    "        - 7.1.3. Macro-Averaged Mean Absolute Error (MA-MAE)\n",
    "        - 7.1.4. Summary of important metrics\n",
    "    - 7.2. Pairwise metrics\n",
    "        - 7.2.1. Value Difference Metric\n",
    "- E1.8. Common pitfalls and recommended practices\n",
    "    - 8.1. Data leakage\n",
    "- E1.9. Dataset loading utilities\n",
    "    - 9.1. Imbalanced datasets for benchmark\n",
    "    - 9.2. Imbalanced generator\n",
    "- E1.10. Developer guideline\n",
    "    - 10.1. Developer utilities\n",
    "        - 10.1.1. Validation Tools\n",
    "        - 10.1.2. Deprecation\n",
    "    - 10.2. Making a release\n",
    "        - 10.2.1. Major release\n",
    "        - 10.2.2. Bug fix release\n",
    "- E1.11. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- E1.1 Introduction\n",
    "    - 1.1. API des échantillonneurs imbalanced-learn\n",
    "    - 1.2. Problème lié aux jeux de données déséquilibrés\n",
    "- E1.2. Sur-échantillonnage\n",
    "    - 2.1. Guide pratique\n",
    "        - 2.1.1. Sur-échantillonnage aléatoire naïf\n",
    "        - 2.1.2. Du sur-échantillonnage aléatoire à SMOTE et ADASYN\n",
    "        - 2.1.3. Exemples de problèmes mal posés\n",
    "        - 2.1.4. Variantes de SMOTE\n",
    "    - 2.2. Formulation mathématique\n",
    "        - 2.2.1. Génération d'échantillons\n",
    "        - 2.2.2. Gestion multi-classes\n",
    "- E1.3. Sous-échantillonnage\n",
    "    - 3.1. Génération de prototypes\n",
    "    - 3.2. Sélection de prototypes\n",
    "        - 3.2.1. Techniques de sous-échantillonnage contrôlé\n",
    "            - 3.2.1.1. Formulation mathématique\n",
    "        - 3.2.2. Techniques de sous-échantillonnage de nettoyage\n",
    "            - 3.2.2.1. Liens de Tomek\n",
    "            - 3.2.2.2. Jeu de données édité en utilisant les voisins les plus proches\n",
    "            - 3.2.2.3. Voisins les plus proches condensés et algorithmes dérivés\n",
    "            - 3.2.2.4. Seuil de difficulté des instances\n",
    "- E1.4. Combinaison de sur-échantillonnage et de sous-échantillonnage\n",
    "- E1.5. Ensemble d'échantillonneurs\n",
    "    - 5.1. Classifieur incluant des échantillonneurs à équilibrage internes\n",
    "        - 5.1.1. Classifieur Bagging\n",
    "        - 5.1.2. Forêt d'arbres aléatoires\n",
    "        - 5.1.3. Boosting\n",
    "- E1.6. Échantillonneurs divers\n",
    "    - 6.1. Échantillonneurs personnalisés\n",
    "    - 6.2. Générateurs personnalisés\n",
    "        - 6.2.1. Générateur TensorFlow\n",
    "        - 6.2.2. Générateur Keras\n",
    "- E1.7. Métriques\n",
    "    - 7.1. Métriques de classification\n",
    "        - 7.1.1. Métriques de sensibilité et spécificité\n",
    "        - 7.1.2. Métriques supplémentaires spécifiques aux jeux de données déséquilibrés\n",
    "        - 7.1.3. Erreur absolue moyenne macro-pondérée (MA-MAE)\n",
    "        - 7.1.4. Résumé des métriques importantes\n",
    "    - 7.2. Métriques par paires\n",
    "        - 7.2.1. Métrique de différence de valeur (VDM)\n",
    "- E1.8. Erreurs courantes et bonnes pratiques recommandées\n",
    "    - 8.1. Fuite de données\n",
    "- E1.9. Utilitaires de chargement de jeux de données\n",
    "    - 9.1. Jeux de données déséquilibrés pour benchmark\n",
    "    - 9.2. Générateur déséquilibré\n",
    "- E1.10. Lignes directrices pour les développeurs\n",
    "    - 10.1. Utilitaires pour les développeurs\n",
    "        - 10.1.1. Outils de validation\n",
    "        - 10.1.2. Obsolescence\n",
    "    - 10.2. Publication d'une version\n",
    "        - 10.2.1. Version majeure\n",
    "        - 10.2.2. Correctif de bug\n",
    "- E1.11. Références"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='introduction'></a> E1.1. **Introduction**<br/>([_Introduction_](https://imbalanced-learn.org/stable/introduction.html#introduction))\n",
    "\n",
    "## <a id='api-s-of-imbalanced-learn-samplers'></a> E1.1.1. **API des échantillonneurs imbalanced-learns**<br/>([_API’s of imbalanced-learn samplers_](https://imbalanced-learn.org/stable/introduction.html#api-s-of-imbalanced-learn-samplers))\n",
    "\n",
    "## <a id='problem-statement-regarding-imbalanced-data-sets'></a> E1.1.2. **Problème lié aux jeux de données déséquilibrés**<br/>([_Problem statement regarding imbalanced data sets_](https://imbalanced-learn.org/stable/introduction.html#problem-statement-regarding-imbalanced-data-sets))\n",
    "\n",
    "\n",
    "# <a id='over-sampling'></a> E1.2. **Sur-échantillonnage**<br/>([_Over-sampling_](https://imbalanced-learn.org/stable/over_sampling.html#over-sampling))\n",
    "\n",
    "## <a id='a-practical-guide'></a> E1.2.1. **Guide pratique**<br/>([_A practical guide_](https://imbalanced-learn.org/stable/over_sampling.html#a-practical-guide))\n",
    "\n",
    "### <a id='naive-random-over-sampling'></a> E1.2.1.1. **Sur-échantillonnage aléatoire naïf**<br/>([_Naive random over-sampling_](https://imbalanced-learn.org/stable/over_sampling.html#naive-random-over-sampling))\n",
    "\n",
    "### <a id='from-random-over-sampling-to-smote-and-adasyn'></a> E1.2.1.2. **Du sur-échantillonnage aléatoire à SMOTE et ADASYN**<br/>([_From random over-sampling to SMOTE and ADASYN_](https://imbalanced-learn.org/stable/over_sampling.html#from-random-over-sampling-to-smote-and-adasyn))\n",
    "\n",
    "### <a id='ill-posed-examples'></a> E1.2.1.3. **Exemples de problèmes mal posés**<br/>([_Ill-posed examples_](https://imbalanced-learn.org/stable/over_sampling.html#ill-posed-examples))\n",
    "\n",
    "### <a id='smote-variants'></a> E1.2.1.4. **Variantes de SMOTE**<br/>([_SMOTE variants_](https://imbalanced-learn.org/stable/over_sampling.html#smote-variants))\n",
    "\n",
    "## <a id='mathematical-formulation'></a> E1.2.2. **Formulation mathématique**<br/>([_Mathematical formulation_](https://imbalanced-learn.org/stable/over_sampling.html#mathematical-formulation))\n",
    "\n",
    "### <a id='sample-generation'></a> E1.2.2.1. **Génération d'échantillons**<br/>([_Sample generation_](https://imbalanced-learn.org/stable/over_sampling.html#sample-generation))\n",
    "\n",
    "### <a id='multi-class-management'></a> E1.2.2.2. **Gestion multi-classes**<br/>([_Multi-class management_](https://imbalanced-learn.org/stable/over_sampling.html#multi-class-management))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='introduction'></a> E1.1. **Introduction**<br/>([_Introduction_](https://imbalanced-learn.org/stable/introduction.html#introduction))\n",
    "\n",
    "## <a id='api-s-of-imbalanced-learn-samplers'></a> E1.1.1. **API des échantillonneurs imbalanced-learns**<br/>([_API’s of imbalanced-learn samplers_](https://imbalanced-learn.org/stable/introduction.html#api-s-of-imbalanced-learn-samplers))\n",
    "\n",
    "Les échantillonneurs disponibles suivent l'API de scikit-learn en utilisant l'estimateur de base et en ajoutant une fonctionnalité d'échantillonnage via la méthode `sample` :\n",
    "\n",
    "**Estimateur :** L'objet de base, implémente une méthode `fit` pour apprendre à partir des données, soit :\n",
    "\n",
    "```python\n",
    "estimator = obj.fit(data, targets)\n",
    "```\n",
    "\n",
    "**ré-échantillonneur :** Pour ré-échantillonner un ensemble de jeux de données, chaque échantillonneur implémente :\n",
    "\n",
    "```python\n",
    "data_resampled, targets_resampled = obj.fit_resample(data, targets)\n",
    "```\n",
    "\n",
    "Les échantillonneurs imbalanced-learn acceptent les mêmes entrées que scikit-learn :\n",
    "* `data`:\n",
    "    * 2-D [**`list`**](https://docs.python.org/3/library/stdtypes.html#list),\n",
    "    * 2-D [**`numpy.ndarray`**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray),\n",
    "    * [**`pandas.DataFrame`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame),\n",
    "    * [**`scipy.sparse.csr_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) or [**`scipy.sparse.csc_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html#scipy.sparse.csc_matrix);\n",
    "* `targets`:\n",
    "    * 1-D [**`numpy.ndarray`**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray),\n",
    "    * [**`pandas.Series`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series).\n",
    "\n",
    "La sortie sera du type suivant :\n",
    "* `data_resampled`:\n",
    "    * 2-D [**`numpy.ndarray`**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray),\n",
    "    * [**`pandas.DataFrame`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame),\n",
    "    * [**`scipy.sparse.csr_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) or [**`scipy.sparse.csc_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html#scipy.sparse.csc_matrix);\n",
    "* `targets_resampled`:\n",
    "    * 1-D [**`numpy.ndarray`**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray),\n",
    "    * [**`pandas.Series`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series).\n",
    "\n",
    "### Entrées/Sortie avec Pandas\n",
    "\n",
    "Contrairement à scikit-learn, imbalanced-learn prend en charge les entrées/sorties avec Pandas. Par conséquent, si vous fournissez un dataframe, vous obtiendrez également un dataframe en sortie.\n",
    "\n",
    "### Entrée creuse\n",
    "\n",
    "Pour les entrées creuses, les données sont converties en représentation Compressed Sparse Rows (CSR) (voir `scipy.sparse.csr_matrix`) avant d'être passées à l'échantillonneur. Pour éviter les copies inutiles en mémoire, il est recommandé de choisir la représentation CSR en amont."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='problem-statement-regarding-imbalanced-data-sets'></a> E1.1.2. **Problème lié aux jeux de données déséquilibrés**<br/>([_Problem statement regarding imbalanced data sets_](https://imbalanced-learn.org/stable/introduction.html#problem-statement-regarding-imbalanced-data-sets))\n",
    "\n",
    "La phase d'apprentissage et la prédiction ultérieure des algorithmes d'apprentissage automatique peuvent être affectées par le problème des jeux de données déséquilibrés. Ce problème d'équilibrage correspond à la différence du nombre d'échantillons dans les différentes classes. Nous illustrons l'effet de l'apprentissage d'un classificateur SVM linéaire avec différents niveaux d'équilibrage des classes.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_001.png\"\n",
    "    alt=\"Fonction de décision du LogisticRegression\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Comme prévu, la fonction de décision du SVM linéaire varie considérablement en fonction du déséquilibre des données. Avec un ratio de déséquilibre plus élevé, la fonction de décision favorise la classe avec le plus grand nombre d'échantillons, généralement appelée classe dominante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='over-sampling'></a> E1.2. **Sur-échantillonnage**<br/>([_Sur-échantillonnage_](https://imbalanced-learn.org/stable/over_sampling.html#over-sampling))\n",
    "\n",
    "## <a id='a-practical-guide'></a> E1.2.1. **Guide pratique**<br/>([_Guide pratique_](https://imbalanced-learn.org/stable/over_sampling.html#a-practical-guide))\n",
    "\n",
    "Vous pouvez vous référer à l'exemple [**Comparer les échantillonneurs de sur-échantillonnage**](https://imbalanced-learn.org/stable/auto_examples/over-sampling/plot_comparison_over_sampling.html).\n",
    "\n",
    "### <a id='naive-random-over-sampling'></a> E1.2.1.1. **Sur-échantillonnage aléatoire naïf**<br/>([_Sur-échantillonnage aléatoire naïf_](https://imbalanced-learn.org/stable/over_sampling.html#naive-random-over-sampling))\n",
    "\n",
    "Une manière de lutter contre ce problème est de générer de nouveaux échantillons pour les classes qui sont sous-représentées. La stratégie la plus naïve consiste à générer de nouveaux échantillons en échantillonnant aléatoirement avec remplacement des échantillons actuellement disponibles. Le [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) propose un tel schéma :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4674), (1, 4674), (2, 4674)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(\n",
    "    n_samples=5000, n_features=2, n_informative=2,\n",
    "    n_redundant=0, n_repeated=0, n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.01, 0.05, 0.94],\n",
    "    class_sep=0.8, random_state=0)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4674), (1, 4674), (2, 4674)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble de données augmenté doit être utilisé à la place de l'ensemble de données d'origine pour entraîner un classifieur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "# LogisticRegression(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la figure ci-dessous, nous comparons les fonctions de décision d'un classifieur entraîné en utilisant l'ensemble de données sur-échantillonné et l'ensemble de données d'origine.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_002.png\"\n",
    "    alt=\"Fonction de décision de LogisticRegression\"\n",
    "    style=\"max-width: 75%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "En conséquence, la classe majoritaire ne prend pas le dessus sur les autres classes pendant le processus d'entraînement. Par conséquent, toutes les classes sont représentées par la fonction de décision.\n",
    "\n",
    "De plus, le [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) permet d'échantillonner des données hétérogènes (par exemple, contenant des chaînes de caractères) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['xxx' 1 1.0]\n",
      " ['yyy' 2 2.0]\n",
      " ['zzz' 3 3.0]\n",
      " ['zzz' 3 3.0]]\n",
      "[0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_hetero = np.array(\n",
    "    [['xxx', 1, 1.0], ['yyy', 2, 2.0], ['zzz', 3, 3.0]],\n",
    "    dtype=object\n",
    ")\n",
    "y_hetero = np.array([0, 0, 1])\n",
    "X_resampled, y_resampled = ros.fit_resample(X_hetero, y_hetero)\n",
    "print(X_resampled)\n",
    "# [['xxx' 1 1.0]\n",
    "#  ['yyy' 2 2.0]\n",
    "#  ['zzz' 3 3.0]\n",
    "#  ['zzz' 3 3.0]]\n",
    "print(y_resampled)\n",
    "# [0 0 1 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il fonctionnerait également avec un dataframe pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "0   25    Private  226802          11th              7       Never-married   \n",
       "1   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
       "4   18        NaN  103497  Some-college             10       Never-married   \n",
       "\n",
       "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                NaN    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  \n",
       "0              40  United-States  \n",
       "1              50  United-States  \n",
       "2              40  United-States  \n",
       "3              40  United-States  \n",
       "4              30  United-States  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "df_adult, y_adult = fetch_openml(\n",
    "    'adult', version=2, as_frame=True, return_X_y=True, parser='auto')\n",
    "df_adult.head()  \n",
    "df_resampled, y_resampled = ros.fit_resample(df_adult, y_adult)\n",
    "df_resampled.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la répétition d'échantillons pose problème, le paramètre `shrinkage` permet de créer un bootstrap lissé. Cependant, les données d'origine doivent être numériques. Le paramètre `shrinkage` contrôle la dispersion des nouveaux échantillons générés. Nous montrons un exemple illustrant que les nouveaux échantillons ne se chevauchent plus une fois qu'un bootstrap lissé est utilisé. Cette manière de générer un bootstrap lissé est également connue sous le nom d'Exemples de Sur-Échantillonnage Aléatoire (ROSE) [MT14].\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_003.png\"\n",
    "    alt=\"Rééchantillonnage avec RandomOverSampler\"\n",
    "    style=\"max-width: 75%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='from-random-over-sampling-to-smote-and-adasyn'></a> E1.2.1.2. **Du sur-échantillonnage aléatoire à SMOTE et ADASYN**<br/>([_From random over-sampling to SMOTE and ADASYN_](https://imbalanced-learn.org/stable/over_sampling.html#from-random-over-sampling-to-smote-and-adasyn))\n",
    "\n",
    "Outre l'échantillonnage aléatoire avec remplacement, il existe deux méthodes populaires pour sur-échantillonner les classes minoritaires : (i) la technique de sur-échantillonnage synthétique des classes minoritaires (SMOTE - _Synthetic Minority Oversampling Technique_) [CBHK02] et (ii) la méthode d'échantillonnage synthétique adaptatif (ADASYN - _Adaptive Synthetic_) [HBGL08]. Ces algorithmes peuvent être utilisés de la même manière :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4674), (1, 4674), (2, 4674)]\n",
      "[(0, 4673), (1, 4662), (2, 4674)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4674), (1, 4674), (2, 4674)]\n",
    "clf_smote = LogisticRegression().fit(X_resampled, y_resampled)\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4673), (1, 4662), (2, 4674)]\n",
    "clf_adasyn = LogisticRegression().fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figure ci-dessous illustre la principale différence entre les différentes méthodes de sur-échantillonnage.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_004.png\"\n",
    "    alt=\"Comparaison des méthodes de sur-échantillonnage\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='ill-posed-examples'></a> E1.2.1.3. **Exemples de problèmes mal posés**<br/>([_Ill-posed examples_](https://imbalanced-learn.org/stable/over_sampling.html#ill-posed-examples))\n",
    "\n",
    "Tandis que le [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) effectue le sur-échantillonnage en dupliquant certains des échantillons originaux de la classe minoritaire, [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) et [**`ADASYN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#imblearn.over_sampling.ADASYN) génèrent de nouveaux échantillons par interpolation. Cependant, les échantillons utilisés pour l'interpolation/la génération de nouveaux échantillons synthétiques diffèrent. En effet, [**`ADASYN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#imblearn.over_sampling.ADASYN) se concentre sur la génération, à l'aide d'un classifieur k-NN, d'échantillons proches des échantillons originaux mal classés, tandis que l'implémentation de base de [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) ne fait aucune distinction entre les échantillons faciles et difficiles à classer suivant la règle des voisins les plus proches. Par conséquent, la fonction de décision trouvée lors de l'entraînement sera différente entre les deux algorithmes.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_005.png\"\n",
    "    alt=\"Comparaison ADASYN, SMOTE et absence de ré-échantillonnage\"\n",
    "    style=\"max-width: 75%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Les particularités de l'échantillonnage de ces deux algorithmes peuvent entraîner des comportements particuliers, comme le montre l'exemple ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_006.png\"\n",
    "    alt=\"Particularités de la sur-échantillonnage avec SMOTE et ADASYN\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='smote-variants'></a> E1.2.1.4. **Variantes de SMOTE**<br/>([_SMOTE variants_](https://imbalanced-learn.org/stable/over_sampling.html#smote-variants))\n",
    "\n",
    "SMOTE pourrait connecter des valeurs aberrantes (outliers) avec les valeurs atypiques (inliers), tandis qu'ADASYN pourrait se concentrer uniquement sur les valeurs aberrantes, ce qui, dans les deux cas, pourrait conduire à une fonction de décision sous-optimale. À cet égard, SMOTE propose trois options supplémentaires pour générer des échantillons. Ces méthodes se concentrent sur les échantillons proches de la frontière de la fonction de décision optimale et généreront des échantillons dans la direction opposée à la classe des voisins les plus proches. Ces variantes sont présentées dans la figure ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_007.png\"\n",
    "    alt=\"Fonction de décision et ré-échantillonnage à l'aide des variantes de SMOTE\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Les algorithmes [**`BorderlineSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html#imblearn.over_sampling.BorderlineSMOTE) [HWM05], [**`SVMSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SVMSMOTE.html#imblearn.over_sampling.SVMSMOTE) [NCK09], et [**`KMeansSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.KMeansSMOTE.html#imblearn.over_sampling.KMeansSMOTE) [LDB17] sont des variantes de l'algorithme SMOTE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4674), (1, 4674), (2, 4674)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4674), (1, 4674), (2, 4674)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'il s'agit de données mixtes, telles que des caractéristiques continues et catégorielles, aucune des méthodes présentées (à l'exception de la classe [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler)) ne peut traiter les caractéristiques catégorielles. La [**`SMOTENC`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) [CBHK02] est une extension de l'algorithme SMOTE qui traite différemment les données catégorielles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 20), (1, 30)]\n"
     ]
    }
   ],
   "source": [
    "# create a synthetic data set with continuous and categorical features\n",
    "rng = np.random.RandomState(42)\n",
    "n_samples = 50\n",
    "X = np.empty((n_samples, 3), dtype=object)\n",
    "X[:, 0] = rng.choice(['A', 'B', 'C'], size=n_samples).astype(object)\n",
    "X[:, 1] = rng.randn(n_samples)\n",
    "X[:, 2] = rng.randint(3, size=n_samples)\n",
    "y = np.array([0] * 20 + [1] * 30)\n",
    "print(sorted(Counter(y).items()))\n",
    "# [(0, 20), (1, 30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce jeu de données, les première et dernière caractéristiques sont considérées comme des caractéristiques catégorielles. Il est nécessaire de fournir cette information à [**`SMOTENC`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) via les paramètres `categorical_features`, que ce soit en passant les indices, les noms des caractéristiques lorsque `X` est un DataFrame pandas, un masque booléen marquant ces caractéristiques, ou en se basant sur l'inférence du type (`dtype`) si les colonnes utilisent le [**`pandas.CategoricalDtype`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.CategoricalDtype.html#pandas.CategoricalDtype) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 30), (1, 30)]\n",
      "[['A' 0.5246469549655818 2]\n",
      " ['B' -0.3657680728116921 2]\n",
      " ['B' 0.9344237230779993 2]\n",
      " ['B' 0.3710891618824609 2]\n",
      " ['B' 0.3327240726719727 2]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "smote_nc = SMOTENC(categorical_features=[0, 2], random_state=0)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 30), (1, 30)]\n",
    "print(X_resampled[-5:])\n",
    "# [['A' 0.5246469549655818 2]\n",
    "# ['B' -0.3657680728116921 2]\n",
    "# ['B' 0.9344237230779993 2]\n",
    "# ['B' 0.3710891618824609 2]\n",
    "# ['B' 0.3327240726719727 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par conséquent, on peut voir que les échantillons générés dans les première et dernière colonnes appartiennent aux mêmes catégories que celles présentées initialement sans aucune interpolation supplémentaire.\n",
    "\n",
    "Cependant, [**`SMOTENC`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) ne fonctionne que lorsque les données sont constituées d'une combinaison de caractéristiques numériques et catégorielles. Si les données sont composées uniquement de données catégorielles, on peut utiliser la variante [**`SMOTEN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTEN.html#imblearn.over_sampling.SMOTEN) [CBHK02]. L'algorithme change de deux manières :\n",
    "- La recherche des voisins les plus proches ne repose pas sur la distance euclidienne. En effet, la métrique de différence de valeur (VDM - _Value Difference Metric_), également implémentée dans la classe `ValueDifferenceMetric`, est utilisée.\n",
    "- Un nouvel échantillon est généré où chaque valeur de caractéristique correspond à la catégorie la plus courante observée dans les échantillons voisins appartenant à la même classe.\n",
    "\n",
    "Prenons l'exemple suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([\"green\"] * 5 + [\"red\"] * 10 + [\"blue\"] * 7,\n",
    "             dtype=object).reshape(-1, 1)\n",
    "y = np.array([\"apple\"] * 5 + [\"not apple\"] * 3 + [\"apple\"] * 7 +\n",
    "             [\"not apple\"] * 5 + [\"apple\"] * 2, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous générons un jeu de données associant une couleur au fait d'être ou non une pomme. Nous associons fortement `\"green\"` et `\"red\"` au fait d'être une pomme. La classe minoritaire étant `\"not apple\"`, nous nous attendons à ce que de nouvelles données générées appartiennent à la catégorie `\"bleu\"` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not apple', 'not apple', 'not apple', 'not apple', 'not apple',\n",
       "       'not apple'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTEN\n",
    "sampler = SMOTEN(random_state=0)\n",
    "X_res, y_res = sampler.fit_resample(X, y)\n",
    "X_res[y.size:]\n",
    "y_res[y.size:]\n",
    "# array(['not apple', 'not apple', 'not apple', 'not apple', 'not apple',\n",
    "#        'not apple'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='mathematical-formulation'></a> E1.2.2. **Formulation mathématique**<br/>([_Mathematical formulation_](https://imbalanced-learn.org/stable/over_sampling.html#mathematical-formulation))\n",
    "\n",
    "### <a id='sample-generation'></a> E1.2.2.1. **Génération d'échantillons**<br/>([_Sample generation_](https://imbalanced-learn.org/stable/over_sampling.html#sample-generation))\n",
    "\n",
    "[**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) et [**`ADASYN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#imblearn.over_sampling.ADASYN) utilisent le même algorithme pour générer de nouveaux échantillons. En considérant un échantillon $x_i$, un nouvel échantillon $x_{new}$ sera généré en prenant en compte ses $k$ plus proches voisins (correspondant à `k_neighbors`). Par exemple, les 3 plus proches voisins sont inclus dans le cercle bleu comme illustré dans la figure ci-dessous. Ensuite, l'un de ces plus proches voisins $x_{zi}$ est sélectionné et un échantillon est généré comme suit :\n",
    "\n",
    "$$x_{new} = x_i + \\lambda \\times (x_{zi} - x_i)$$\n",
    "\n",
    "où $\\lambda$ est un nombre aléatoire dans la plage $[0, 1]$. Cette interpolation créera un échantillon sur la ligne entre $x_i$ et $x_{zi}$, comme illustré dans l'image ci-dessous :\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_illustration_generation_sample_001.png\"\n",
    "    alt=\"Stratégie d'échantillonnage\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "SMOTE-NC change légèrement la manière dont un nouvel échantillon est généré en effectuant quelque chose de spécifique pour les caractéristiques catégorielles. En fait, les catégories d'un nouvel échantillon généré sont décidées en choisissant la catégorie la plus fréquente parmi les voisins les plus proches présents lors de la génération.\n",
    "\n",
    "> **Avertissement** Soyez conscient que SMOTE-NC n'est pas conçu pour fonctionner uniquement avec des données catégorielles.\n",
    "\n",
    "Les autres variantes de SMOTE et ADASYN diffèrent les unes des autres en sélectionnant les échantillons $x_i$ avant de générer les nouveaux échantillons.\n",
    "\n",
    "Le SMOTE **régulier** - cf. l'objet [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) - n'impose aucune règle et choisira de manière aléatoire tous les $x_i$ possibles disponibles.\n",
    "\n",
    "Le SMOTE **borderline** - cf. [**`BorderlineSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html#imblearn.over_sampling.BorderlineSMOTE) avec les paramètres `kind='borderline-1'` et `kind='borderline-2'` - classe chaque échantillon $x_i$ comme (i) du bruit (c'est-à-dire que tous les voisins les plus proches sont d'une classe différente de celle de $x_i$), (ii) en danger (c'est-à-dire qu'au moins la moitié des voisins les plus proches sont de la même classe que $x_i$), ou (iii) sûr (c'est-à-dire que tous les voisins les plus proches sont de la même classe que $x_i$). Le SMOTE **Borderline-1** et **Borderline-2** utilise les échantillons en danger pour générer de nouveaux échantillons. Dans le **Borderline-1** SMOTE, $x_{zi}$ appartient à la même classe que celle de l'échantillon $x_i$. En revanche, le **Borderline-2** SMOTE prend en compte $x_{zi}$ qui peut être de n'importe quelle classe.\n",
    "\n",
    "Le SMOTE **SVM** - cf. [**`SVMSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SVMSMOTE.html#imblearn.over_sampling.SVMSMOTE) - utilise un classifieur SVM pour trouver des vecteurs de support et génère des échantillons en les prenant en compte. Notez que le paramètre `C` du classifieur SVM permet de sélectionner plus ou moins de vecteurs de support.\n",
    "\n",
    "Pour le SMOTE borderline et SVM, un voisinage est défini à l'aide du paramètre `m_neighbors` pour décider si un échantillon est en danger, sûr ou du bruit.\n",
    "\n",
    "Le SMOTE **KMeans** - cf. [**`KMeansSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.KMeansSMOTE.html#imblearn.over_sampling.KMeansSMOTE) - utilise une méthode de regroupement KMeans avant d'appliquer le SMOTE. Le regroupement regroupe des échantillons ensemble et génère de nouveaux échantillons en fonction de la densité de la grappe.\n",
    "\n",
    "ADASYN fonctionne de manière similaire au SMOTE régulier. Cependant, le nombre d'échantillons générés pour chaque échantillon est proportionnel au nombre d'échantillons qui ne sont pas de la même classe que dans un voisinage donné. Par conséquent, plus d'échantillons seront générés dans la zone où la règle du voisinage le plus proche n'est pas respectée. Le paramètre `m_neighbors` est équivalent à `k_neighbors` dans [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='multi-class-management'></a> E1.2.2.2. **Gestion multi-classes**<br/>([_Multi-class management_](https://imbalanced-learn.org/stable/over_sampling.html#multi-class-management))\n",
    "\n",
    "Tous les algorithmes peuvent être utilisés tant avec des classes multiples qu'avec une classification binaire. [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) ne nécessite aucune information inter-classes lors de la génération d'échantillons. Par conséquent, chaque classe cible est ré-échantillonnée indépendamment. En revanche, [**`ADASYN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#imblearn.over_sampling.ADASYN) et [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) ont besoin d'informations concernant le voisinage de chaque échantillon utilisé pour la génération d'échantillons. Ils utilisent une approche un-contre-tous (OvR) en sélectionnant chaque classe cible et en calculant les statistiques nécessaires par rapport au reste du jeu de données, qui est regroupé dans une seule classe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
