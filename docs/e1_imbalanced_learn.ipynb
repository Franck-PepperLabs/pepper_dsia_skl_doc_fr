{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='skl-ext'></a> 1. **Extensions de Scikit-learn**</br>(*Scikit-learn extension*)\n",
    "\n",
    "# E1. [**..**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/e1_imbalanced_learn.ipynb)<br/>([*Imbalanced Learn*](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : . pages, . exemples, . papiers\n",
    "- E1.1 Introduction\n",
    "    - 1.1. API’s of imbalanced-learn samplers\n",
    "    - 1.2. Problem statement regarding imbalanced data sets\n",
    "- E1.2. Over-sampling\n",
    "    - 2.1. A practical guide\n",
    "        - 2.1.1. Naive random over-sampling\n",
    "        - 2.1.2. From random over-sampling to SMOTE and ADASYN\n",
    "        - 2.1.3. Ill-posed examples\n",
    "        - 2.1.4. SMOTE variants\n",
    "    - 2.2. Mathematical formulation\n",
    "        - 2.2.1. Sample generation\n",
    "        - 2.2.2. Multi-class management\n",
    "- E1.3. Under-sampling\n",
    "    - 3.1. Prototype generation\n",
    "    - 3.2. Prototype selection\n",
    "        - 3.2.1. Controlled under-sampling techniques\n",
    "            - 3.2.1.1. Mathematical formulation\n",
    "        - 3.2.2. Cleaning under-sampling techniques\n",
    "            - 3.2.2.1. Tomek’s links\n",
    "            - 3.2.2.2. Edited data set using nearest neighbours\n",
    "            - 3.2.2.3. Condensed nearest neighbors and derived algorithms\n",
    "            - 3.2.2.4. Instance hardness threshold\n",
    "- E1.4. Combination of over- and under-sampling\n",
    "- E1.5. Ensemble of samplers\n",
    "    - 5.1. Classifier including inner balancing samplers\n",
    "        - 5.1.1. Bagging classifier\n",
    "        - 5.1.2. Forest of randomized trees\n",
    "        - 5.1.3. Boosting\n",
    "- E1.6. Miscellaneous samplers\n",
    "    - 6.1. Custom samplers\n",
    "    - 6.2. Custom generators\n",
    "        - 6.2.1. TensorFlow generator\n",
    "        - 6.2.2. Keras generator\n",
    "- E1.7. Metrics\n",
    "    - 7.1. Classification metrics\n",
    "        - 7.1.1. Sensitivity and specificity metrics\n",
    "        - 7.1.2. Additional metrics specific to imbalanced datasets\n",
    "        - 7.1.3. Macro-Averaged Mean Absolute Error (MA-MAE)\n",
    "        - 7.1.4. Summary of important metrics\n",
    "    - 7.2. Pairwise metrics\n",
    "        - 7.2.1. Value Difference Metric\n",
    "- E1.8. Common pitfalls and recommended practices\n",
    "    - 8.1. Data leakage\n",
    "- E1.9. Dataset loading utilities\n",
    "    - 9.1. Imbalanced datasets for benchmark\n",
    "    - 9.2. Imbalanced generator\n",
    "- E1.10. Developer guideline\n",
    "    - 10.1. Developer utilities\n",
    "        - 10.1.1. Validation Tools\n",
    "        - 10.1.2. Deprecation\n",
    "    - 10.2. Making a release\n",
    "        - 10.2.1. Major release\n",
    "        - 10.2.2. Bug fix release\n",
    "- E1.11. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- E1.1 Introduction\n",
    "    - 1.1. API des échantillonneurs imbalanced-learn\n",
    "    - 1.2. Problème lié aux jeux de données déséquilibrés\n",
    "- E1.2. Sur-échantillonnage\n",
    "    - 2.1. Guide pratique\n",
    "        - 2.1.1. Sur-échantillonnage aléatoire naïf\n",
    "        - 2.1.2. Du sur-échantillonnage aléatoire à SMOTE et ADASYN\n",
    "        - 2.1.3. Exemples de problèmes mal posés\n",
    "        - 2.1.4. Variantes de SMOTE\n",
    "    - 2.2. Formulation mathématique\n",
    "        - 2.2.1. Génération d'échantillons\n",
    "        - 2.2.2. Gestion multi-classes\n",
    "- E1.3. Sous-échantillonnage\n",
    "    - 3.1. Génération de prototypes\n",
    "    - 3.2. Sélection de prototypes\n",
    "        - 3.2.1. Techniques de sous-échantillonnage contrôlé\n",
    "            - 3.2.1.1. Formulation mathématique\n",
    "        - 3.2.2. Techniques de sous-échantillonnage de nettoyage\n",
    "            - 3.2.2.1. Liens de Tomek\n",
    "            - 3.2.2.2. Jeu de données édité en utilisant les voisins les plus proches\n",
    "            - 3.2.2.3. Voisins les plus proches condensés et algorithmes dérivés\n",
    "            - 3.2.2.4. Seuil de difficulté des instances\n",
    "- E1.4. Combinaison de sur-échantillonnage et de sous-échantillonnage\n",
    "- E1.5. Ensemble d'échantillonneurs\n",
    "    - 5.1. Classifieur incluant des échantillonneurs à équilibrage internes\n",
    "        - 5.1.1. Classifieur Bagging\n",
    "        - 5.1.2. Forêt d'arbres aléatoires\n",
    "        - 5.1.3. Boosting\n",
    "- E1.6. Échantillonneurs divers\n",
    "    - 6.1. Échantillonneurs personnalisés\n",
    "    - 6.2. Générateurs personnalisés\n",
    "        - 6.2.1. Générateur TensorFlow\n",
    "        - 6.2.2. Générateur Keras\n",
    "- E1.7. Métriques\n",
    "    - 7.1. Métriques de classification\n",
    "        - 7.1.1. Métriques de sensibilité et spécificité\n",
    "        - 7.1.2. Métriques supplémentaires spécifiques aux jeux de données déséquilibrés\n",
    "        - 7.1.3. Erreur absolue moyenne macro-pondérée (MA-MAE)\n",
    "        - 7.1.4. Résumé des métriques importantes\n",
    "    - 7.2. Métriques par paires\n",
    "        - 7.2.1. Métrique de différence de valeur (VDM)\n",
    "- E1.8. Erreurs courantes et bonnes pratiques recommandées\n",
    "    - 8.1. Fuite de données\n",
    "- E1.9. Utilitaires de chargement de jeux de données\n",
    "    - 9.1. Jeux de données déséquilibrés pour benchmark\n",
    "    - 9.2. Générateur déséquilibré\n",
    "- E1.10. Lignes directrices pour les développeurs\n",
    "    - 10.1. Utilitaires pour les développeurs\n",
    "        - 10.1.1. Outils de validation\n",
    "        - 10.1.2. Obsolescence\n",
    "    - 10.2. Publication d'une version\n",
    "        - 10.2.1. Version majeure\n",
    "        - 10.2.2. Correctif de bug\n",
    "- E1.11. Références"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='introduction'></a> E1.1. **Introduction**<br/>([_Introduction_](https://imbalanced-learn.org/stable/introduction.html#introduction))\n",
    "\n",
    "## <a id='api-s-of-imbalanced-learn-samplers'></a> E1.1.1. **API des échantillonneurs imbalanced-learns**<br/>([_API’s of imbalanced-learn samplers_](https://imbalanced-learn.org/stable/introduction.html#api-s-of-imbalanced-learn-samplers))\n",
    "\n",
    "## <a id='problem-statement-regarding-imbalanced-data-sets'></a> E1.1.2. **Problème lié aux jeux de données déséquilibrés**<br/>([_Problem statement regarding imbalanced data sets_](https://imbalanced-learn.org/stable/introduction.html#problem-statement-regarding-imbalanced-data-sets))\n",
    "\n",
    "\n",
    "# <a id='over-sampling'></a> E1.2. **Sur-échantillonnage**<br/>([_Over-sampling_](https://imbalanced-learn.org/stable/over_sampling.html#over-sampling))\n",
    "\n",
    "## <a id='a-practical-guide'></a> E1.2.1. **Guide pratique**<br/>([_A practical guide_](https://imbalanced-learn.org/stable/over_sampling.html#a-practical-guide))\n",
    "\n",
    "### <a id='naive-random-over-sampling'></a> E1.2.1.1. **Sur-échantillonnage aléatoire naïf**<br/>([_Naive random over-sampling_](https://imbalanced-learn.org/stable/over_sampling.html#naive-random-over-sampling))\n",
    "\n",
    "### <a id='from-random-over-sampling-to-smote-and-adasyn'></a> E1.2.1.2. **Du sur-échantillonnage aléatoire à SMOTE et ADASYN**<br/>([_From random over-sampling to SMOTE and ADASYN_](https://imbalanced-learn.org/stable/over_sampling.html#from-random-over-sampling-to-smote-and-adasyn))\n",
    "\n",
    "### <a id='ill-posed-examples'></a> E1.2.1.3. **Exemples de problèmes mal posés**<br/>([_Ill-posed examples_](https://imbalanced-learn.org/stable/over_sampling.html#ill-posed-examples))\n",
    "\n",
    "### <a id='smote-variants'></a> E1.2.1.4. **Variantes de SMOTE**<br/>([_SMOTE variants_](https://imbalanced-learn.org/stable/over_sampling.html#smote-variants))\n",
    "\n",
    "## <a id='mathematical-formulation'></a> E1.2.2. **Formulation mathématique**<br/>([_Mathematical formulation_](https://imbalanced-learn.org/stable/over_sampling.html#mathematical-formulation))\n",
    "\n",
    "### <a id='sample-generation'></a> E1.2.2.1. **Génération d'échantillons**<br/>([_Sample generation_](https://imbalanced-learn.org/stable/over_sampling.html#sample-generation))\n",
    "\n",
    "### <a id='multi-class-management'></a> E1.2.2.2. **Gestion multi-classes**<br/>([_Multi-class management_](https://imbalanced-learn.org/stable/over_sampling.html#multi-class-management))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='introduction'></a> E1.1. **Introduction**<br/>([_Introduction_](https://imbalanced-learn.org/stable/introduction.html#introduction))\n",
    "\n",
    "## <a id='api-s-of-imbalanced-learn-samplers'></a> E1.1.1. **API des échantillonneurs imbalanced-learns**<br/>([_API’s of imbalanced-learn samplers_](https://imbalanced-learn.org/stable/introduction.html#api-s-of-imbalanced-learn-samplers))\n",
    "\n",
    "Les échantillonneurs disponibles suivent l'API de scikit-learn en utilisant l'estimateur de base et en ajoutant une fonctionnalité d'échantillonnage via la méthode `sample` :\n",
    "\n",
    "**Estimateur :** L'objet de base, implémente une méthode `fit` pour apprendre à partir des données, soit :\n",
    "\n",
    "```python\n",
    "estimator = obj.fit(data, targets)\n",
    "```\n",
    "\n",
    "**ré-échantillonneur :** Pour ré-échantillonner un ensemble de jeux de données, chaque échantillonneur implémente :\n",
    "\n",
    "```python\n",
    "data_resampled, targets_resampled = obj.fit_resample(data, targets)\n",
    "```\n",
    "\n",
    "Les échantillonneurs imbalanced-learn acceptent les mêmes entrées que scikit-learn :\n",
    "* `data`:\n",
    "    * 2-D [**`list`**](https://docs.python.org/3/library/stdtypes.html#list),\n",
    "    * 2-D [**`numpy.ndarray`**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray),\n",
    "    * [**`pandas.DataFrame`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame),\n",
    "    * [**`scipy.sparse.csr_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) or [**`scipy.sparse.csc_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html#scipy.sparse.csc_matrix);\n",
    "* `targets`:\n",
    "    * 1-D [**`numpy.ndarray`**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray),\n",
    "    * [**`pandas.Series`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series).\n",
    "\n",
    "La sortie sera du type suivant :\n",
    "* `data_resampled`:\n",
    "    * 2-D [**`numpy.ndarray`**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray),\n",
    "    * [**`pandas.DataFrame`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame),\n",
    "    * [**`scipy.sparse.csr_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) or [**`scipy.sparse.csc_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html#scipy.sparse.csc_matrix);\n",
    "* `targets_resampled`:\n",
    "    * 1-D [**`numpy.ndarray`**](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray),\n",
    "    * [**`pandas.Series`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series).\n",
    "\n",
    "### Entrées/Sortie avec Pandas\n",
    "\n",
    "Contrairement à scikit-learn, imbalanced-learn prend en charge les entrées/sorties avec Pandas. Par conséquent, si vous fournissez un dataframe, vous obtiendrez également un dataframe en sortie.\n",
    "\n",
    "### Entrée creuse\n",
    "\n",
    "Pour les entrées creuses, les données sont converties en représentation Compressed Sparse Rows (CSR) (voir `scipy.sparse.csr_matrix`) avant d'être passées à l'échantillonneur. Pour éviter les copies inutiles en mémoire, il est recommandé de choisir la représentation CSR en amont."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='problem-statement-regarding-imbalanced-data-sets'></a> E1.1.2. **Problème lié aux jeux de données déséquilibrés**<br/>([_Problem statement regarding imbalanced data sets_](https://imbalanced-learn.org/stable/introduction.html#problem-statement-regarding-imbalanced-data-sets))\n",
    "\n",
    "La phase d'apprentissage et la prédiction ultérieure des algorithmes d'apprentissage automatique peuvent être affectées par le problème des jeux de données déséquilibrés. Ce problème d'équilibrage correspond à la différence du nombre d'échantillons dans les différentes classes. Nous illustrons l'effet de l'apprentissage d'un classificateur SVM linéaire avec différents niveaux d'équilibrage des classes.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_001.png\"\n",
    "    alt=\"Fonction de décision du LogisticRegression\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Comme prévu, la fonction de décision du SVM linéaire varie considérablement en fonction du déséquilibre des données. Avec un ratio de déséquilibre plus élevé, la fonction de décision favorise la classe avec le plus grand nombre d'échantillons, généralement appelée classe dominante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='over-sampling'></a> E1.2. **Sur-échantillonnage**<br/>([_Over-sampling_](https://imbalanced-learn.org/stable/over_sampling.html#over-sampling))\n",
    "\n",
    "## <a id='a-practical-guide'></a> E1.2.1. **Guide pratique**<br/>([_A practical guide_](https://imbalanced-learn.org/stable/over_sampling.html#a-practical-guide))\n",
    "\n",
    "Vous pouvez vous référer à l'exemple [**Comparer les échantillonneurs de sur-échantillonnage**](https://imbalanced-learn.org/stable/auto_examples/over-sampling/plot_comparison_over_sampling.html).\n",
    "\n",
    "### <a id='naive-random-over-sampling'></a> E1.2.1.1. **Sur-échantillonnage aléatoire naïf**<br/>([_Sur-échantillonnage aléatoire naïf_](https://imbalanced-learn.org/stable/over_sampling.html#naive-random-over-sampling))\n",
    "\n",
    "Une manière de lutter contre ce problème est de générer de nouveaux échantillons pour les classes qui sont sous-représentées. La stratégie la plus naïve consiste à générer de nouveaux échantillons en échantillonnant aléatoirement avec remplacement des échantillons actuellement disponibles. Le [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) propose un tel schéma :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4674), (1, 4674), (2, 4674)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(\n",
    "    n_samples=5000, n_features=2, n_informative=2,\n",
    "    n_redundant=0, n_repeated=0, n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.01, 0.05, 0.94],\n",
    "    class_sep=0.8, random_state=0)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4674), (1, 4674), (2, 4674)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble de données augmenté doit être utilisé à la place de l'ensemble de données d'origine pour entraîner un classifieur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "# LogisticRegression(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la figure ci-dessous, nous comparons les fonctions de décision d'un classifieur entraîné en utilisant l'ensemble de données sur-échantillonné et l'ensemble de données d'origine.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_002.png\"\n",
    "    alt=\"Fonction de décision de LogisticRegression\"\n",
    "    style=\"max-width: 75%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "En conséquence, la classe majoritaire ne prend pas le dessus sur les autres classes pendant le processus d'entraînement. Par conséquent, toutes les classes sont représentées par la fonction de décision.\n",
    "\n",
    "De plus, le [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) permet d'échantillonner des données hétérogènes (par exemple, contenant des chaînes de caractères) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['xxx' 1 1.0]\n",
      " ['yyy' 2 2.0]\n",
      " ['zzz' 3 3.0]\n",
      " ['zzz' 3 3.0]]\n",
      "[0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_hetero = np.array(\n",
    "    [['xxx', 1, 1.0], ['yyy', 2, 2.0], ['zzz', 3, 3.0]],\n",
    "    dtype=object\n",
    ")\n",
    "y_hetero = np.array([0, 0, 1])\n",
    "X_resampled, y_resampled = ros.fit_resample(X_hetero, y_hetero)\n",
    "print(X_resampled)\n",
    "# [['xxx' 1 1.0]\n",
    "#  ['yyy' 2 2.0]\n",
    "#  ['zzz' 3 3.0]\n",
    "#  ['zzz' 3 3.0]]\n",
    "print(y_resampled)\n",
    "# [0 0 1 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il fonctionnerait également avec un dataframe pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "0   25    Private  226802          11th              7       Never-married   \n",
       "1   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
       "4   18        NaN  103497  Some-college             10       Never-married   \n",
       "\n",
       "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                NaN    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  \n",
       "0              40  United-States  \n",
       "1              50  United-States  \n",
       "2              40  United-States  \n",
       "3              40  United-States  \n",
       "4              30  United-States  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "df_adult, y_adult = fetch_openml(\n",
    "    'adult', version=2, as_frame=True, return_X_y=True, parser='auto')\n",
    "df_adult.head()  \n",
    "df_resampled, y_resampled = ros.fit_resample(df_adult, y_adult)\n",
    "df_resampled.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la répétition d'échantillons pose problème, le paramètre `shrinkage` permet de créer un bootstrap lissé. Cependant, les données d'origine doivent être numériques. Le paramètre `shrinkage` contrôle la dispersion des nouveaux échantillons générés. Nous montrons un exemple illustrant que les nouveaux échantillons ne se chevauchent plus une fois qu'un bootstrap lissé est utilisé. Cette manière de générer un bootstrap lissé est également connue sous le nom d'Exemples de Sur-Échantillonnage Aléatoire (ROSE) [MT14].\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_003.png\"\n",
    "    alt=\"Rééchantillonnage avec RandomOverSampler\"\n",
    "    style=\"max-width: 75%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='from-random-over-sampling-to-smote-and-adasyn'></a> E1.2.1.2. **Du sur-échantillonnage aléatoire à SMOTE et ADASYN**<br/>([_From random over-sampling to SMOTE and ADASYN_](https://imbalanced-learn.org/stable/over_sampling.html#from-random-over-sampling-to-smote-and-adasyn))\n",
    "\n",
    "Outre l'échantillonnage aléatoire avec remplacement, il existe deux méthodes populaires pour sur-échantillonner les classes minoritaires : (i) la technique de sur-échantillonnage synthétique des classes minoritaires (SMOTE - _Synthetic Minority Oversampling Technique_) [CBHK02] et (ii) la méthode d'échantillonnage synthétique adaptatif (ADASYN - _Adaptive Synthetic_) [HBGL08]. Ces algorithmes peuvent être utilisés de la même manière :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4674), (1, 4674), (2, 4674)]\n",
      "[(0, 4673), (1, 4662), (2, 4674)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4674), (1, 4674), (2, 4674)]\n",
    "clf_smote = LogisticRegression().fit(X_resampled, y_resampled)\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4673), (1, 4662), (2, 4674)]\n",
    "clf_adasyn = LogisticRegression().fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figure ci-dessous illustre la principale différence entre les différentes méthodes de sur-échantillonnage.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_004.png\"\n",
    "    alt=\"Comparaison des méthodes de sur-échantillonnage\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='ill-posed-examples'></a> E1.2.1.3. **Exemples de problèmes mal posés**<br/>([_Ill-posed examples_](https://imbalanced-learn.org/stable/over_sampling.html#ill-posed-examples))\n",
    "\n",
    "Tandis que le [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) effectue le sur-échantillonnage en dupliquant certains des échantillons originaux de la classe minoritaire, [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) et [**`ADASYN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#imblearn.over_sampling.ADASYN) génèrent de nouveaux échantillons par interpolation. Cependant, les échantillons utilisés pour l'interpolation/la génération de nouveaux échantillons synthétiques diffèrent. En effet, [**`ADASYN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#imblearn.over_sampling.ADASYN) se concentre sur la génération, à l'aide d'un classifieur k-NN, d'échantillons proches des échantillons originaux mal classés, tandis que l'implémentation de base de [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) ne fait aucune distinction entre les échantillons faciles et difficiles à classer suivant la règle des voisins les plus proches. Par conséquent, la fonction de décision trouvée lors de l'entraînement sera différente entre les deux algorithmes.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_005.png\"\n",
    "    alt=\"Comparaison ADASYN, SMOTE et absence de ré-échantillonnage\"\n",
    "    style=\"max-width: 75%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Les particularités de l'échantillonnage de ces deux algorithmes peuvent entraîner des comportements particuliers, comme le montre l'exemple ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_006.png\"\n",
    "    alt=\"Particularités de la sur-échantillonnage avec SMOTE et ADASYN\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='smote-variants'></a> E1.2.1.4. **Variantes de SMOTE**<br/>([_SMOTE variants_](https://imbalanced-learn.org/stable/over_sampling.html#smote-variants))\n",
    "\n",
    "SMOTE pourrait connecter des valeurs aberrantes (outliers) avec les valeurs atypiques (inliers), tandis qu'ADASYN pourrait se concentrer uniquement sur les valeurs aberrantes, ce qui, dans les deux cas, pourrait conduire à une fonction de décision sous-optimale. À cet égard, SMOTE propose trois options supplémentaires pour générer des échantillons. Ces méthodes se concentrent sur les échantillons proches de la frontière de la fonction de décision optimale et généreront des échantillons dans la direction opposée à la classe des voisins les plus proches. Ces variantes sont présentées dans la figure ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_over_sampling_007.png\"\n",
    "    alt=\"Fonction de décision et ré-échantillonnage à l'aide des variantes de SMOTE\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Les algorithmes [**`BorderlineSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html#imblearn.over_sampling.BorderlineSMOTE) [HWM05], [**`SVMSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SVMSMOTE.html#imblearn.over_sampling.SVMSMOTE) [NCK09], et [**`KMeansSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.KMeansSMOTE.html#imblearn.over_sampling.KMeansSMOTE) [LDB17] sont des variantes de l'algorithme SMOTE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4674), (1, 4674), (2, 4674)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4674), (1, 4674), (2, 4674)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'il s'agit de données mixtes, telles que des caractéristiques continues et catégorielles, aucune des méthodes présentées (à l'exception de la classe [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler)) ne peut traiter les caractéristiques catégorielles. La [**`SMOTENC`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) [CBHK02] est une extension de l'algorithme SMOTE qui traite différemment les données catégorielles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 20), (1, 30)]\n"
     ]
    }
   ],
   "source": [
    "# create a synthetic data set with continuous and categorical features\n",
    "rng = np.random.RandomState(42)\n",
    "n_samples = 50\n",
    "X = np.empty((n_samples, 3), dtype=object)\n",
    "X[:, 0] = rng.choice(['A', 'B', 'C'], size=n_samples).astype(object)\n",
    "X[:, 1] = rng.randn(n_samples)\n",
    "X[:, 2] = rng.randint(3, size=n_samples)\n",
    "y = np.array([0] * 20 + [1] * 30)\n",
    "print(sorted(Counter(y).items()))\n",
    "# [(0, 20), (1, 30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce jeu de données, les première et dernière caractéristiques sont considérées comme des caractéristiques catégorielles. Il est nécessaire de fournir cette information à [**`SMOTENC`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) via les paramètres `categorical_features`, que ce soit en passant les indices, les noms des caractéristiques lorsque `X` est un DataFrame pandas, un masque booléen marquant ces caractéristiques, ou en se basant sur l'inférence du type (`dtype`) si les colonnes utilisent le [**`pandas.CategoricalDtype`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.CategoricalDtype.html#pandas.CategoricalDtype) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 30), (1, 30)]\n",
      "[['A' 0.5246469549655818 2]\n",
      " ['B' -0.3657680728116921 2]\n",
      " ['B' 0.9344237230779993 2]\n",
      " ['B' 0.3710891618824609 2]\n",
      " ['B' 0.3327240726719727 2]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "smote_nc = SMOTENC(categorical_features=[0, 2], random_state=0)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 30), (1, 30)]\n",
    "print(X_resampled[-5:])\n",
    "# [['A' 0.5246469549655818 2]\n",
    "# ['B' -0.3657680728116921 2]\n",
    "# ['B' 0.9344237230779993 2]\n",
    "# ['B' 0.3710891618824609 2]\n",
    "# ['B' 0.3327240726719727 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par conséquent, on peut voir que les échantillons générés dans les première et dernière colonnes appartiennent aux mêmes catégories que celles présentées initialement sans aucune interpolation supplémentaire.\n",
    "\n",
    "Cependant, [**`SMOTENC`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) ne fonctionne que lorsque les données sont constituées d'une combinaison de caractéristiques numériques et catégorielles. Si les données sont composées uniquement de données catégorielles, on peut utiliser la variante [**`SMOTEN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTEN.html#imblearn.over_sampling.SMOTEN) [CBHK02]. L'algorithme change de deux manières :\n",
    "- La recherche des voisins les plus proches ne repose pas sur la distance euclidienne. En effet, la métrique de différence de valeur (VDM - _Value Difference Metric_), également implémentée dans la classe `ValueDifferenceMetric`, est utilisée.\n",
    "- Un nouvel échantillon est généré où chaque valeur de caractéristique correspond à la catégorie la plus courante observée dans les échantillons voisins appartenant à la même classe.\n",
    "\n",
    "Prenons l'exemple suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([\"green\"] * 5 + [\"red\"] * 10 + [\"blue\"] * 7,\n",
    "             dtype=object).reshape(-1, 1)\n",
    "y = np.array([\"apple\"] * 5 + [\"not apple\"] * 3 + [\"apple\"] * 7 +\n",
    "             [\"not apple\"] * 5 + [\"apple\"] * 2, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous générons un jeu de données associant une couleur au fait d'être ou non une pomme. Nous associons fortement `\"green\"` et `\"red\"` au fait d'être une pomme. La classe minoritaire étant `\"not apple\"`, nous nous attendons à ce que de nouvelles données générées appartiennent à la catégorie `\"bleu\"` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not apple', 'not apple', 'not apple', 'not apple', 'not apple',\n",
       "       'not apple'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTEN\n",
    "sampler = SMOTEN(random_state=0)\n",
    "X_res, y_res = sampler.fit_resample(X, y)\n",
    "X_res[y.size:]\n",
    "y_res[y.size:]\n",
    "# array(['not apple', 'not apple', 'not apple', 'not apple', 'not apple',\n",
    "#        'not apple'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='mathematical-formulation'></a> E1.2.2. **Formulation mathématique**<br/>([_Mathematical formulation_](https://imbalanced-learn.org/stable/over_sampling.html#mathematical-formulation))\n",
    "\n",
    "### <a id='sample-generation'></a> E1.2.2.1. **Génération d'échantillons**<br/>([_Sample generation_](https://imbalanced-learn.org/stable/over_sampling.html#sample-generation))\n",
    "\n",
    "[**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) et [**`ADASYN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#imblearn.over_sampling.ADASYN) utilisent le même algorithme pour générer de nouveaux échantillons. En considérant un échantillon $x_i$, un nouvel échantillon $x_{new}$ sera généré en prenant en compte ses $k$ plus proches voisins (correspondant à `k_neighbors`). Par exemple, les 3 plus proches voisins sont inclus dans le cercle bleu comme illustré dans la figure ci-dessous. Ensuite, l'un de ces plus proches voisins $x_{zi}$ est sélectionné et un échantillon est généré comme suit :\n",
    "\n",
    "$$x_{new} = x_i + \\lambda \\times (x_{zi} - x_i)$$\n",
    "\n",
    "où $\\lambda$ est un nombre aléatoire dans la plage $[0, 1]$. Cette interpolation créera un échantillon sur la ligne entre $x_i$ et $x_{zi}$, comme illustré dans l'image ci-dessous :\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_illustration_generation_sample_001.png\"\n",
    "    alt=\"Stratégie d'échantillonnage\"\n",
    "    style=\"max-width: 30%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "SMOTE-NC change légèrement la manière dont un nouvel échantillon est généré en effectuant quelque chose de spécifique pour les caractéristiques catégorielles. En fait, les catégories d'un nouvel échantillon généré sont décidées en choisissant la catégorie la plus fréquente parmi les voisins les plus proches présents lors de la génération.\n",
    "\n",
    "> **Avertissement** Soyez conscient que SMOTE-NC n'est pas conçu pour fonctionner uniquement avec des données catégorielles.\n",
    "\n",
    "Les autres variantes de SMOTE et ADASYN diffèrent les unes des autres en sélectionnant les échantillons $x_i$ avant de générer les nouveaux échantillons.\n",
    "\n",
    "Le SMOTE **régulier** - cf. l'objet [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) - n'impose aucune règle et choisira de manière aléatoire tous les $x_i$ possibles disponibles.\n",
    "\n",
    "Le SMOTE **borderline** - cf. [**`BorderlineSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html#imblearn.over_sampling.BorderlineSMOTE) avec les paramètres `kind='borderline-1'` et `kind='borderline-2'` - classe chaque échantillon $x_i$ comme (i) du bruit (c'est-à-dire que tous les voisins les plus proches sont d'une classe différente de celle de $x_i$), (ii) en danger (c'est-à-dire qu'au moins la moitié des voisins les plus proches sont de la même classe que $x_i$), ou (iii) sûr (c'est-à-dire que tous les voisins les plus proches sont de la même classe que $x_i$). Le SMOTE **Borderline-1** et **Borderline-2** utilise les échantillons en danger pour générer de nouveaux échantillons. Dans le **Borderline-1** SMOTE, $x_{zi}$ appartient à la même classe que celle de l'échantillon $x_i$. En revanche, le **Borderline-2** SMOTE prend en compte $x_{zi}$ qui peut être de n'importe quelle classe.\n",
    "\n",
    "Le SMOTE **SVM** - cf. [**`SVMSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SVMSMOTE.html#imblearn.over_sampling.SVMSMOTE) - utilise un classifieur SVM pour trouver des vecteurs de support et génère des échantillons en les prenant en compte. Notez que le paramètre `C` du classifieur SVM permet de sélectionner plus ou moins de vecteurs de support.\n",
    "\n",
    "Pour le SMOTE borderline et SVM, un voisinage est défini à l'aide du paramètre `m_neighbors` pour décider si un échantillon est en danger, sûr ou du bruit.\n",
    "\n",
    "Le SMOTE **KMeans** - cf. [**`KMeansSMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.KMeansSMOTE.html#imblearn.over_sampling.KMeansSMOTE) - utilise une méthode de regroupement KMeans avant d'appliquer le SMOTE. Le regroupement regroupe des échantillons ensemble et génère de nouveaux échantillons en fonction de la densité de la grappe.\n",
    "\n",
    "ADASYN fonctionne de manière similaire au SMOTE régulier. Cependant, le nombre d'échantillons générés pour chaque échantillon est proportionnel au nombre d'échantillons qui ne sont pas de la même classe que dans un voisinage donné. Par conséquent, plus d'échantillons seront générés dans la zone où la règle du voisinage le plus proche n'est pas respectée. Le paramètre `m_neighbors` est équivalent à `k_neighbors` dans [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='multi-class-management'></a> E1.2.2.2. **Gestion multi-classes**<br/>([_Multi-class management_](https://imbalanced-learn.org/stable/over_sampling.html#multi-class-management))\n",
    "\n",
    "Tous les algorithmes peuvent être utilisés tant avec des classes multiples qu'avec une classification binaire. [**`RandomOverSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) ne nécessite aucune information inter-classes lors de la génération d'échantillons. Par conséquent, chaque classe cible est ré-échantillonnée indépendamment. En revanche, [**`ADASYN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html#imblearn.over_sampling.ADASYN) et [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) ont besoin d'informations concernant le voisinage de chaque échantillon utilisé pour la génération d'échantillons. Ils utilisent une approche un-contre-tous (OvR) en sélectionnant chaque classe cible et en calculant les statistiques nécessaires par rapport au reste du jeu de données, qui est regroupé dans une seule classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='under-sampling'></a> E1.3. **Sous-échantillonnage**<br/>([_Under-sampling_](https://imbalanced-learn.org/stable/under_sampling.html#under-sampling))\n",
    "\n",
    "Vous pouvez vous référer à l'exemple [**Comparaison des échantillonneurs de sous-échantillonnage**](https://imbalanced-learn.org/stable/auto_examples/under-sampling/plot_comparison_under_sampling.html#sphx-glr-auto-examples-under-sampling-plot-comparison-under-sampling-py).\n",
    "\n",
    "## <a id='prototype-generation'></a> E1.3.1. **Génération de prototypes**<br/>([_Prototype generation_](https://imbalanced-learn.org/stable/under_sampling.html#prototype-generation))\n",
    "\n",
    "Étant donné un jeu de données original $S$, les algorithmes de génération de prototypes génèrent un nouvel ensemble $S'$ où $|S'| < |S|$ et $S' \\not\\subset S$. En d'autres termes, la technique de génération de prototypes réduit le nombre d'échantillons dans les classes ciblées, mais les échantillons restants sont générés, et non sélectionnés, à partir de l'ensemble d'origine.\n",
    "\n",
    "[**`ClusterCentroids`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.ClusterCentroids.html#imblearn.under_sampling.ClusterCentroids) utilise K-means pour réduire le nombre d'échantillons. Par conséquent, chaque classe est synthétisée avec les centroïdes de la méthode K-means au lieu des échantillons d'origine :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 262), (2, 4674)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 64), (2, 64)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(\n",
    "    n_samples=5000, n_features=2, n_informative=2,\n",
    "    n_redundant=0, n_repeated=0, n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.01, 0.05, 0.94],\n",
    "    class_sep=0.8, random_state=0\n",
    ")\n",
    "print(sorted(Counter(y).items()))\n",
    "# [(0, 64), (1, 262), (2, 4674)]\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_resampled, y_resampled = cc.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 64), (2, 64)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figure ci-dessous illustre un tel sous-échantillonnage.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_under_sampling_001.png\"\n",
    "    alt=\"Resampling avec ClusterCentroids\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "[**`ClusterCentroids`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.ClusterCentroids.html#imblearn.under_sampling.ClusterCentroids) offre un moyen efficace de représenter la grappe de données avec un nombre réduit d'échantillons. Gardez à l'esprit que cette méthode nécessite que vos données soient regroupées en grappes. De plus, le nombre de centroïdes doit être défini de manière à ce que les grappes sous-échantillonnées soient représentatives de l'originale.\n",
    "\n",
    "> **Avertissement** [**`ClusterCentroids`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.ClusterCentroids.html#imblearn.under_sampling.ClusterCentroids) prend en charge les matrices creuses. Cependant, les nouveaux échantillons générés ne sont pas spécifiquement creux. Par conséquent, même si la matrice résultante est creuse, l'algorithme est inefficace à cet égard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='prototype-selection'></a> E1.3.2. **Sélection de prototypes**<br/>([_Prototype selection_](https://imbalanced-learn.org/stable/under_sampling.html#prototype-selection))\n",
    "\n",
    "Contrairement aux algorithmes de génération de prototypes, les algorithmes de sélection de prototypes sélectionnent des échantillons à partir de l'ensemble d'origine $S$. Par conséquent, $S'$ est défini de telle sorte que $|S'| < |S|$ et $S' \\subset S$.\n",
    "\n",
    "De plus, ces algorithmes peuvent être divisés en deux groupes :\n",
    "- (i) les techniques de sous-échantillonnage contrôlées et\n",
    "- (ii) les techniques de sous-échantillonnage de nettoyage.\n",
    "\n",
    "Le premier groupe de méthodes permet une stratégie de sous-échantillonnage dans laquelle le nombre d'échantillons dans $S'$ est spécifié par l'utilisateur. En revanche, les techniques de sous-échantillonnage de nettoyage n'autorisent pas cette spécification et sont destinées au nettoyage de l'espace des caractéristiques.\n",
    "\n",
    "### <a id='controlled-under-sampling-techniques'></a> E1.3.2.1. **Techniques de sous-échantillonnage contrôlé**<br/>([_Controlled under-sampling techniques_](https://imbalanced-learn.org/stable/under_sampling.html#controlled-under-sampling-techniques))\n",
    "\n",
    "[**`RandomUnderSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler) est un moyen rapide et simple d'équilibrer les données en sélectionnant de manière aléatoire un sous-ensemble de données pour les classes ciblées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 64), (2, 64)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 64), (2, 64)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`RandomUnderSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler) permet de réaliser un échantillonnage avec remplacement des données en définissant `replacement` sur `True`. Le ré-échantillonnage avec plusieurs classes est effectué en considérant indépendamment chaque classe ciblée :\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_under_sampling_002.png\"\n",
    "    alt=\"Ré-échantillonnage avec RandomUnderSampler\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 2)\n",
      "(181, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.vstack([tuple(row) for row in X_resampled]).shape)\n",
    "# (192, 2)\n",
    "rus = RandomUnderSampler(random_state=0, replacement=True)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "print(np.vstack(np.unique([tuple(row) for row in X_resampled], axis=0)).shape)\n",
    "# (181, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, [**`RandomUnderSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler) permet d'échantillonner des données hétérogènes (par exemple, contenant des chaînes de caractères)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['xxx' 1 1.0]\n",
      " ['zzz' 3 3.0]]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "X_hetero = np.array(\n",
    "    [['xxx', 1, 1.0], ['yyy', 2, 2.0], ['zzz', 3, 3.0]],\n",
    "    dtype=object\n",
    ")\n",
    "y_hetero = np.array([0, 0, 1])\n",
    "X_resampled, y_resampled = rus.fit_resample(X_hetero, y_hetero)\n",
    "print(X_resampled)\n",
    "# [['xxx' 1 1.0]\n",
    "#  ['zzz' 3 3.0]]\n",
    "print(y_resampled)\n",
    "# [0 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il fonctionnerait également avec un dataframe pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>201101.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27844</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>188950.0</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39877</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>282604.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42144</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>174419.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27199</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>236592.0</td>\n",
       "      <td>12th</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age workclass    fnlwgt     education  education-num  \\\n",
       "3582   29.0   Private  201101.0       HS-grad            9.0   \n",
       "27844  23.0   Private  188950.0     Assoc-voc           11.0   \n",
       "39877  24.0   Private  282604.0  Some-college           10.0   \n",
       "42144  29.0   Private  174419.0       HS-grad            9.0   \n",
       "27199  20.0   Private  236592.0          12th            8.0   \n",
       "\n",
       "           marital-status         occupation    relationship   race     sex  \\\n",
       "3582   Married-civ-spouse  Machine-op-inspct         Husband  White    Male   \n",
       "27844       Never-married              Sales       Own-child  White    Male   \n",
       "39877  Married-civ-spouse    Protective-serv  Other-relative  White    Male   \n",
       "42144       Never-married      Other-service       Unmarried  White  Female   \n",
       "27199       Never-married     Prof-specialty   Not-in-family  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  \n",
       "3582            0.0           0.0            50.0  United-States  \n",
       "27844           0.0           0.0            40.0  United-States  \n",
       "39877           0.0           0.0            24.0  United-States  \n",
       "42144           0.0           0.0            30.0  United-States  \n",
       "27199           0.0           0.0            35.0          Italy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "df_adult, y_adult = fetch_openml('adult', version=2, as_frame=True, return_X_y=True)\n",
    "df_adult.head()  \n",
    "df_resampled, y_resampled = rus.fit_resample(df_adult, y_adult)\n",
    "df_resampled.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`NearMiss`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html#imblearn.under_sampling.NearMiss) ajoute quelques règles heuristiques pour sélectionner des échantillons [MZ03]. [**`NearMiss`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html#imblearn.under_sampling.NearMiss) implémente 3 types différents d'heuristiques qui peuvent être sélectionnés avec le paramètre `version` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 64), (2, 64)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "nm1 = NearMiss(version=1)\n",
    "X_resampled_nm1, y_resampled = nm1.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 64), (2, 64)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme indiqué ultérieurement dans la section suivante, les règles heuristiques de [**`NearMiss`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html#imblearn.under_sampling.NearMiss) sont basées sur l'algorithme des plus proches voisins. Par conséquent, les paramètres `n_neighbors` et `n_neighbors_ver3` acceptent un classificateur dérivé de `KNeighborsMixin` de scikit-learn. Le premier paramètre est utilisé pour calculer la distance moyenne aux voisins, tandis que le second est utilisé pour la pré-sélection des échantillons d'intérêt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='mathematical-formulation'></a> E1.3.2.1.1. **Formulation mathématique**<br/>([_Mathematical formulation_](https://imbalanced-learn.org/stable/under_sampling.html#mathematical-formulation))\n",
    "\n",
    "Soient les _échantillons positifs_ les échantillons appartenant à la classe ciblée à sous-échantillonner. L'échantillon négatif désigne les échantillons de la classe minoritaire (c'est-à-dire la classe la moins représentée).\n",
    "\n",
    "NearMiss-1 sélectionne les échantillons positifs pour lesquels la distance moyenne aux $N$ échantillons les plus proches de la classe négative est la plus petite.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_illustration_nearmiss_001.png\"\n",
    "    alt=\"NearMiss-1\"\n",
    "    style=\"max-width: 30%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "NearMiss-2 sélectionne les échantillons positifs pour lesquels la distance moyenne aux $N$ échantillons les plus éloignés de la classe négative est la plus petite.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_illustration_nearmiss_002.png\"\n",
    "    alt=\"NearMiss-2\"\n",
    "    style=\"max-width: 30%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "NearMiss-3 est un algorithme en 2 étapes. Tout d'abord, pour chaque échantillon négatif, leurs $M$ plus proches voisins seront conservés. Ensuite, les échantillons positifs sélectionnés sont ceux pour lesquels la distance moyenne aux $N$ plus proches voisins est la plus grande.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_illustration_nearmiss_003.png\"\n",
    "    alt=\"NearMiss-3\"\n",
    "    style=\"max-width: 30%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Dans l'exemple suivant, les différentes variantes de [**`NearMiss`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html#imblearn.under_sampling.NearMiss) sont appliquées à l'exemple factice précédent. On peut constater que les fonctions de décision obtenues dans chaque cas sont différentes.\n",
    "\n",
    "Lors du sous-échantillonnage d'une classe spécifique, NearMiss-1 peut être altéré par la présence de bruit. En effet, cela impliquera que les échantillons de la classe ciblée seront sélectionnés autour de ces échantillons, comme c'est le cas dans l'illustration ci-dessous pour la classe jaune. Cependant, dans le cas normal, ce sont les échantillons situés près des limites qui seront sélectionnés. NearMiss-2 n'aura pas cet effet car il ne se concentre pas sur les échantillons les plus proches, mais plutôt sur les échantillons les plus éloignés. On peut imaginer que la présence de bruit peut également altérer l'échantillonnage principalement en présence de valeurs aberrantes marginales. NearMiss-3 est probablement la version la moins affectée par le bruit en raison de la sélection d'échantillons de la première étape.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_under_sampling_003.png\"\n",
    "    alt=\"NearMiss-3\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='cleaning-under-sampling-techniques'></a> E1.3.2.2. **Techniques de sous-échantillonnage de nettoyage**<br/>([_Cleaning under-sampling techniques_](https://imbalanced-learn.org/stable/under_sampling.html#cleaning-under-sampling-techniques))\n",
    "\n",
    "Les techniques de sous-échantillonnage de nettoyage ne permettent pas de spécifier le nombre d'échantillons à avoir dans chaque classe. En fait, chaque algorithme met en œuvre une heuristique qui nettoie l'ensemble de données.\n",
    "\n",
    "#### <a id='controlled-under-sampling-techniques'></a> E1.3.2.2.1. **Liens de Tomek**<br/>([_Tomek’s links_](https://imbalanced-learn.org/stable/under_sampling.html#tomek-s-links))\n",
    "\n",
    "[**`TomekLinks`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html#imblearn.under_sampling.TomekLinks) détecte les liens de Tomek [Tom76b]. Un lien de Tomek entre deux échantillons de classes différentes $x$ et $y$ est défini de telle sorte que pour n'importe quel échantillon $z$ :\n",
    "\n",
    "$$d(x, y) < d(x, z) \\text{et} d(x, y) < d(y, z)$$\n",
    "\n",
    "où $d(\\cdot)$ est la distance entre les deux échantillons. En d'autres termes, un lien de Tomek existe si les deux échantillons sont les voisins les plus proches l'un de l'autre. Dans la figure ci-dessous, un lien de Tomek est illustré en mettant en évidence les échantillons d'intérêt en vert.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_illustration_tomek_links_001.png\"\n",
    "    alt=\"NearMiss-3\"\n",
    "    style=\"max-width: 30%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Le paramètre `sampling_strategy` contrôle quel échantillon du lien est supprimé. Par exemple, la valeur par défaut (c'est-à-dire `sampling_strategy='auto'`) supprime l'échantillon de la classe majoritaire. Les échantillons des classes majoritaire et minoritaire peuvent être supprimés en définissant `sampling_strategy` sur `'all'`. La figure suivante illustre ce comportement.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_illustration_tomek_links_002.png\"\n",
    "    alt=\"NearMiss-3\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=''></a> E1.3.2.2.2. **Jeu de données édité en utilisant les voisins les plus proches**<br/>([_Edited data set using nearest neighbors_](https://imbalanced-learn.org/stable/under_sampling.html#edited-data-set-using-nearest-neighbours))\n",
    "\n",
    "[**`EditedNearestNeighbours`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html#imblearn.under_sampling.EditedNearestNeighbours) applique un algorithme de plus proches voisins et \"édite\" l'ensemble de données en supprimant les échantillons qui ne sont pas suffisamment conformes à leur voisinage [Wil72]. Pour chaque échantillon de la classe à sous-échantillonner, les voisins les plus proches sont calculés et si le critère de sélection n'est pas rempli, l'échantillon est supprimé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 213), (2, 4568)]\n"
     ]
    }
   ],
   "source": [
    "sorted(Counter(y).items())\n",
    "# [(0, 64), (1, 262), (2, 4674)]\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours()\n",
    "X_resampled, y_resampled = enn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 213), (2, 4568)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux critères de sélection sont actuellement disponibles :\n",
    "- (i) la majorité (c'est-à-dire `kind_sel='mode'`) ou\n",
    "- (ii) tous (c'est-à-dire `kind_sel='all'`) les plus proches voisins doivent appartenir à la même classe que l'échantillon inspecté pour le conserver dans l'ensemble de données.\n",
    "\n",
    "Par conséquent, cela implique que `kind_sel='all'` soit moins conservateur que `kind_sel='mode'`, et plus d'échantillons soient exclus dans la première stratégie que dans la dernière :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 213), (2, 4568)]\n",
      "[(0, 64), (1, 234), (2, 4666)]\n"
     ]
    }
   ],
   "source": [
    "enn = EditedNearestNeighbours(kind_sel=\"all\")\n",
    "X_resampled, y_resampled = enn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 213), (2, 4568)]\n",
    "enn = EditedNearestNeighbours(kind_sel=\"mode\")\n",
    "X_resampled, y_resampled = enn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 234), (2, 4666)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre `n_neighbors` permet de fournir un classificateur issu de la classe `KNeighborsMixin` de scikit-learn pour trouver les voisins les plus proches et prendre la décision de conserver ou non un échantillon donné.\n",
    "\n",
    "[**`RepeatedEditedNearestNeighbours`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RepeatedEditedNearestNeighbours.html#imblearn.under_sampling.RepeatedEditedNearestNeighbours) étend [**`EditedNearestNeighbours`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html#imblearn.under_sampling.EditedNearestNeighbours) en répétant l'algorithme plusieurs fois [Tom76a]. En général, la répétition de l'algorithme supprime davantage de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 208), (2, 4551)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "renn = RepeatedEditedNearestNeighbours()\n",
    "X_resampled, y_resampled = renn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 208), (2, 4551)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`AllKNN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.AllKNN.html#imblearn.under_sampling.AllKNN) diffère du précédent [**`RepeatedEditedNearestNeighbours`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RepeatedEditedNearestNeighbours.html#imblearn.under_sampling.RepeatedEditedNearestNeighbours) car le nombre de voisins de l'algorithme interne des voisins les plus proches est augmenté à chaque itération [Tom76a] :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 220), (2, 4601)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import AllKNN\n",
    "allknn = AllKNN()\n",
    "X_resampled, y_resampled = allknn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 220), (2, 4601)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exemple ci-dessous, on peut voir que les trois algorithmes ont un impact similaire en nettoyant les échantillons bruyants près des frontières des classes.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_under_sampling_004.png\"\n",
    "    alt=\"EditedNearestNeighbours, RepeatedEditedNearestNeighbours, AllKNN\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='condensed-nearest-neighbors-and-derived-algorithms'></a> E1.3.2.2.3. **Voisins les plus proches condensés et algorithmes dérivés**<br/>([_Condensed nearest neighbors and derived algorithms_](https://imbalanced-learn.org/stable/under_sampling.html#condensed-nearest-neighbors-and-derived-algorithms))\n",
    "\n",
    "[**`CondensedNearestNeighbour`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.CondensedNearestNeighbour.html#imblearn.under_sampling.CondensedNearestNeighbour) utilise une règle du 1 voisin le plus proche pour décider de manière itérative si un échantillon doit être supprimé ou non [Har68]. L'algorithme se déroule comme suit :\n",
    "\n",
    "1. Obtenir tous les échantillons de la classe minoritaire dans un ensemble $C$.\n",
    "2. Ajouter un échantillon de la classe cible (classe à sous-échantillonner) dans $C$ et tous les autres échantillons de cette classe dans un ensemble $S$.\n",
    "3. Parcourir l'ensemble $S$, échantillon par échantillon, et classifier chaque échantillon en utilisant une règle du 1 voisin le plus proche.\n",
    "4. Si l'échantillon est mal classifié, l'ajouter à $C$, sinon ne rien faire.\n",
    "5. Répéter sur $S$ jusqu'à ce qu'il n'y ait plus d'échantillons à ajouter.\n",
    "\n",
    "Le [**`CondensedNearestNeighbour`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.CondensedNearestNeighbour.html#imblearn.under_sampling.CondensedNearestNeighbour) peut être utilisé de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 24), (2, 115)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "cnn = CondensedNearestNeighbour(random_state=0)\n",
    "X_resampled, y_resampled = cnn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 24), (2, 115)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, comme illustré dans la figure ci-dessous, [**`CondensedNearestNeighbour`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.CondensedNearestNeighbour.html#imblearn.under_sampling.CondensedNearestNeighbour) est sensible au bruit et ajoute des échantillons bruyants.\n",
    "\n",
    "En revanche, [**`OneSidedSelection`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.OneSidedSelection.html#imblearn.under_sampling.OneSidedSelection) utilisera [**`TomekLinks`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html#imblearn.under_sampling.TomekLinks) pour supprimer les échantillons bruyants [Har68]. De plus, la règle du 1 voisin le plus proche est appliquée à tous les échantillons et ceux qui sont mal classés sont ajoutés à l'ensemble $C$. Aucune itération sur l'ensemble $S$ n'a lieu. Cette classe peut être utilisée comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 174), (2, 4404)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "X_resampled, y_resampled = oss.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 174), (2, 4404)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre implémentation permet de définir le nombre de graines à mettre initialement dans l'ensemble $C$ en définissant le paramètre `n_seeds_S`.\n",
    "\n",
    "[**`NeighbourhoodCleaningRule`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NeighbourhoodCleaningRule.html#imblearn.under_sampling.NeighbourhoodCleaningRule) se concentre davantage sur le nettoyage des données que sur leur condensation [Lau01]. Par conséquent, il utilise l'union des échantillons à rejeter entre les [**`EditedNearestNeighbours`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html#imblearn.under_sampling.EditedNearestNeighbours) et la sortie d'un classifieur à 3 voisins les plus proches. Cette classe peut être utilisée comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 234), (2, 4666)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "ncr = NeighbourhoodCleaningRule()\n",
    "X_resampled, y_resampled = ncr.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 234), (2, 4666)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_under_sampling_005.png\"\n",
    "    alt=\"CondensedNearestNeighbour, OneSidedSelection, NeighbourhoodCleaningRule\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='instance-hardness-threshold'></a> E1.3.2.2.4. **Seuil de difficulté des instances**<br/>([_Instance hardness threshold_](https://imbalanced-learn.org/stable/under_sampling.html#instance-hardness-threshold))\n",
    "\n",
    "[**`InstanceHardnessThreshold`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.InstanceHardnessThreshold.html#imblearn.under_sampling.InstanceHardnessThreshold) est un algorithme spécifique dans lequel un classifieur est entraîné sur les données et les échantillons ayant des probabilités plus faibles sont supprimés [SMGC14]. Cette classe peut être utilisée comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 64), (1, 64), (2, 64)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "iht = InstanceHardnessThreshold(\n",
    "    random_state=0,\n",
    "    estimator=LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    ")\n",
    "X_resampled, y_resampled = iht.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 64), (1, 64), (2, 64)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette classe comporte 2 paramètres importants. `estimator` accepte n'importe quel classifieur scikit-learn qui a une méthode `predict_proba`. L'entraînement du classifieur est effectué à l'aide d'une validation croisée et le paramètre `cv` peut définir le nombre de plis à utiliser.\n",
    "\n",
    "> **Note :** [**`InstanceHardnessThreshold`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.InstanceHardnessThreshold.html#imblearn.under_sampling.InstanceHardnessThreshold) pourrait presque être considéré comme une méthode de sous-échantillonnage contrôlé. Cependant, en raison des sorties de probabilité, il n'est pas toujours possible d'obtenir un nombre spécifique d'échantillons.\n",
    "\n",
    "La figure ci-dessous donne d'autres exemples sur des données fictives.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_under_sampling_006.png\"\n",
    "    alt=\"FunctionSampler, InstanceHardnessThreshold\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='combination-of-over-and-under-sampling'></a> E1.4. **Combination de sur-échantillonnage et de sous-échantillonnage**<br/>([_Combination of over- and under-sampling_](https://imbalanced-learn.org/stable/combine.html#combination-of-over-and-under-sampling))\n",
    "\n",
    "Nous avons précédemment présenté [**`SMOTE`**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE) et montré que cette méthode peut générer des échantillons bruyants en interpolant de nouveaux points entre les valeurs aberrantes marginales et les valeurs typiques. Ce problème peut être résolu en nettoyant l'espace résultant du sur-échantillonnage.\n",
    "\n",
    "À cet égard, le lien de Tomek et les voisins les plus proches modifiés sont les deux méthodes de nettoyage qui ont été ajoutées à la chaîne de traitement après l'application du sur-échantillonnage SMOTE pour obtenir un espace plus propre. Les deux classes prêtes à l'emploi implémentées par imbalanced-learn pour combiner les méthodes de sur- et sous-échantillonnage sont : (i) [**`SMOTETomek`**](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTETomek.html#imblearn.combine.SMOTETomek) [BPM04] et (ii) [**`SMOTEENN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html#imblearn.combine.SMOTEENN) [BBM03].\n",
    "\n",
    "Ces deux classes peuvent être utilisées comme tout autre échantillonneur avec des paramètres identiques à leurs échantillonneurs d'origine :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(\n",
    "    n_samples=5000, n_features=2, n_informative=2,\n",
    "    n_redundant=0, n_repeated=0, n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.01, 0.05, 0.94],\n",
    "    class_sep=0.8, random_state=0)\n",
    "print(sorted(Counter(y).items()))\n",
    "# [(0, 64), (1, 262), (2, 4674)]\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4060), (1, 4381), (2, 3502)]\n",
    "from imblearn.combine import SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "# [(0, 4499), (1, 4566), (2, 4413)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons également voir dans l'exemple ci-dessous que [**`SMOTEENN`**](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html#imblearn.combine.SMOTEENN) tend à nettoyer davantage d'échantillons bruyants que [**`SMOTETomek`**](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTETomek.html#imblearn.combine.SMOTETomek).\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://imbalanced-learn.org/stable/_images/sphx_glr_plot_comparison_combine_001.png\"\n",
    "    alt=\"SMOTEENN nettoie davantage d'échantillons bruyants que SMOTETomek\"\n",
    "    style=\"max-width: 30%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "## Exemples\n",
    "\n",
    "### [**Comparaison d'échantillonneurs combinant le sur-échantillonnage et le sous-échantillonnage**](https://imbalanced-learn.org/stable/auto_examples/combine/plot_comparison_combine.html#sphx-glr-auto-examples-combine-plot-comparison-combine-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='ensemble-of-samplers'></a> E1.5. **Échantillonneurs ensemblistes**<br/>([_Ensemble of samplers_](https://imbalanced-learn.org/stable/ensemble.html#ensemble-of-samplers))\n",
    "\n",
    "## <a id='classifier-including-inner-balancing-samplers'></a> E1.5.1. **Classifieur incluant des échantillonneurs à équilibrage internes**<br/>([_Classifier including inner balancing samplers_](https://imbalanced-learn.org/stable/ensemble.html#classifier-including-inner-balancing-samplers))\n",
    "\n",
    "### <a id='bagging-classifier'></a> E1.5.1.1. **Bagging classifier**<br/>([_Classifieur Bagging_](https://imbalanced-learn.org/stable/ensemble.html#bagging-classifier))\n",
    "\n",
    "Dans les classifieurs ensemblistes, les méthodes de bagging construisent plusieurs estimateurs sur différents sous-ensembles de données sélectionnés de manière aléatoire. Dans scikit-learn, ce classifieur est nommé **`BaggingClassifier`**. Cependant, ce classifieur ne permet pas d'équilibrer chaque sous-ensemble de données. Par conséquent, lors de l'entraînement sur un jeu de données déséquilibré, ce classifieur favorisera les classes majoritaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7739629664028289"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(\n",
    "    n_samples=10000, n_features=2, n_informative=2,\n",
    "    n_redundant=0, n_repeated=0, n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.01, 0.05, 0.94], class_sep=0.8,\n",
    "    random_state=0)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "bc = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(),\n",
    "    random_state=0)\n",
    "bc.fit(X_train, y_train) #doctest:\n",
    "y_pred = bc.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "# 0.77.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le [**`BalancedBaggingClassifier`**](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedBaggingClassifier.html#imblearn.ensemble.BalancedBaggingClassifier), chaque échantillon bootstrap sera encore rééchantillonné pour atteindre la `sampling_strategy` souhaitée. Par conséquent, [**`BalancedBaggingClassifier`**](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedBaggingClassifier.html#imblearn.ensemble.BalancedBaggingClassifier) prend les mêmes paramètres que **`BaggingClassifier`** de scikit-learn. De plus, l'échantillonnage est contrôlé par le paramètre `sampler` ou les deux paramètres `sampling_strategy` et `replacement`, si l'on souhaite utiliser le [**`RandomUnderSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\ensemble\\_bagging.py:362: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8251353587264241"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "bbc = BalancedBaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(),\n",
    "    sampling_strategy='auto',\n",
    "    replacement=False,\n",
    "    random_state=0)\n",
    "bbc.fit(X_train, y_train)\n",
    "y_pred = bbc.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "# 0.8..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changer le `sampler` donnera lieu à différentes implémentations connues [MO97], [HKT09], [WY09]. Vous pouvez vous référer à l'exemple suivant qui montre en pratique ces différentes méthodes : [**Classifieurs de bagging utilisant un échantillonneur**](https://imbalanced-learn.org/stable/auto_examples/ensemble/plot_bagging_classifier.html#sphx-glr-auto-examples-ensemble-plot-bagging-classifier-py).\n",
    "\n",
    "### <a id='forest-of-randomized-trees'></a> E1.5.1.2. **Forest of randomized trees**<br/>([_Forêt d'arbres aléatoires_](https://imbalanced-learn.org/stable/ensemble.html#forest-of-randomized-trees))\n",
    "\n",
    "[**`BalancedRandomForestClassifier`**](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedRandomForestClassifier.html#imblearn.ensemble.BalancedRandomForestClassifier) est une autre méthode ensembliste dans laquelle chaque arbre de la forêt recevra un échantillon bootstrap équilibré [CLB+04]. Cette classe offre toutes les fonctionnalités de **`RandomForestClassifier`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8299918475176207"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brf = BalancedRandomForestClassifier(\n",
    "    n_estimators=100, random_state=0, sampling_strategy=\"all\", replacement=True\n",
    ")\n",
    "brf.fit(X_train, y_train)\n",
    "y_pred = brf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "# 0.8..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='boosting'></a> E1.5.1.3. **Boosting**<br/>([_Boosting_](https://imbalanced-learn.org/stable/ensemble.html#forest-of-randomized-trees))\n",
    "\n",
    "Plusieurs méthodes exploitant le boosting ont été conçues.\n",
    "\n",
    "[**`RUSBoostClassifier`**](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.RUSBoostClassifier.html#imblearn.ensemble.RUSBoostClassifier) sous-échantillonne de manière aléatoire le jeu de données avant d'effectuer une itération de boosting [SKVHN09]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.595736286114293"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "rusboost = RUSBoostClassifier(\n",
    "    n_estimators=200, algorithm='SAMME.R', random_state=0\n",
    ")\n",
    "rusboost.fit(X_train, y_train)\n",
    "y_pred = rusboost.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une méthode spécifique qui utilise **`AdaBoostClassifier`** comme apprenants dans le classifieur de bagging s'appelle \"EasyEnsemble\". L'[**`EasyEnsembleClassifier`**](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.EasyEnsembleClassifier.html#imblearn.ensemble.EasyEnsembleClassifier) permet de regrouper les apprenants AdaBoost qui sont entraînés sur des échantillons bootstrap équilibrés [LWZ08]. De manière similaire à l'API de [**`BalancedBaggingClassifier`**](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedBaggingClassifier.html#imblearn.ensemble.BalancedBaggingClassifier), on peut construire l'ensemble de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6248477859302602"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "eec = EasyEnsembleClassifier(random_state=0)\n",
    "eec.fit(X_train, y_train)\n",
    "y_pred = eec.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "# 0.6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### Comparer les classifieurs ensemblistes en utilisant le ré-échantillonnage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='miscellaneous-samplers'></a> E1.6. **Échantillonneurs divers**<br/>([_Miscellaneous samplers_](https://imbalanced-learn.org/stable/miscellaneous.html#miscellaneous-samplers))\n",
    "\n",
    "## <a id='custom-samplers'></a> E1.6.1. **Échantillonneurs personnalisés**<br/>([_Custom samplers_](https://imbalanced-learn.org/stable/miscellaneous.html#custom-samplers))\n",
    "\n",
    "Un échantillonneur entièrement personnalisé, [**`FunctionSampler`**](https://imbalanced-learn.org/stable/references/generated/imblearn.FunctionSampler.html#imblearn.FunctionSampler), est disponible dans imbalanced-learn. Il vous permet de prototyper rapidement votre propre échantillonneur en définissant une seule fonction. Des paramètres supplémentaires peuvent être ajoutés en utilisant l'attribut `kw_args`, qui accepte un dictionnaire. L'exemple suivant illustre comment conserver les 10 premiers éléments du tableau `X` et `y` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn import FunctionSampler\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(\n",
    "    n_samples=5000, n_features=2, n_informative=2,\n",
    "    n_redundant=0, n_repeated=0, n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.01, 0.05, 0.94],\n",
    "    class_sep=0.8, random_state=0\n",
    ")\n",
    "def func(X, y):\n",
    "    return X[:10], y[:10]\n",
    "sampler = FunctionSampler(func=func)\n",
    "X_res, y_res = sampler.fit_resample(X, y)\n",
    "np.all(X_res == X[:10])\n",
    "np.all(y_res == y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, le paramètre `validate` contrôle la vérification des entrées. Par exemple, en définissant `validate=False`, vous pouvez passer n'importe quel type de cible `y` et effectuer un échantillonnage pour les cibles de régression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41.49112498, -142.78526195,   85.55095317,  141.43321419,\n",
       "         75.46571114,  -67.49177372,  159.72700509, -169.80498923,\n",
       "        211.95889757,  211.95889757])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X_reg, y_reg = make_regression(n_samples=100, random_state=42)\n",
    "rng = np.random.RandomState(42)\n",
    "def dummy_sampler(X, y):\n",
    "    indices = rng.choice(np.arange(X.shape[0]), size=10)\n",
    "    return X[indices], y[indices]\n",
    "sampler = FunctionSampler(func=dummy_sampler, validate=False)\n",
    "X_res, y_res = sampler.fit_resample(X_reg, y_reg)\n",
    "y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons illustré l'utilisation de cet échantillonneur pour mettre en œuvre un estimateur de rejet des valeurs aberrantes qui peut être facilement utilisé dans un [**`Pipeline`**](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html#imblearn.pipeline.Pipeline) : **Échantillonneur personnalisé pour mettre en œuvre un estimateur de rejet des valeurs aberrantes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='custom-generators'></a> E1.6.2. **Générateurs personnalisés**<br/>([_Custom generators_](https://imbalanced-learn.org/stable/miscellaneous.html#custom-generators))\n",
    "\n",
    "Imbalanced-learn propose des générateurs spécifiques pour TensorFlow et Keras qui généreront des mini-lots équilibrés.\n",
    "\n",
    "### <a id='tensorflow-generator'></a> E1.6.2.1. **Générateur TensorFlow**<br/>([_TensorFlow generator_](https://imbalanced-learn.org/stable/miscellaneous.html#tensorflow-generator))\n",
    "\n",
    "Le [**`balanced_batch_generator`**](https://imbalanced-learn.org/stable/references/generated/imblearn.tensorflow.balanced_batch_generator.html#imblearn.tensorflow.balanced_batch_generator) permet de générer des mini-lots équilibrés en utilisant un échantillonneur imbalanced-learn qui renvoie des indices.\n",
    "\n",
    "Commençons par générer des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features, n_classes = 10, 2\n",
    "X, y = make_classification(\n",
    "    n_samples=10_000, n_features=n_features, n_informative=2,\n",
    "    n_redundant=0, n_repeated=0, n_classes=n_classes,\n",
    "    n_clusters_per_class=1, weights=[0.1, 0.9],\n",
    "    class_sep=0.8, random_state=0\n",
    ")\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous pouvons créer le générateur qui produira des mini-lots équilibrés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.tensorflow import balanced_batch_generator\n",
    "training_generator, steps_per_epoch = balanced_batch_generator(\n",
    "    X,\n",
    "    y,\n",
    "    sample_weight=None,\n",
    "    sampler=RandomUnderSampler(),\n",
    "    batch_size=32,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres `generator` et `steps_per_epoch` sont utilisés lors de l'entraînement d'un modèle Tensorflow. Nous allons illustrer comment utiliser ce générateur. Tout d'abord, nous pouvons définir un modèle de régression logistique qui sera optimisé par une descente de gradient :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# initialize the weights and intercept\n",
    "normal_initializer = tf.random_normal_initializer(mean=0, stddev=0.01)\n",
    "coef = tf.Variable(normal_initializer(\n",
    "    shape=[n_features, n_classes]), dtype=\"float32\"\n",
    ")\n",
    "intercept = tf.Variable(\n",
    "    normal_initializer(shape=[n_classes]), dtype=\"float32\"\n",
    ")\n",
    "# define the model\n",
    "def logistic_regression(X):\n",
    "    return tf.nn.softmax(tf.matmul(X, coef) + intercept)\n",
    "# define the loss function\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    y_true = tf.one_hot(y_true, depth=n_classes)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
    "# define our metric\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    cm = tf.math.confusion_matrix(tf.cast(y_true, tf.int64), tf.argmax(y_pred, 1))\n",
    "    per_class = np.diag(cm) / tf.math.reduce_sum(cm, axis=1)\n",
    "    return np.mean(per_class)\n",
    "# define the optimizer\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "# define the optimization step\n",
    "def run_optimization(X, y):\n",
    "    with tf.GradientTape() as g:\n",
    "        y_pred = logistic_regression(X)\n",
    "        loss = cross_entropy(y, y_pred)\n",
    "    gradients = g.gradient(loss, [coef, intercept])\n",
    "    optimizer.apply_gradients(zip(gradients, [coef, intercept]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois initialisé, le modèle est entraîné en itérant sur des mini-lots équilibrés de données et en minimisant la perte précédemment définie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 6881.147, accuracy: 0.5421011021956641\n",
      "epoch: 1, loss: 3942.267, accuracy: 0.7999513158412606\n",
      "epoch: 2, loss: 3760.627, accuracy: 0.7970163626687475\n",
      "epoch: 3, loss: 3790.591, accuracy: 0.7998105681415657\n",
      "epoch: 4, loss: 3644.607, accuracy: 0.7986326082901678\n",
      "epoch: 5, loss: 3620.346, accuracy: 0.7973868414162727\n",
      "epoch: 6, loss: 3496.922, accuracy: 0.7888339587835976\n",
      "epoch: 7, loss: 3603.346, accuracy: 0.7958854613187674\n",
      "epoch: 8, loss: 3916.773, accuracy: 0.802113867883685\n",
      "epoch: 9, loss: 4099.809, accuracy: 0.804816737083297\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    y_pred = logistic_regression(X)\n",
    "    loss = cross_entropy(y, y_pred)\n",
    "    bal_acc = balanced_accuracy(y, y_pred)\n",
    "    print(f\"epoch: {e}, loss: {loss:.3f}, accuracy: {bal_acc}\")\n",
    "    for _ in range(steps_per_epoch):\n",
    "        X_batch, y_batch = next(training_generator)\n",
    "        run_optimization(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='keras-generator'></a> E1.6.2.2. **Générateur Keras**<br/>([_Keras generator_](https://imbalanced-learn.org/stable/miscellaneous.html#keras-generator))\n",
    "\n",
    "Keras provides an higher level API in which a model can be defined and train by calling `fit_generator` method to train the model. To illustrate, we will define a logistic regression model:\n",
    "\n",
    "---\n",
    "\n",
    "[**`balanced_batch_generator`**](https://imbalanced-learn.org/stable/references/generated/imblearn.tensorflow.balanced_batch_generator.html#imblearn.tensorflow.balanced_batch_generator) creates a balanced mini-batches generator with the associated number of mini-batches which will be generated:\n",
    "\n",
    "---\n",
    "\n",
    "Then, `fit` can be called passing the generator and the step:\n",
    "\n",
    "---\n",
    "\n",
    "The second possibility is to use [**`BalancedBatchGenerator`**](https://imbalanced-learn.org/stable/references/generated/imblearn.keras.BalancedBatchGenerator.html#imblearn.keras.BalancedBatchGenerator). Only an instance of this class will be passed to `fit`:\n",
    "\n",
    "---\n",
    "\n",
    "##  Exemple de référence\n",
    "\n",
    "**Porto Seguro: balancing samples in mini-batches with Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='keras-generator'></a> E1.6.2.2. **Générateur Keras**<br/>([_Keras generator_](https://imbalanced-learn.org/stable/miscellaneous.html#keras-generator))\n",
    "\n",
    "Keras offre une API de niveau supérieur dans laquelle un modèle peut être défini et entraîné en appelant la méthode `fit_generator` pour entraîner le modèle. Pour illustrer, nous allons définir un modèle de régression logistique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "y = keras.utils.to_categorical(y, 3)\n",
    "model = keras.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        y.shape[1], input_dim=X.shape[1], activation='softmax'\n",
    "    )\n",
    ")\n",
    "model.compile(\n",
    "    optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`balanced_batch_generator`**](https://imbalanced-learn.org/stable/references/generated/imblearn.tensorflow.balanced_batch_generator.html#imblearn.tensorflow.balanced_batch_generator) crée un générateur de mini-lots équilibrés avec le nombre associé de mini-lots qui seront générés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.keras import balanced_batch_generator\n",
    "training_generator, steps_per_epoch = balanced_batch_generator(\n",
    "    X, y, sampler=RandomUnderSampler(), batch_size=10, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, `fit` peut être appelé en passant le générateur et l'étape :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.9283 - accuracy: 0.5615\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.5909 - accuracy: 0.7575\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8099\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8138\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8181\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.8181\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8195\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8191\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4486 - accuracy: 0.8191\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8191\n"
     ]
    }
   ],
   "source": [
    "callback_history = model.fit(\n",
    "    training_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La deuxième possibilité est d'utiliser [**`BalancedBatchGenerator`**](https://imbalanced-learn.org/stable/references/generated/imblearn.keras.BalancedBatchGenerator.html#imblearn.keras.BalancedBatchGenerator). Seule une instance de cette classe sera passée à `fit` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.8183\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4401 - accuracy: 0.8197\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.8202\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4375 - accuracy: 0.8197\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8188\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8188\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8163\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8188\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 1s 2ms/step - loss: 0.4332 - accuracy: 0.8197\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8154\n"
     ]
    }
   ],
   "source": [
    "from imblearn.keras import BalancedBatchGenerator\n",
    "training_generator = BalancedBatchGenerator(\n",
    "    X, y, sampler=RandomUnderSampler(), batch_size=10, random_state=42\n",
    ")\n",
    "callback_history = model.fit(\n",
    "    training_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de référence\n",
    "\n",
    "**Porto Seguro: balancing samples in mini-batches with Keras**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
