{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='unsupervised-learning'></a> 2. [**Apprentissage non supervis√©**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_unsupervised_learning.ipynb#model-selection-and-evaluation)</br>([*Unsupervised learning*](https://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning))\n",
    "\n",
    "# 2.7. [**D√©tection de nouveaut√© et d'atypique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#novelty-and-outlier-detection)<br/>([_Novelty and Outlier Detection_](https://scikit-learn.org/stable/modules/outlier_detection.html#novelty-and-outlier-detection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 12 pages, 10 exemples, 4 papiers\n",
    "- 2.7.1. [**Aper√ßu des m√©thodes de d√©tection d'atypique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#overview-of-outlier-detection-methods)<br/>([_Overview of outlier detection methods_](https://scikit-learn.org/stable/outlier_detection.html#overview-of-outlier-detection-methods))\n",
    "- 2.7.2. [**D√©tection de nouveaut√©**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#novelty-detection)<br/>([_Novelty Detection_](https://scikit-learn.org/stable/outlier_detection.html#novelty-detection))\n",
    "- 2.7.3. [**D√©tection d'atypique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#outlier-detection)<br/>([_Outlier Detection_](https://scikit-learn.org/stable/outlier_detection.html#outlier-detection))\n",
    "- 2.7.4. [**D√©tection de nouveaut√© avec Local Outlier Factor**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#novelty-detection-with-local-outlier-factor)<br/>([_Novelty detection with Local Outlier Factor_](https://scikit-learn.org/stable/outlier_detection.html#novelty-detection-with-local-outlier-factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='novelty-and-outlier-detection'></a> 2.7. D√©tection de nouveaut√© et d'atypique\n",
    "\n",
    "De nombreuses applications n√©cessitent de pouvoir d√©cider si une nouvelle observation appartient √† la m√™me distribution que les observations existantes (elle est un _inlier_) ou si elle doit √™tre consid√©r√©e comme diff√©rente (elle est un _outlier_, ou _valeur atypique_). Souvent, cette capacit√© est utilis√©e pour nettoyer des ensembles de donn√©es r√©els. Deux distinctions importantes doivent √™tre faites :\n",
    "\n",
    "- **D√©tection d'atypiques (_Outlier Detection_) :** Les donn√©es d'entra√Ænement contiennent des valeurs atypiques, d√©finis comme des observations tr√®s √©loign√©es des autres. Les estimateurs de d√©tection d'atypique cherchent donc √† ajuster les r√©gions o√π les donn√©es d'entra√Ænement sont les plus concentr√©es, en ignorant les observations d√©viantes.\n",
    "- **D√©tection de nouveaut√© (_Novelty Detection_) :** Les donn√©es d'entra√Ænement ne sont pas pollu√©es par des atypiques, et nous cherchons √† d√©tecter si une **nouvelle** observation est un atypique. Dans ce contexte, un atypique est √©galement appel√© une nouveaut√©.\n",
    "\n",
    "La d√©tection d'atypique et la d√©tection de nouveaut√© sont toutes deux utilis√©es pour la d√©tection d'anomalies, o√π l'on s'int√©resse √† d√©tecter des observations anormales ou inhabituelles. La d√©tection d'atypique est alors √©galement appel√©e d√©tection d'anomalie non supervis√©e, tandis que la d√©tection de nouveaut√© est appel√©e d√©tection d'anomalie semi-supervis√©e. Dans le contexte de la d√©tection d'atypique, les atypiques/anomalies ne peuvent pas former un groupe dense, car les estimateurs disponibles supposent que les atypiques/anomalies sont situ√©s dans des r√©gions de faible densit√©. En revanche, dans le contexte de la d√©tection de nouveaut√©, les nouveaut√©s/anomalies peuvent former un groupe dense √† condition qu'elles se trouvent dans une r√©gion de faible densit√© des donn√©es d'entra√Ænement, consid√©r√©e comme normale dans ce contexte.\n",
    "\n",
    "Le projet scikit-learn fournit un ensemble d'outils d'apprentissage automatique pouvant √™tre utilis√©s √† la fois pour la d√©tection de nouveaut√© et d'atypique. Cette strat√©gie est mise en ≈ìuvre avec des objets apprenant de mani√®re non supervis√©e √† partir des donn√©es :\n",
    "\n",
    "```python\n",
    "estimator.fit(X_train)\n",
    "```\n",
    "\n",
    "Les nouvelles observations peuvent ensuite √™tre class√©es comme _inliers_ ou _outliers_ avec une m√©thode `predict` :\n",
    "\n",
    "```python\n",
    "estimator.predict(X_test)\n",
    "```\n",
    "\n",
    "Les _inliers_ sont √©tiquet√©s avec 1, tandis que les _outliers_ sont √©tiquet√©s avec -1. La m√©thode `predict` utilise un seuil sur la fonction de score brute calcul√©e par l'estimateur. Cette fonction de score est accessible via la m√©thode `score_samples`, tandis que le seuil peut √™tre contr√¥l√© par le param√®tre `contamination`.\n",
    "\n",
    "La m√©thode `decision_function` est √©galement d√©finie √† partir de la fonction de score, de sorte que les valeurs n√©gatives correspondent aux _outliers_ et les valeurs non n√©gatives aux _inliers_ :\n",
    "\n",
    "```python\n",
    "estimator.decision_function(X_test)\n",
    "```\n",
    "\n",
    "Notez que [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) ne prend pas en charge les m√©thodes `predict`, `decision_function` et `score_samples` par d√©faut, mais seulement une m√©thode `fit_predict`, car cet estimateur √©tait initialement destin√© √† √™tre utilis√© pour la d√©tection d'atypique. Les scores d'anomalie des √©chantillons d'entra√Ænement sont accessibles via l'attribut `negative_outlier_factor_`.\n",
    "\n",
    "Si vous souhaitez vraiment utiliser [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) pour la d√©tection de nouveaut√©, c'est-√†-dire pr√©dire des √©tiquettes ou calculer le score d'anomalie de nouvelles donn√©es non vues, vous pouvez instancier l'estimateur avec le param√®tre `novelty` d√©fini sur `True` avant d'ajuster l'estimateur. Dans ce cas, `fit_predict` n'est pas disponible.\n",
    "\n",
    "> **Attention : D√©tection de nouveaut√© avec Local Outlier Factor**\n",
    "> \n",
    "> Lorsque `novelty` est d√©fini sur `True`, prenez garde √† n'utiliser `predict`, `decision_function` et `score_samples` que sur de nouvelles donn√©es non vues, et non sur les √©chantillons d'entra√Ænement, car cela conduirait √† des r√©sultats erron√©s. Autrement dit, le r√©sultat de `predict` ne sera pas le m√™me que `fit_predict`. Les scores d'anomalie des √©chantillons d'entra√Ænement sont toujours accessibles via l'attribut `negative_outlier_factor_`.\n",
    "\n",
    "Le comportement de [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) est r√©sum√© dans le tableau suivant :\n",
    "\n",
    "|           M√©thode          |         D√©tection d'atypique        |            D√©tection de nouveaut√©           |\n",
    "|:---------------------------|:------------------------------------|:--------------------------------------------|\n",
    "| `fit_predict`              | OK                                  | Non disponible                              |\n",
    "| `predict`                  | Non disponible                      | Utiliser seulement sur de nouvelles donn√©es |\n",
    "| `decision_function`        | Non disponible                      | Utiliser seulement sur de nouvelles donn√©es |\n",
    "| `score_samples`            | Utiliser `negative_outlier_factor_` | Utiliser seulement sur de nouvelles donn√©es |\n",
    "| `negative_outlier_factor_` | OK                                  | OK                                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='overview-of-outlier-detection-methods'></a> 2.7.1. Aper√ßu des m√©thodes de d√©tection d'atypique\n",
    "\n",
    "Une comparaison des algorithmes de d√©tection d'atypique dans scikit-learn. Le Local Outlier Factor (LOF) n'affiche pas de fronti√®re de d√©cision en noir car il n'a pas de m√©thode predict pouvant √™tre appliqu√©e sur de nouvelles donn√©es lorsqu'il est utilis√© pour la d√©tection d'atypique.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_anomaly_comparison_001.png\"\n",
    "    alt=\"Comparaison des m√©thodes de d√©tection d'atypique\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "[**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) et [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) donnent des r√©sultats raisonnables sur les ensembles de donn√©es consid√©r√©s ici. [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html) est connu pour √™tre sensible aux atypiques et ne donne donc pas de tr√®s bons r√©sultats pour la d√©tection d'atypique. Cela √©tant dit, la d√©tection d'atypique en haute dimension ou sans aucune hypoth√®se sur la distribution des donn√©es internes est tr√®s difficile. [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html) peut toujours √™tre utilis√© pour la d√©tection d'atypique, mais n√©cessite un r√©glage fin de son hyperparam√®tre `nu` pour g√©rer les atypiques et √©viter le surajustement. [**`linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html) propose une impl√©mentation d'un SVM lin√©aire en une seule classe avec une complexit√© lin√©aire par rapport au nombre d'√©chantillons. Cette impl√©mentation est utilis√©e ici avec une technique d'approximation de noyau pour obtenir des r√©sultats similaires √† [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html), qui utilise un noyau gaussien par d√©faut. Enfin, [**`covariance.EllipticEnvelope`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html) suppose que les donn√©es sont gaussiennes et apprend une ellipse. Pour plus de d√©tails sur les diff√©rents estimateurs, reportez-vous √† l'exemple **Comparing anomaly detection algorithms for outlier detection on toy datasets** et aux sections ci-dessous.\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**Comparaison des algorithmes de d√©tection d'atypique pour la d√©tection d'atypique sur des ensembles de donn√©es factices**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/misc/plot_anomaly_comparison.ipynb)<br/>([_Comparing anomaly detection algorithms for outlier detection on toy datasets_](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html))\n",
    "\n",
    "Comparaison du [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html), de [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html), de [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) et de [**`covariance.EllipticEnvelope`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html).\n",
    "\n",
    "#### [**√âvaluation des estimateurs de d√©tection d'atypisme**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/misc/plot_outlier_detection_bench.ipynb)<br/>([_Evaluation of outlier detection estimators_](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_outlier_detection_bench.html))\n",
    "\n",
    "Exemple montrant comment √©valuer les estimateurs de d√©tection d'atypisme, [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) et [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html), en utilisant les courbes ROC de [**`metrics.RocCurveDisplay`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='novelty-detection'></a> 2.7.2. D√©tection de nouveaut√©\n",
    "\n",
    "Consid√©rez un ensemble de donn√©es compos√© de $n$ observations provenant de la m√™me distribution d√©crite par $p$ caract√©ristiques. Maintenant, supposons que nous ajoutions une observation suppl√©mentaire √† cet ensemble de donn√©es. Cette nouvelle observation est-elle si diff√©rente des autres que nous pouvons douter de sa r√©gularit√© ? (c'est-√†-dire provient-elle de la m√™me distribution ?) Ou au contraire, est-elle si similaire aux autres que nous ne pouvons pas la distinguer des observations originales ? C'est la question √† laquelle r√©pondent les outils et les m√©thodes de d√©tection de nouveaut√©.\n",
    "\n",
    "En g√©n√©ral, il s'agit d'apprendre une fronti√®re approximative et proche d√©limitant le contour de la distribution initiale des observations, trac√©e dans l'espace d'int√©gration √† $p$ dimensions. Ensuite, si des observations ult√©rieures se trouvent √† l'int√©rieur de l'espace d√©limit√© par la fronti√®re, elles sont consid√©r√©es comme provenant de la m√™me population que les observations initiales. Sinon, si elles se trouvent en dehors de la fronti√®re, nous pouvons dire qu'elles sont anormales avec une certaine confiance dans notre √©valuation.\n",
    "\n",
    "Le SVM √† une classe (One-Class SVM) a √©t√© introduit par Sch√∂lkopf et al. dans ce but et impl√©ment√© dans le module des Machines √† Vecteurs de Support (SVM) dans l'objet [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html). Il n√©cessite le choix d'un noyau et d'un param√®tre scalaire pour d√©finir une fronti√®re. Le noyau RBF est g√©n√©ralement choisi bien qu'il n'existe aucune formule ou algorithme exact pour d√©finir son param√®tre de bande passante. C'est la valeur par d√©faut dans l'impl√©mentation de scikit-learn. Le param√®tre `nu`, √©galement connu sous le nom de marge du SVM √† une classe, correspond √† la probabilit√© de trouver une nouvelle observation r√©guli√®re, mais diff√©rente, en dehors de la fronti√®re.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_oneclass_001.png\"\n",
    "    alt=\"D√©tection d'atypiques avec le SVM √† une classe\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**SVM √† une classe avec noyau non lin√©aire (RBF)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_4_svm/plot_oneclass.ipynb)<br/>([_One-class SVM with non-linear kernel (RBF)_](https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html))\n",
    "\n",
    "Visualisation de la fronti√®re apprise autour de certaines donn√©es par un objet [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html).\n",
    "\n",
    "#### [**Mod√©lisation de la distribution des esp√®ces**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/applications/plot_species_distribution_modeling.ipynb)<br/>([_Species distribution modeling_](https://scikit-learn.org/stable/auto_examples/applications/plot_species_distribution_modeling.html))\n",
    "\n",
    "### R√©f√©rences\n",
    "\n",
    "üî¨ Sch√∂lkopf, Bernhard, et al., [**‚ÄúEstimating the support of a high-dimensional distribution‚Äù**](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-99-87.pdf)  Neural computation 13.7 (2001): 1443-1471."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='scaling-up-the-one-class-svm'></a> 2.7.2.1. Mise √† l'√©chelle du SVM √† une classe\n",
    "\n",
    "Une version en ligne lin√©aire du SVM √† une classe est impl√©ment√©e dans [**`linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html). Cette impl√©mentation est lin√©aire par rapport au nombre d'√©chantillons et peut √™tre utilis√©e avec une approximation de noyau pour approximer la solution d'un SVM √† une classe noyaut√© dont la complexit√© est au mieux quadratique par rapport au nombre d'√©chantillons. Consultez la section [**SVM √† une classe en ligne** (1.5.3)](https://scikit-learn.org/stable/modules/sgd.html#sgd-online-one-class-svm) pour plus de d√©tails.\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**SVM √† une classe versus SVM √† une classe utilisant la descente de gradient stochastique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_5_sgd/plot_sgdocsvm_vs_ocsvm.ipynb)<br/>([_One-Class SVM versus One-Class SVM using Stochastic Gradient Descent_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgdocsvm_vs_ocsvm.html))\n",
    "\n",
    "Illustration de l'approximation d'un SVM √† une classe noyaut√© avec [**`linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html) combin√© avec une approximation de noyau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='outlier-detection'></a> 2.7.3. D√©tection d'atypisme (_Outlier Detection_)\n",
    "\n",
    "La d√©tection d'atypisme est similaire √† la d√©tection de nouveaut√© dans le sens o√π l'objectif est de s√©parer un noyau d'observations r√©guli√®res de certaines observations polluantes, appel√©es atypiques (_outliers_). Cependant, dans le cas de la d√©tection d'atypisme, nous n'avons pas un ensemble de donn√©es propre repr√©sentant la population d'observations r√©guli√®res qui peut √™tre utilis√© pour entra√Æner un outil.\n",
    "\n",
    "### <a id='fitting-an-elliptic-envelope'></a> 2.7.3.1. Ajustement d'une enveloppe elliptique (_Fitting an elliptic envelope_)\n",
    "\n",
    "Une m√©thode courante pour effectuer la d√©tection d'atypisme consiste √† supposer que les donn√©es r√©guli√®res proviennent d'une distribution connue (par exemple, les donn√©es sont distribu√©es selon une distribution gaussienne). √Ä partir de cette hypoth√®se, nous essayons g√©n√©ralement de d√©finir la \"forme\" des donn√©es et pouvons d√©finir les observations atypiques comme des observations qui s'√©loignent suffisamment de la forme ajust√©e.\n",
    "\n",
    "La biblioth√®que scikit-learn fournit un objet [**`covariance.EllipticEnvelope`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html) qui ajuste une estimation de covariance robuste aux donn√©es et ajuste ainsi une ellipse aux points de donn√©es centraux, en ignorant les points en dehors du mode central.\n",
    "\n",
    "Par exemple, en supposant que les donn√©es internes sont distribu√©es selon une distribution gaussienne, il estimerait la position et la covariance des donn√©es internes de mani√®re robuste (c'est-√†-dire sans √™tre influenc√© par les atypiques). Les distances de Mahalanobis obtenues √† partir de cette estimation sont utilis√©es pour d√©duire une mesure d'atypisme. Cette strat√©gie est illustr√©e ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_mahalanobis_distances_001.png\"\n",
    "    alt=\"Mahalanobis distances\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**Estimation de covariance robuste et pertinence des distances de Mahalanobis**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/covariance/plot_mahalanobis_distances.ipynb)<br/>([_Robust covariance estimation and Mahalanobis distances relevance_](https://scikit-learn.org/stable/auto_examples/covariance/plot_mahalanobis_distances.html))\n",
    "\n",
    "Illustration de la diff√©rence entre l'utilisation d'une estimation standard ([**`covariance.EmpiricalCovariance`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EmpiricalCovariance.html)) et d'une estimation robuste ([**`covariance.MinCovDet`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.MinCovDet.html)) de la position et de la covariance pour √©valuer le degr√© d'atypisme d'une observation.\n",
    "\n",
    "#### R√©f√©rences\n",
    "\n",
    "üî¨ Rousseeuw, P.J., Van Driessen, K. [**‚ÄúA fast algorithm for the minimum covariance determinant estimator‚Äù**](https://wis.kuleuven.be/statdatascience/robust/papers/1999/rousseeuwvandriessen-fastalgorithmformcd-technomet.pdf) Technometrics 41(3), 212 (1999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='isolation-forest'></a> 2.7.3.2. For√™t d'isolation (_Isolation Forest_)\n",
    "\n",
    "Une fa√ßon efficace de d√©tecter les valeurs aberrantes dans des ensembles de donn√©es de grande dimension est d'utiliser des for√™ts al√©atoires. La classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) \"isole\" les observations en s√©lectionnant al√©atoirement une caract√©ristique, puis en choisissant al√©atoirement une valeur de division entre la valeur maximale et minimale de la caract√©ristique s√©lectionn√©e.\n",
    "\n",
    "Comme le partitionnement r√©cursif peut √™tre repr√©sent√© par une structure arborescente, le nombre de divisions n√©cessaires pour isoler un √©chantillon est √©quivalent √† la longueur du chemin du n≈ìud racine au n≈ìud terminal.\n",
    "\n",
    "Cette longueur de chemin, en moyenne sur une for√™t de ces arbres al√©atoires, est une mesure de la normalit√© et de notre fonction de d√©cision.\n",
    "\n",
    "Le partitionnement al√©atoire produit des chemins nettement plus courts pour les anomalies. Ainsi, lorsque plusieurs arbres al√©atoires produisent collectivement des chemins plus courts pour des √©chantillons particuliers, ils sont tr√®s susceptibles d'√™tre des anomalies.\n",
    "\n",
    "La mise en ≈ìuvre de la classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) repose sur un ensemble de [**`tree.ExtraTreeRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeRegressor.html). Suivant le papier original de l'Isolation Forest, la profondeur maximale de chaque arbre est d√©finie √† $\\lceil \\log_2(n) \\rceil$, o√π $n$ est le nombre d'√©chantillons utilis√©s pour construire l'arbre (voir (Liu et al., 2008) pour plus de d√©tails).\n",
    "\n",
    "Cet algorithme est illustr√© ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_isolation_forest_003.png\"\n",
    "    alt=\"Isolation Forest\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "La classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) prend en charge `warm_start=True`, ce qui vous permet d'ajouter plus d'arbres √† un mod√®le d√©j√† ajust√© :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [0, 0], [-20, 50], [3, 5]])\n",
    "clf = IsolationForest(n_estimators=10, warm_start=True)\n",
    "clf.fit(X)  # fit 10 trees  \n",
    "clf.set_params(n_estimators=20)  # add 10 more trees  \n",
    "clf.fit(X)  # fit the added trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemples\n",
    "\n",
    "##### [**Exemple for√™t d'isolation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_11_ensemble/plot_isolation_forest.ipynb)<br/>([_IsolationForest example_](https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html))\n",
    "\n",
    "Illustration de l'utilisation de la classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html).\n",
    "\n",
    "##### [**Comparaison des algorithmes de d√©tection d'atypique pour la d√©tection d'atypique sur des ensembles de donn√©es factices**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/misc/plot_anomaly_comparison.ipynb)<br/>([_Comparing anomaly detection algorithms for outlier detection on toy datasets_](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html))\n",
    "\n",
    "Comparaison de la classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) avec [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html), [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html) (ajust√© pour fonctionner comme une m√©thode de d√©tection d'atypique), [**`linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html) et une d√©tection d'atypique bas√©e sur la covariance avec [**`covariance.EllipticEnvelope`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html).\n",
    "\n",
    "#### R√©f√©rences\n",
    "\n",
    "üî¨ Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. [**‚ÄúIsolation forest‚Äù**](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf). Data Mining, 2008. ICDM‚Äô08. Eighth IEEE International Conference on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='local-outlier-factor'></a> 2.7.3.3. Facteur Local d'Atypisme (_Local Outlier Factor_)\n",
    "\n",
    "Une autre fa√ßon efficace de d√©tecter les valeurs atypiques dans des ensembles de donn√©es mod√©r√©ment de haute dimension est d'utiliser l'algorithme du Facteur Local d'Atypisme (_Local Outlier Factor_ - LOF).\n",
    "\n",
    "L'algorithme [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) (LOF) calcule un score (appel√© facteur local d'atypisme) refl√©tant le degr√© d'anormalit√© des observations. Il mesure la d√©viation de densit√© locale d'un point de donn√©es donn√© par rapport √† ses voisins. L'id√©e est de d√©tecter les √©chantillons qui ont une densit√© nettement plus faible que leurs voisins.\n",
    "\n",
    "En pratique, la densit√© locale est obtenue √† partir des $k$ plus proches voisins. Le score LOF d'une observation est √©gal au rapport entre la densit√© locale moyenne de ses $k$ plus proches voisins et sa propre densit√© locale : une instance normale devrait avoir une densit√© locale similaire √† celle de ses voisins, tandis que les donn√©es anormales devraient avoir une densit√© locale beaucoup plus petite.\n",
    "\n",
    "Le nombre $k$ de voisins consid√©r√©s (alias param√®tre `n_neighbors`) est g√©n√©ralement choisi de mani√®re √† la fois 1) sup√©rieure au nombre minimum d'objets qu'un cluster doit contenir, de sorte que d'autres objets puissent √™tre des valeurs atypiques locales par rapport √† ce cluster, et 2) inf√©rieure au nombre maximum d'objets proches qui peuvent potentiellement √™tre des valeurs atypiques locales. En pratique, de telles informations ne sont g√©n√©ralement pas disponibles, et choisir `n_neighbors=20` semble bien fonctionner en g√©n√©ral. Lorsque la proportion de valeurs atypiques est √©lev√©e (c'est-√†-dire sup√©rieure √† 10 %, comme dans l'exemple ci-dessous), `n_neighbors` devrait √™tre plus grand (`n_neighbors=35` dans l'exemple ci-dessous).\n",
    "\n",
    "La force de l'algorithme LOF est qu'il prend en compte √† la fois les propri√©t√©s locales et globales des ensembles de donn√©es : il peut bien fonctionner m√™me dans les ensembles de donn√©es o√π les √©chantillons atypiques ont des densit√©s sous-jacentes diff√©rentes. La question n'est pas de savoir √† quel point l'√©chantillon est isol√©, mais √† quel point il est isol√© par rapport au quartier environnant.\n",
    "\n",
    "Lorsque l'on applique LOF pour la d√©tection de valeurs atypiques, il n'y a pas de m√©thodes `predict`, `decision_function` et `score_samples`, mais seulement une m√©thode `fit_predict`. Les scores d'anormalit√© des √©chantillons d'entra√Ænement sont accessibles via l'attribut `negative_outlier_factor_`. Notez que `predict`, `decision_function` et `score_samples` peuvent √™tre utilis√©s sur de nouvelles donn√©es non vues lorsque LOF est appliqu√© pour la d√©tection de nouveaut√© (`novelty`), c'est-√†-dire lorsque le param√®tre `novelty` est d√©fini sur `True`, mais le r√©sultat de `predict` peut diff√©rer de celui de `fit_predict`. Voir [**D√©tection de nouveaut√© avec le Facteur Local d'Atypisme** (2.7.4)](https://scikit-learn.org/stable/modules/outlier_detection.html#novelty-with-lof).\n",
    "\n",
    "Cette strat√©gie est illustr√©e ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_lof_outlier_detection_001.png\"\n",
    "    alt=\"Local Outlier Factor\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**D√©tection d'atypisme avec le Facteur Local d'Atypisme (LOF)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/neighbors/plot_lof_outlier_detection.ipynb)<br/>([_Outlier detection with Local Outlier Factor (LOF)_](https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html))\n",
    "\n",
    "Illustration de l'utilisation de [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html).\n",
    "\n",
    "##### [**Comparaison des algorithmes de d√©tection d'atypique pour la d√©tection d'atypique sur des ensembles de donn√©es factices**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/misc/plot_anomaly_comparison.ipynb)<br/>([_Comparing anomaly detection algorithms for outlier detection on toy datasets_](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html))\n",
    "\n",
    "Comparaison avec d'autres m√©thodes de d√©tection d'atypisme.\n",
    "\n",
    "#### R√©f√©rences\n",
    "\n",
    "üî¨ Breunig, Kriegel, Ng, and Sander (2000) [**‚ÄúLOF: identifying density-based local outliers‚Äù**](https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf). Proc. ACM SIGMOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='novelty-detection-with-local-outlier-factor'></a> 2.7.4. D√©tection de nouveaut√© avec le Facteur Local d'Atypisme (_Local Outlier Factor_)\n",
    "\n",
    "Pour utiliser [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) pour la d√©tection de nouveaut√©, c'est-√†-dire pr√©dire des √©tiquettes ou calculer le score d'anormalit√© de nouvelles donn√©es non vues, vous devez instancier l'estimateur avec le param√®tre novelty d√©fini sur True avant de l'ajuster :\n",
    "\n",
    "```python\n",
    "lof = LocalOutlierFactor(novelty=True)\n",
    "lof.fit(X_train)\n",
    "```\n",
    "\n",
    "Notez que `fit_predict` n'est pas disponible dans ce cas pour √©viter les incoh√©rences.\n",
    "\n",
    "> **Attention : D√©tection de nouveaut√© avec le Facteur Local d'Atypisme**\n",
    "> Lorsque novelty est d√©fini sur True, veuillez noter que vous ne devez utiliser `predict`, `decision_function` et `score_samples` que sur de nouvelles donn√©es non vues et non sur les √©chantillons d'entra√Ænement, car cela entra√Ænerait des r√©sultats incorrects. Autrement dit, le r√©sultat de `predict` ne sera pas le m√™me que `fit_predict`. Les scores d'anormalit√© des √©chantillons d'entra√Ænement sont toujours accessibles via l'attribut `negative_outlier_factor_`.\n",
    "\n",
    "La d√©tection de nouveaut√© avec le Facteur Local d'Atypisme est illustr√©e ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_lof_novelty_detection_001.png\"\n",
    "    alt=\"Novelty Detection with LOF\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
