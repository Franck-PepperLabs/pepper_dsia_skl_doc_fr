{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='unsupervised-learning'></a> 2. [**Apprentissage non supervisé**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_unsupervised_learning.ipynb#model-selection-and-evaluation)</br>([*Unsupervised learning*](https://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning))\n",
    "\n",
    "# 2.7. [**Détection de nouveauté et d'atypique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#novelty-and-outlier-detection)<br/>([_Novelty and Outlier Detection_](https://scikit-learn.org/stable/modules/outlier_detection.html#novelty-and-outlier-detection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 12 pages, 10 exemples, 4 papiers\n",
    "- 2.7.1. [**Aperçu des méthodes de détection d'atypique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#overview-of-outlier-detection-methods)<br/>([_Overview of outlier detection methods_](https://scikit-learn.org/stable/outlier_detection.html#overview-of-outlier-detection-methods))\n",
    "- 2.7.2. [**Détection de nouveauté**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#novelty-detection)<br/>([_Novelty Detection_](https://scikit-learn.org/stable/outlier_detection.html#novelty-detection))\n",
    "- 2.7.3. [**Détection d'atypique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#outlier-detection)<br/>([_Outlier Detection_](https://scikit-learn.org/stable/outlier_detection.html#outlier-detection))\n",
    "- 2.7.4. [**Détection de nouveauté avec Local Outlier Factor**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_7_outlier_detection.ipynb#novelty-detection-with-local-outlier-factor)<br/>([_Novelty detection with Local Outlier Factor_](https://scikit-learn.org/stable/outlier_detection.html#novelty-detection-with-local-outlier-factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='novelty-and-outlier-detection'></a> 2.7. Détection de nouveauté et d'atypique\n",
    "\n",
    "De nombreuses applications nécessitent de pouvoir décider si une nouvelle observation appartient à la même distribution que les observations existantes (elle est un _inlier_) ou si elle doit être considérée comme différente (elle est un _outlier_, ou _valeur atypique_). Souvent, cette capacité est utilisée pour nettoyer des ensembles de données réels. Deux distinctions importantes doivent être faites :\n",
    "\n",
    "- **Détection d'atypiques (_Outlier Detection_) :** Les données d'entraînement contiennent des valeurs atypiques, définis comme des observations très éloignées des autres. Les estimateurs de détection d'atypique cherchent donc à ajuster les régions où les données d'entraînement sont les plus concentrées, en ignorant les observations déviantes.\n",
    "- **Détection de nouveauté (_Novelty Detection_) :** Les données d'entraînement ne sont pas polluées par des atypiques, et nous cherchons à détecter si une **nouvelle** observation est un atypique. Dans ce contexte, un atypique est également appelé une nouveauté.\n",
    "\n",
    "La détection d'atypique et la détection de nouveauté sont toutes deux utilisées pour la détection d'anomalies, où l'on s'intéresse à détecter des observations anormales ou inhabituelles. La détection d'atypique est alors également appelée détection d'anomalie non supervisée, tandis que la détection de nouveauté est appelée détection d'anomalie semi-supervisée. Dans le contexte de la détection d'atypique, les atypiques/anomalies ne peuvent pas former un groupe dense, car les estimateurs disponibles supposent que les atypiques/anomalies sont situés dans des régions de faible densité. En revanche, dans le contexte de la détection de nouveauté, les nouveautés/anomalies peuvent former un groupe dense à condition qu'elles se trouvent dans une région de faible densité des données d'entraînement, considérée comme normale dans ce contexte.\n",
    "\n",
    "Le projet scikit-learn fournit un ensemble d'outils d'apprentissage automatique pouvant être utilisés à la fois pour la détection de nouveauté et d'atypique. Cette stratégie est mise en œuvre avec des objets apprenant de manière non supervisée à partir des données :\n",
    "\n",
    "```python\n",
    "estimator.fit(X_train)\n",
    "```\n",
    "\n",
    "Les nouvelles observations peuvent ensuite être classées comme _inliers_ ou _outliers_ avec une méthode `predict` :\n",
    "\n",
    "```python\n",
    "estimator.predict(X_test)\n",
    "```\n",
    "\n",
    "Les _inliers_ sont étiquetés avec 1, tandis que les _outliers_ sont étiquetés avec -1. La méthode `predict` utilise un seuil sur la fonction de score brute calculée par l'estimateur. Cette fonction de score est accessible via la méthode `score_samples`, tandis que le seuil peut être contrôlé par le paramètre `contamination`.\n",
    "\n",
    "La méthode `decision_function` est également définie à partir de la fonction de score, de sorte que les valeurs négatives correspondent aux _outliers_ et les valeurs non négatives aux _inliers_ :\n",
    "\n",
    "```python\n",
    "estimator.decision_function(X_test)\n",
    "```\n",
    "\n",
    "Notez que [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) ne prend pas en charge les méthodes `predict`, `decision_function` et `score_samples` par défaut, mais seulement une méthode `fit_predict`, car cet estimateur était initialement destiné à être utilisé pour la détection d'atypique. Les scores d'anomalie des échantillons d'entraînement sont accessibles via l'attribut `negative_outlier_factor_`.\n",
    "\n",
    "Si vous souhaitez vraiment utiliser [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) pour la détection de nouveauté, c'est-à-dire prédire des étiquettes ou calculer le score d'anomalie de nouvelles données non vues, vous pouvez instancier l'estimateur avec le paramètre `novelty` défini sur `True` avant d'ajuster l'estimateur. Dans ce cas, `fit_predict` n'est pas disponible.\n",
    "\n",
    "> **Attention : Détection de nouveauté avec Local Outlier Factor**\n",
    "> \n",
    "> Lorsque `novelty` est défini sur `True`, prenez garde à n'utiliser `predict`, `decision_function` et `score_samples` que sur de nouvelles données non vues, et non sur les échantillons d'entraînement, car cela conduirait à des résultats erronés. Autrement dit, le résultat de `predict` ne sera pas le même que `fit_predict`. Les scores d'anomalie des échantillons d'entraînement sont toujours accessibles via l'attribut `negative_outlier_factor_`.\n",
    "\n",
    "Le comportement de [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) est résumé dans le tableau suivant :\n",
    "\n",
    "|           Méthode          |         Détection d'atypique        |            Détection de nouveauté           |\n",
    "|:---------------------------|:------------------------------------|:--------------------------------------------|\n",
    "| `fit_predict`              | OK                                  | Non disponible                              |\n",
    "| `predict`                  | Non disponible                      | Utiliser seulement sur de nouvelles données |\n",
    "| `decision_function`        | Non disponible                      | Utiliser seulement sur de nouvelles données |\n",
    "| `score_samples`            | Utiliser `negative_outlier_factor_` | Utiliser seulement sur de nouvelles données |\n",
    "| `negative_outlier_factor_` | OK                                  | OK                                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='overview-of-outlier-detection-methods'></a> 2.7.1. Aperçu des méthodes de détection d'atypique\n",
    "\n",
    "Une comparaison des algorithmes de détection d'atypique dans scikit-learn. Le Local Outlier Factor (LOF) n'affiche pas de frontière de décision en noir car il n'a pas de méthode predict pouvant être appliquée sur de nouvelles données lorsqu'il est utilisé pour la détection d'atypique.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_anomaly_comparison_001.png\"\n",
    "    alt=\"Comparaison des méthodes de détection d'atypique\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "[**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) et [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) donnent des résultats raisonnables sur les ensembles de données considérés ici. [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html) est connu pour être sensible aux atypiques et ne donne donc pas de très bons résultats pour la détection d'atypique. Cela étant dit, la détection d'atypique en haute dimension ou sans aucune hypothèse sur la distribution des données internes est très difficile. [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html) peut toujours être utilisé pour la détection d'atypique, mais nécessite un réglage fin de son hyperparamètre `nu` pour gérer les atypiques et éviter le surajustement. [**`linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html) propose une implémentation d'un SVM linéaire en une seule classe avec une complexité linéaire par rapport au nombre d'échantillons. Cette implémentation est utilisée ici avec une technique d'approximation de noyau pour obtenir des résultats similaires à [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html), qui utilise un noyau gaussien par défaut. Enfin, [**`covariance.EllipticEnvelope`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html) suppose que les données sont gaussiennes et apprend une ellipse. Pour plus de détails sur les différents estimateurs, reportez-vous à l'exemple **Comparing anomaly detection algorithms for outlier detection on toy datasets** et aux sections ci-dessous.\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**Comparaison des algorithmes de détection d'atypique pour la détection d'atypique sur des ensembles de données factices**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/misc/plot_anomaly_comparison.ipynb)<br/>([_Comparing anomaly detection algorithms for outlier detection on toy datasets_](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html))\n",
    "\n",
    "Comparaison du [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html), de [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html), de [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) et de [**`covariance.EllipticEnvelope`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html).\n",
    "\n",
    "#### [**Évaluation des estimateurs de détection d'atypisme**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/misc/plot_outlier_detection_bench.ipynb)<br/>([_Evaluation of outlier detection estimators_](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_outlier_detection_bench.html))\n",
    "\n",
    "Exemple montrant comment évaluer les estimateurs de détection d'atypisme, [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) et [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html), en utilisant les courbes ROC de [**`metrics.RocCurveDisplay`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='novelty-detection'></a> 2.7.2. Détection de nouveauté\n",
    "\n",
    "Considérez un ensemble de données composé de $n$ observations provenant de la même distribution décrite par $p$ caractéristiques. Maintenant, supposons que nous ajoutions une observation supplémentaire à cet ensemble de données. Cette nouvelle observation est-elle si différente des autres que nous pouvons douter de sa régularité ? (c'est-à-dire provient-elle de la même distribution ?) Ou au contraire, est-elle si similaire aux autres que nous ne pouvons pas la distinguer des observations originales ? C'est la question à laquelle répondent les outils et les méthodes de détection de nouveauté.\n",
    "\n",
    "En général, il s'agit d'apprendre une frontière approximative et proche délimitant le contour de la distribution initiale des observations, tracée dans l'espace d'intégration à $p$ dimensions. Ensuite, si des observations ultérieures se trouvent à l'intérieur de l'espace délimité par la frontière, elles sont considérées comme provenant de la même population que les observations initiales. Sinon, si elles se trouvent en dehors de la frontière, nous pouvons dire qu'elles sont anormales avec une certaine confiance dans notre évaluation.\n",
    "\n",
    "Le SVM à une classe (One-Class SVM) a été introduit par Schölkopf et al. dans ce but et implémenté dans le module des Machines à Vecteurs de Support (SVM) dans l'objet [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html). Il nécessite le choix d'un noyau et d'un paramètre scalaire pour définir une frontière. Le noyau RBF est généralement choisi bien qu'il n'existe aucune formule ou algorithme exact pour définir son paramètre de bande passante. C'est la valeur par défaut dans l'implémentation de scikit-learn. Le paramètre `nu`, également connu sous le nom de marge du SVM à une classe, correspond à la probabilité de trouver une nouvelle observation régulière, mais différente, en dehors de la frontière.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_oneclass_001.png\"\n",
    "    alt=\"Détection d'atypiques avec le SVM à une classe\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**SVM à une classe avec noyau non linéaire (RBF)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_4_svm/plot_oneclass.ipynb)<br/>([_One-class SVM with non-linear kernel (RBF)_](https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html))\n",
    "\n",
    "Visualisation de la frontière apprise autour de certaines données par un objet [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html).\n",
    "\n",
    "#### [**Modélisation de la distribution des espèces**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/applications/plot_species_distribution_modeling.ipynb)<br/>([_Species distribution modeling_](https://scikit-learn.org/stable/auto_examples/applications/plot_species_distribution_modeling.html))\n",
    "\n",
    "### Références\n",
    "\n",
    "🔬 Schölkopf, Bernhard, et al., [**“Estimating the support of a high-dimensional distribution”**](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-99-87.pdf)  Neural computation 13.7 (2001): 1443-1471."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='scaling-up-the-one-class-svm'></a> 2.7.2.1. Mise à l'échelle du SVM à une classe\n",
    "\n",
    "Une version en ligne linéaire du SVM à une classe est implémentée dans [**`linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html). Cette implémentation est linéaire par rapport au nombre d'échantillons et peut être utilisée avec une approximation de noyau pour approximer la solution d'un SVM à une classe noyauté dont la complexité est au mieux quadratique par rapport au nombre d'échantillons. Consultez la section [**SVM à une classe en ligne** (1.5.3)](https://scikit-learn.org/stable/modules/sgd.html#sgd-online-one-class-svm) pour plus de détails.\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**SVM à une classe versus SVM à une classe utilisant la descente de gradient stochastique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_5_sgd/plot_sgdocsvm_vs_ocsvm.ipynb)<br/>([_One-Class SVM versus One-Class SVM using Stochastic Gradient Descent_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgdocsvm_vs_ocsvm.html))\n",
    "\n",
    "Illustration de l'approximation d'un SVM à une classe noyauté avec [**`linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html) combiné avec une approximation de noyau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='outlier-detection'></a> 2.7.3. Détection d'atypisme (_Outlier Detection_)\n",
    "\n",
    "La détection d'atypisme est similaire à la détection de nouveauté dans le sens où l'objectif est de séparer un noyau d'observations régulières de certaines observations polluantes, appelées atypiques (_outliers_). Cependant, dans le cas de la détection d'atypisme, nous n'avons pas un ensemble de données propre représentant la population d'observations régulières qui peut être utilisé pour entraîner un outil.\n",
    "\n",
    "### <a id='fitting-an-elliptic-envelope'></a> 2.7.3.1. Ajustement d'une enveloppe elliptique (_Fitting an elliptic envelope_)\n",
    "\n",
    "Une méthode courante pour effectuer la détection d'atypisme consiste à supposer que les données régulières proviennent d'une distribution connue (par exemple, les données sont distribuées selon une distribution gaussienne). À partir de cette hypothèse, nous essayons généralement de définir la \"forme\" des données et pouvons définir les observations atypiques comme des observations qui s'éloignent suffisamment de la forme ajustée.\n",
    "\n",
    "La bibliothèque scikit-learn fournit un objet [**`covariance.EllipticEnvelope`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html) qui ajuste une estimation de covariance robuste aux données et ajuste ainsi une ellipse aux points de données centraux, en ignorant les points en dehors du mode central.\n",
    "\n",
    "Par exemple, en supposant que les données internes sont distribuées selon une distribution gaussienne, il estimerait la position et la covariance des données internes de manière robuste (c'est-à-dire sans être influencé par les atypiques). Les distances de Mahalanobis obtenues à partir de cette estimation sont utilisées pour déduire une mesure d'atypisme. Cette stratégie est illustrée ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_mahalanobis_distances_001.png\"\n",
    "    alt=\"Mahalanobis distances\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**Estimation de covariance robuste et pertinence des distances de Mahalanobis**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/covariance/plot_mahalanobis_distances.ipynb)<br/>([_Robust covariance estimation and Mahalanobis distances relevance_](https://scikit-learn.org/stable/auto_examples/covariance/plot_mahalanobis_distances.html))\n",
    "\n",
    "Illustration de la différence entre l'utilisation d'une estimation standard ([**`covariance.EmpiricalCovariance`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EmpiricalCovariance.html)) et d'une estimation robuste ([**`covariance.MinCovDet`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.MinCovDet.html)) de la position et de la covariance pour évaluer le degré d'atypisme d'une observation.\n",
    "\n",
    "#### Références\n",
    "\n",
    "🔬 Rousseeuw, P.J., Van Driessen, K. [**“A fast algorithm for the minimum covariance determinant estimator”**](https://wis.kuleuven.be/statdatascience/robust/papers/1999/rousseeuwvandriessen-fastalgorithmformcd-technomet.pdf) Technometrics 41(3), 212 (1999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='isolation-forest'></a> 2.7.3.2. Forêt d'isolation (_Isolation Forest_)\n",
    "\n",
    "Une façon efficace de détecter les valeurs aberrantes dans des ensembles de données de grande dimension est d'utiliser des forêts aléatoires. La classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) \"isole\" les observations en sélectionnant aléatoirement une caractéristique, puis en choisissant aléatoirement une valeur de division entre la valeur maximale et minimale de la caractéristique sélectionnée.\n",
    "\n",
    "Comme le partitionnement récursif peut être représenté par une structure arborescente, le nombre de divisions nécessaires pour isoler un échantillon est équivalent à la longueur du chemin du nœud racine au nœud terminal.\n",
    "\n",
    "Cette longueur de chemin, en moyenne sur une forêt de ces arbres aléatoires, est une mesure de la normalité et de notre fonction de décision.\n",
    "\n",
    "Le partitionnement aléatoire produit des chemins nettement plus courts pour les anomalies. Ainsi, lorsque plusieurs arbres aléatoires produisent collectivement des chemins plus courts pour des échantillons particuliers, ils sont très susceptibles d'être des anomalies.\n",
    "\n",
    "La mise en œuvre de la classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) repose sur un ensemble de [**`tree.ExtraTreeRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeRegressor.html). Suivant le papier original de l'Isolation Forest, la profondeur maximale de chaque arbre est définie à $\\lceil \\log_2(n) \\rceil$, où $n$ est le nombre d'échantillons utilisés pour construire l'arbre (voir (Liu et al., 2008) pour plus de détails).\n",
    "\n",
    "Cet algorithme est illustré ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_isolation_forest_003.png\"\n",
    "    alt=\"Isolation Forest\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "La classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) prend en charge `warm_start=True`, ce qui vous permet d'ajouter plus d'arbres à un modèle déjà ajusté :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [0, 0], [-20, 50], [3, 5]])\n",
    "clf = IsolationForest(n_estimators=10, warm_start=True)\n",
    "clf.fit(X)  # fit 10 trees  \n",
    "clf.set_params(n_estimators=20)  # add 10 more trees  \n",
    "clf.fit(X)  # fit the added trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemples\n",
    "\n",
    "##### [**Exemple forêt d'isolation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_11_ensemble/plot_isolation_forest.ipynb)<br/>([_IsolationForest example_](https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html))\n",
    "\n",
    "Illustration de l'utilisation de la classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html).\n",
    "\n",
    "##### [**Comparaison des algorithmes de détection d'atypique pour la détection d'atypique sur des ensembles de données factices**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/misc/plot_anomaly_comparison.ipynb)<br/>([_Comparing anomaly detection algorithms for outlier detection on toy datasets_](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html))\n",
    "\n",
    "Comparaison de la classe [**`ensemble.IsolationForest`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) avec [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html), [**`svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html) (ajusté pour fonctionner comme une méthode de détection d'atypique), [**`linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html) et une détection d'atypique basée sur la covariance avec [**`covariance.EllipticEnvelope`**](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html).\n",
    "\n",
    "#### Références\n",
    "\n",
    "🔬 Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. [**“Isolation forest”**](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf). Data Mining, 2008. ICDM’08. Eighth IEEE International Conference on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='local-outlier-factor'></a> 2.7.3.3. Facteur Local d'Atypisme (_Local Outlier Factor_)\n",
    "\n",
    "Une autre façon efficace de détecter les valeurs atypiques dans des ensembles de données modérément de haute dimension est d'utiliser l'algorithme du Facteur Local d'Atypisme (_Local Outlier Factor_ - LOF).\n",
    "\n",
    "L'algorithme [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) (LOF) calcule un score (appelé facteur local d'atypisme) reflétant le degré d'anormalité des observations. Il mesure la déviation de densité locale d'un point de données donné par rapport à ses voisins. L'idée est de détecter les échantillons qui ont une densité nettement plus faible que leurs voisins.\n",
    "\n",
    "En pratique, la densité locale est obtenue à partir des $k$ plus proches voisins. Le score LOF d'une observation est égal au rapport entre la densité locale moyenne de ses $k$ plus proches voisins et sa propre densité locale : une instance normale devrait avoir une densité locale similaire à celle de ses voisins, tandis que les données anormales devraient avoir une densité locale beaucoup plus petite.\n",
    "\n",
    "Le nombre $k$ de voisins considérés (alias paramètre `n_neighbors`) est généralement choisi de manière à la fois 1) supérieure au nombre minimum d'objets qu'un cluster doit contenir, de sorte que d'autres objets puissent être des valeurs atypiques locales par rapport à ce cluster, et 2) inférieure au nombre maximum d'objets proches qui peuvent potentiellement être des valeurs atypiques locales. En pratique, de telles informations ne sont généralement pas disponibles, et choisir `n_neighbors=20` semble bien fonctionner en général. Lorsque la proportion de valeurs atypiques est élevée (c'est-à-dire supérieure à 10 %, comme dans l'exemple ci-dessous), `n_neighbors` devrait être plus grand (`n_neighbors=35` dans l'exemple ci-dessous).\n",
    "\n",
    "La force de l'algorithme LOF est qu'il prend en compte à la fois les propriétés locales et globales des ensembles de données : il peut bien fonctionner même dans les ensembles de données où les échantillons atypiques ont des densités sous-jacentes différentes. La question n'est pas de savoir à quel point l'échantillon est isolé, mais à quel point il est isolé par rapport au quartier environnant.\n",
    "\n",
    "Lorsque l'on applique LOF pour la détection de valeurs atypiques, il n'y a pas de méthodes `predict`, `decision_function` et `score_samples`, mais seulement une méthode `fit_predict`. Les scores d'anormalité des échantillons d'entraînement sont accessibles via l'attribut `negative_outlier_factor_`. Notez que `predict`, `decision_function` et `score_samples` peuvent être utilisés sur de nouvelles données non vues lorsque LOF est appliqué pour la détection de nouveauté (`novelty`), c'est-à-dire lorsque le paramètre `novelty` est défini sur `True`, mais le résultat de `predict` peut différer de celui de `fit_predict`. Voir [**Détection de nouveauté avec le Facteur Local d'Atypisme** (2.7.4)](https://scikit-learn.org/stable/modules/outlier_detection.html#novelty-with-lof).\n",
    "\n",
    "Cette stratégie est illustrée ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_lof_outlier_detection_001.png\"\n",
    "    alt=\"Local Outlier Factor\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**Détection d'atypisme avec le Facteur Local d'Atypisme (LOF)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/neighbors/plot_lof_outlier_detection.ipynb)<br/>([_Outlier detection with Local Outlier Factor (LOF)_](https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html))\n",
    "\n",
    "Illustration de l'utilisation de [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html).\n",
    "\n",
    "##### [**Comparaison des algorithmes de détection d'atypique pour la détection d'atypique sur des ensembles de données factices**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/misc/plot_anomaly_comparison.ipynb)<br/>([_Comparing anomaly detection algorithms for outlier detection on toy datasets_](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html))\n",
    "\n",
    "Comparaison avec d'autres méthodes de détection d'atypisme.\n",
    "\n",
    "#### Références\n",
    "\n",
    "🔬 Breunig, Kriegel, Ng, and Sander (2000) [**“LOF: identifying density-based local outliers”**](https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf). Proc. ACM SIGMOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='novelty-detection-with-local-outlier-factor'></a> 2.7.4. Détection de nouveauté avec le Facteur Local d'Atypisme (_Local Outlier Factor_)\n",
    "\n",
    "Pour utiliser [**`neighbors.LocalOutlierFactor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) pour la détection de nouveauté, c'est-à-dire prédire des étiquettes ou calculer le score d'anormalité de nouvelles données non vues, vous devez instancier l'estimateur avec le paramètre novelty défini sur True avant de l'ajuster :\n",
    "\n",
    "```python\n",
    "lof = LocalOutlierFactor(novelty=True)\n",
    "lof.fit(X_train)\n",
    "```\n",
    "\n",
    "Notez que `fit_predict` n'est pas disponible dans ce cas pour éviter les incohérences.\n",
    "\n",
    "> **Attention : Détection de nouveauté avec le Facteur Local d'Atypisme**\n",
    "> Lorsque novelty est défini sur True, veuillez noter que vous ne devez utiliser `predict`, `decision_function` et `score_samples` que sur de nouvelles données non vues et non sur les échantillons d'entraînement, car cela entraînerait des résultats incorrects. Autrement dit, le résultat de `predict` ne sera pas le même que `fit_predict`. Les scores d'anormalité des échantillons d'entraînement sont toujours accessibles via l'attribut `negative_outlier_factor_`.\n",
    "\n",
    "La détection de nouveauté avec le Facteur Local d'Atypisme est illustrée ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_lof_novelty_detection_001.png\"\n",
    "    alt=\"Novelty Detection with LOF\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
