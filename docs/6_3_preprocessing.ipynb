{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3. [**Prétraitement des données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb)</br>([*Preprocessing data*](https://scikit-learn.org/stable/modules/preprocessing.html))\n",
    "\n",
    "Le package `sklearn.preprocessing` fournit plusieurs fonctions utilitaires courantes et des classes de transformeurs pour changer les vecteurs de caractéristiques brutes en une représentation plus adaptée aux estimateurs aval.\n",
    "\n",
    "En général, les algorithmes d'apprentissage bénéficient d'une standardisation de l'ensemble de données. Si des outliers sont présents dans l'ensemble, des redimensionneurs ou transformateurs robustes sont plus appropriés. Le comportement des différents redimensionneurs, transformateurs et normaliseurs sur un jeu de données contenant des outliers marginaux est mis en évidence dans [**Comparaison de l'effet de différents redimensionneurs sur des données avec des outliers**](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='standardization-or-mean-removal-and-variance-scaling'></a>  6.3.1. Standardisation, ou suppression de la moyenne et normalisation de la variance\n",
    "\n",
    "La **standardisation** des ensembles de données est **une exigence courante pour de nombreux estimateurs d'apprentissage automatique** mis en œuvre dans scikit-learn; ils pourraient mal se comporter si les caractéristiques individuelles ne ressemblent pas plus ou moins à des données distribuées normalement standard : Gaussienne avec une **moyenne nulle et une variance unitaire**.\n",
    "\n",
    "En pratique, nous ignorons souvent la forme de la distribution et transformons simplement les données pour les centrer en supprimant la valeur moyenne de chaque caractéristique, puis en les dimensionnant en divisant les caractéristiques non constantes par leur écart-type.\n",
    "\n",
    "Par exemple, de nombreux éléments utilisés dans la fonction objective d'un algorithme d'apprentissage (tels que le noyau RBF des Machines à vecteurs de support ou les régulariseurs $\\ell_1$ et $\\ell_2$ des modèles linéaires) peuvent supposer que toutes les caractéristiques sont centrées autour de zéro ou ont une variance de même ordre. Si une caractéristique a une variance qui est des ordres de grandeur plus grande que les autres, elle pourrait dominer la fonction objective et empêcher l'estimateur d'apprendre correctement des autres caractéristiques comme prévu.\n",
    "\n",
    "Le module [**`preprocessing`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) fournit la classe d'utilité [**`StandardScaler`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), qui est un moyen rapide et facile d'effectuer les opérations suivantes sur un jeu de données de type tableau :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='encoding-categorical-features'></a> 6.3.4. Encodage des caractéristiques catégorielles\n",
    "\n",
    "Souvent, les caractéristiques ne sont pas données sous forme de valeurs continues mais catégorielles. Par exemple, une personne peut avoir des caractéristiques `[\"homme\", \"femme\"]`, `[\"from Europe\", \"from États-Unis\", \"from Asia\"]`, `[\"uses Firefox\", \"uses Chrome\", \"uses Safari\", \"uses Internet Explorer\"]`. De telles caractéristiques peuvent être efficacement codées sous forme d'entiers, par exemple `[\"male\", \"from États-Unis\", \"uses Internet Explorer\"]` pourrait être exprimé par `[0, 1, 3]` tandis que `[\"female\", \"from Asia\", \"uses Chrome\"]` serait `[1, 2, 1]`.\n",
    "\n",
    "Pour convertir des caractéristiques catégorielles en de tels codes entiers, nous pouvons utiliser [**`OrdinalEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html). Cet estimateur transforme chaque caractéristique catégorielle en une nouvelle caractéristique d'entiers ($0$ à $n_{\\text{categories}} - 1$) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "# OrdinalEncoder()\n",
    "enc.transform([['female', 'from US', 'uses Safari']])\n",
    "# array([[0., 1., 1.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une telle représentation entière ne peut cependant pas être utilisée directement avec tous les estimateurs scikit-learn, car ceux-ci attendent une entrée continue et interpréteraient les catégories en tant qu'ordinaux, ce qui n'est souvent pas souhaité (c'est-à-dire que l'ensemble des navigateurs a été ordonné arbitrairement).\n",
    "\n",
    "Par défaut, [**`OrdinalEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) transmettra également les valeurs manquantes représentées par `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [nan],\n",
       "       [ 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male'], ['female'], [np.nan], ['female']]\n",
    "enc.fit_transform(X)\n",
    "# array([[ 1.],\n",
    "#       [ 0.],\n",
    "#       [nan],\n",
    "#       [ 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`OrdinalEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) fournit un paramètre `encoded_missing_value` pour encoder les valeurs manquantes sans avoir besoin de créer un pipeline et en utilisant [**`SimpleImputer`**](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [-1.],\n",
       "       [ 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder(encoded_missing_value=-1)\n",
    "X = [['male'], ['female'], [np.nan], ['female']]\n",
    "enc.fit_transform(X)\n",
    "# array([[ 1.],\n",
    "#        [ 0.],\n",
    "#        [-1.],\n",
    "#        [ 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le traitement ci-dessus est équivalent au pipeline suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "enc = Pipeline(steps=[\n",
    "        (\"encoder\", preprocessing.OrdinalEncoder()),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "    ])\n",
    "enc.fit_transform(X)\n",
    "# array([[ 1.],\n",
    "#        [ 0.],\n",
    "#        [-1.],\n",
    "#        [ 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre possibilité de convertir des caractéristiques catégorielles en caractéristiques pouvant être utilisées avec les estimateurs scikit-learn consiste à utiliser un one-of-K, également connu sous le nom de codage one-hot ou factice. Ce type d'encodage peut être obtenu avec le [**`OneHotEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), qui transforme chaque caractéristique catégorique avec `n_categories` valeurs possibles en `n_categories` caractéristiques binaires, avec l'une d'elles à 1, et toutes les autres à 0.\n",
    "\n",
    "Reprenons l'exemple ci-dessus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "# OneHotEncoder()\n",
    "enc.transform([['female', 'from US', 'uses Safari'],\n",
    "               ['male', 'from Europe', 'uses Safari']]).toarray()\n",
    "# array([[1., 0., 0., 1., 0., 1.],\n",
    "#        [0., 1., 1., 0., 0., 1.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, les valeurs que chaque caractéristique peut prendre sont automatiquement déduites du jeu de données et peuvent être trouvées dans l'attribut `categories_` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Europe', 'from US'], dtype=object),\n",
       " array(['uses Firefox', 'uses Safari'], dtype=object)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc.categories_\n",
    "# [array(['female', 'male'], dtype=object),\n",
    "#  array(['from Europe', 'from US'], dtype=object),\n",
    "#  array(['uses Firefox', 'uses Safari'], dtype=object)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de le spécifier explicitement à l'aide du paramètre `categories`. Il existe deux genres, quatre continents possibles et quatre navigateurs Web dans notre ensemble de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])\n",
    "# Note that for there are missing categorical values for the 2nd and 3rd\n",
    "# feature\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "# OneHotEncoder(categories=[['female', 'male'],\n",
    "#                           ['from Africa', 'from Asia', 'from Europe',\n",
    "#                            'from US'],\n",
    "#                           ['uses Chrome', 'uses Firefox', 'uses IE',\n",
    "#                            'uses Safari']])\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()\n",
    "# array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S'il est possible que les données d'entraînement aient des caractéristiques catégorielles manquantes, il peut souvent être préférable de spécifier `handle_unknown='infrequent_if_exist'` au lieu de définir les catégories manuellement comme ci-dessus. Lorsque `handle_unknown='infrequent_if_exist'` est spécifié et que des catégories inconnues sont rencontrées lors de la transformation, aucune erreur n'est générée, mais les colonnes encodées à chaud résultantes pour cette caractéristique sont toutes nulles ou considérées comme une catégorie peu fréquente si elle cette option est activée. (`handle_unknown='infrequent_if_exist'` n'est pris en charge que pour l'encodage one-hot) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='infrequent_if_exist')\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "# OneHotEncoder(handle_unknown='infrequent_if_exist')\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()\n",
    "# array([[1., 0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible d'encoder chaque colonne en `n_categories - 1` colonnes au lieu de `n_categories` colonnes en utilisant le paramètre `drop`. Ce paramètre permet à l'utilisateur de spécifier une catégorie pour chaque caractéristique à supprimer. Ceci est utile pour éviter la colinéarité dans la matrice d'entrée dans certains classificateurs. Une telle fonctionnalité est utile, par exemple, lors de l'utilisation d'une régression non régularisée ([**`LinearRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)), car la colinéarité rendrait la matrice de covariance non inversible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [['male', 'from US', 'uses Safari'],\n",
    "     ['female', 'from Europe', 'uses Firefox']]\n",
    "drop_enc = preprocessing.OneHotEncoder(drop='first').fit(X)\n",
    "drop_enc.categories_\n",
    "# [array(['female', 'male'], dtype=object), array(['from Europe', 'from US'], dtype=object),\n",
    "#  array(['uses Firefox', 'uses Safari'], dtype=object)]\n",
    "drop_enc.transform(X).toarray()\n",
    "# array([[1., 1., 1.],\n",
    "#        [0., 0., 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vouloir supprimer l'une des deux colonnes uniquement pour les caractéristiques à 2 catégories. Dans ce cas, vous pouvez définir le paramètre `drop='if_binary'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [['male', 'US', 'Safari'],\n",
    "     ['female', 'Europe', 'Firefox'],\n",
    "     ['female', 'Asia', 'Chrome']]\n",
    "drop_enc = preprocessing.OneHotEncoder(drop='if_binary').fit(X)\n",
    "drop_enc.categories_\n",
    "# [array(['female', 'male'], dtype=object), array(['Asia', 'Europe', 'US'], dtype=object),\n",
    "#  array(['Chrome', 'Firefox', 'Safari'], dtype=object)]\n",
    "drop_enc.transform(X).toarray()\n",
    "# array([[1., 0., 0., 1., 0., 0., 1.],\n",
    "#        [0., 0., 1., 0., 0., 1., 0.],\n",
    "#        [0., 1., 0., 0., 1., 0., 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le `X` transformé, la première colonne est encode la caractéristique avec les catégories \"masculin\"/\"féminin\", tandis que les 6 colonnes restantes encodent les 2 caractéristiques avec respectivement 3 catégories chacune.\n",
    "\n",
    "Lorsque `handle_unknown='ignore'` et que `drop` n'est pas `None`, les catégories inconnues seront encodées en zéros :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_enc = preprocessing.OneHotEncoder(drop='first',\n",
    "                                       handle_unknown='ignore').fit(X)\n",
    "X_test = [['unknown', 'America', 'IE']]\n",
    "drop_enc.transform(X_test).toarray()\n",
    "# array([[0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les catégories dans `X_test` sont inconnues lors de la transformation et seront mappées sur tous les zéros. Cela signifie que les catégories inconnues auront la même correspondance que la catégorie supprimée. : `OneHotEncoder.inverse_transform` mappera tous les zéros sur la catégorie supprimée si une catégorie est supprimée et `None` si une catégorie n'est pas supprimée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:188: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['female', None, None]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop_enc = preprocessing.OneHotEncoder(drop='if_binary', sparse=False,\n",
    "                                       handle_unknown='ignore').fit(X)\n",
    "X_test = [['unknown', 'America', 'IE']]\n",
    "X_trans = drop_enc.transform(X_test)\n",
    "X_trans\n",
    "# array([[0., 0., 0., 0., 0., 0., 0.]])\n",
    "drop_enc.inverse_transform(X_trans)\n",
    "# array([['female', None, None]], dtype=object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`OneHotEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) prend en charge les caractéristiques catégorielles avec des valeurs manquantes en considérant les valeurs manquantes comme une catégorie supplémentaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [['male', 'Safari'],\n",
    "     ['female', None],\n",
    "     [np.nan, 'Firefox']]\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown='error').fit(X)\n",
    "enc.categories_\n",
    "# [array(['female', 'male', nan], dtype=object),\n",
    "#  array(['Firefox', 'Safari', None], dtype=object)]\n",
    "enc.transform(X).toarray()\n",
    "# array([[0., 1., 0., 0., 1., 0.],\n",
    "#        [1., 0., 0., 0., 0., 1.],\n",
    "#        [0., 0., 1., 1., 0., 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si une caractéristique contient à la fois `np.nan` et `None`, elles seront considérées comme des catégories distinctes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [['Safari'], [None], [np.nan], ['Firefox']]\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown='error').fit(X)\n",
    "enc.categories_\n",
    "# [array(['Firefox', 'Safari', None, nan], dtype=object)]\n",
    "enc.transform(X).toarray()\n",
    "# array([[0., 1., 0., 0.],\n",
    "#        [0., 0., 1., 0.],\n",
    "#        [0., 0., 0., 1.],\n",
    "#        [1., 0., 0., 0.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [**Chargement de caractéristiques** (6.2.1)](https://scikit-learn.org/stable/modules/feature_extraction.html#dict-feature-extraction) à partir de dicts pour des caractéristiques catégorielles représentées sous forme de dictionnaires, et non sous forme de scalaires."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='infrequent-categories'></a> 6.3.4.1. Catégories peu fréquentes\n",
    "\n",
    "[**`OneHotEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) prend en charge l'agrégation de catégories peu fréquentes en une seule sortie pour chaque caractéristique. Les paramètres permettant de rassembler les catégories peu fréquentes sont `min_frequency` et `max_categories`.\n",
    "\n",
    "1. `min_frequency` est soit un entier supérieur ou égal à 1, soit un flottant dans l'intervalle `(0.0, 1.0)`. Si `min_frequency` est un entier, les catégories avec une cardinalité inférieure à `min_frequency` seront considérées comme peu fréquentes. Si `min_frequency` est un flottant, les catégories avec une cardinalité inférieure à cette fraction du nombre total d'échantillons seront considérées comme peu fréquentes. La valeur par défaut est 1, ce qui signifie que chaque catégorie est encodée séparément.\n",
    "\n",
    "2. `max_categories` vaut `None` ou tout entier supérieur à 1. Ce paramètre définit une limite supérieure au nombre de caractéristiques en sortie pour chaque caractéristique en entrée. `max_categories` inclut la caractéristique qui combine des catégories peu fréquentes.\n",
    "\n",
    "Dans l'exemple suivant, les catégories `dog`, `snake` sont considérées comme peu fréquentes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([['dog'] * 5 + ['cat'] * 20 + ['rabbit'] * 10 +\n",
    "              ['snake'] * 3], dtype=object).T\n",
    "enc = preprocessing.OneHotEncoder(min_frequency=6, sparse=False).fit(X)\n",
    "enc.infrequent_categories_\n",
    "# [array(['dog', 'snake'], dtype=object)]\n",
    "enc.transform(np.array([['dog'], ['cat'], ['rabbit'], ['snake']]))\n",
    "# array([[0., 0., 1.],\n",
    "#        [1., 0., 0.],\n",
    "#        [0., 1., 0.],\n",
    "#        [0., 0., 1.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En définissant `handle_unknown` sur `'infrequent_if_exist'`, les catégories inconnues seront considérées comme peu fréquentes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(\n",
    "    handle_unknown='infrequent_if_exist', sparse=False, min_frequency=6)\n",
    "enc = enc.fit(X)\n",
    "enc.transform(np.array([['dragon']]))\n",
    "# array([[0., 0., 1.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`OneHotEncoder.get_feature_names_out`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder.get_feature_names_out) utilise `'infrequent'` pour désigner les caractéristiques peu fréquentes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_cat', 'x0_rabbit', 'x0_infrequent_sklearn'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc.get_feature_names_out()\n",
    "# array(['x0_cat', 'x0_rabbit', 'x0_infrequent_sklearn'], dtype=object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque `'handle_unknown'` est défini sur `'infrequent_if_exist'` et qu'une catégorie inconnue est rencontrée dans la transformation :\n",
    "\n",
    "1. Si la prise en charge de la catégorie peu fréquente n'a pas été configurée ou s'il n'y avait pas de catégorie peu fréquente pendant l'entraînement, les colonnes encodées à chaud résultantes pour cette caractéristique seront toutes des zéros. Dans la transformation inverse, une catégorie inconnue sera notée `None`.\n",
    "\n",
    "2. S'il y a une catégorie peu fréquente pendant l'entraînement, la catégorie inconnue sera considérée comme peu fréquente. Dans la transformation inverse, \"infrequent_sklearn\" sera utilisé pour représenter la catégorie peu fréquente.\n",
    "\n",
    "Les catégories peu fréquentes peuvent également être configurées à l'aide de `max_categories`. Dans l'exemple suivant, nous définissons `max_categories=2` pour limiter le nombre de caractéristiques dans la sortie. Il en résultera que toutes les catégories sauf la catégorie `'cat'` seront considérées comme peu fréquentes, ce qui conduira à deux caractéristiques, une pour les catégories `'cat'` et une pour les catégories peu fréquentes - qui sont toutes les autres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(max_categories=2, sparse=False)\n",
    "enc = enc.fit(X)\n",
    "enc.transform([['dog'], ['cat'], ['rabbit'], ['snake']])\n",
    "# array([[0., 1.],\n",
    "#        [1., 0.],\n",
    "#        [0., 1.],\n",
    "#        [0., 1.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si `max_categories` et `min_frequency` ne sont pas des valeurs par défaut, les catégories sont sélectionnées en fonction de `min_frequency` en premier et les catégories `max_categories` sont conservées. Dans l'exemple suivant, `min_frequency=4` considère que seul `snake` est peu fréquent, mais `max_categories=3`, force `dog` à être également peu fréquent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder(min_frequency=4, max_categories=3, sparse=False)\n",
    "enc = enc.fit(X)\n",
    "enc.transform([['dog'], ['cat'], ['rabbit'], ['snake']])\n",
    "# array([[0., 0., 1.],\n",
    "#        [1., 0., 0.],\n",
    "#        [0., 1., 0.],\n",
    "#        [0., 0., 1.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S'il existe des catégories peu fréquentes avec la même cardinalité au seuil de `max_categories`, alors les premières `max_categories` sont prises en fonction de l'ordre du lexique. Dans l'exemple suivant, « b », « c » et « d » ont la même cardinalité et avec `max_categories=2`, « b » et « c » sont peu fréquents car ils ont un ordre de lexique plus élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['b', 'c'], dtype=object)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.asarray([[\"a\"] * 20 + [\"b\"] * 10 + [\"c\"] * 10 + [\"d\"] * 10], dtype=object).T\n",
    "enc = preprocessing.OneHotEncoder(max_categories=3).fit(X)\n",
    "enc.infrequent_categories_\n",
    "# [array(['b', 'c'], dtype=object)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.5. Discrétisation\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aff9e50adfaa9e30c910fb3872ffdc72747acb5f50803ca0504f00e980f7c25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
