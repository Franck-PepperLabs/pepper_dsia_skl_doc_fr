{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='supervised-learning'></a> 1. [**Apprentissage supervis√©**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_supervised_learning.ipynb#supervised-learning)</br>([*Supervised learning*](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='kernel-ridge-regression'></a> 1.3. **R√©gression ridge par noyau**<br/>([_Kernel ridge regression_](https://scikit-learn.org/stable/modules/kernel_ridge.html))\n",
    "\n",
    "La r√©gression ridge par noyau (KRR) [M2012] combine [**la r√©gression et la classification Ridge** (1.1.2)](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression) (moindres carr√©s lin√©aires avec r√©gularisation $\\ell_2$) avec la [**technique du noyau**](https://en.wikipedia.org/wiki/Kernel_method). Elle apprend ainsi une fonction lin√©aire dans l'espace induit par le noyau respectif et les donn√©es. Pour les noyaux non lin√©aires, cela correspond √† une fonction non lin√©aire dans l'espace d'origine.\n",
    "\n",
    "La forme du mod√®le appris par [**`KernelRidge`**](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge) est identique √† la r√©gression des vecteurs de support ([**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)). Cependant, diff√©rentes fonctions de perte sont utilis√©es : KRR utilise la perte d'erreur quadratique tandis que la r√©gression des vecteurs de support utilise la perte $\\epsilon$-insensitive, toutes deux combin√©es avec une r√©gularisation $\\ell_2$. Contrairement √† [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR), l'ajustement de [**`KernelRidge`**](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge) peut se faire sous forme ferm√©e et est g√©n√©ralement plus rapide pour des ensembles de donn√©es de taille moyenne. D'autre part, le mod√®le appris n'est pas parcimonieux et donc plus lent que [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR), qui apprend un mod√®le parcimonieux pour $\\epsilon > 0$, au moment de la pr√©diction.\n",
    "\n",
    "La figure suivante compare [**`KernelRidge`**](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge) et [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) sur un ensemble de donn√©es artificiel, compos√© d'une fonction cible sinuso√Ødale et de bruit important ajout√© √† chaque cinqui√®me point de donn√©es. Le mod√®le appris de [**`KernelRidge`**](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge) et [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) est repr√©sent√©, o√π √† la fois la complexit√©/la r√©gularisation et la bande passante du noyau RBF ont √©t√© optimis√©es par recherche sur grille. Les fonctions apprises sont tr√®s similaires ; cependant, l'ajustement de [**`KernelRidge`**](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge) est environ sept fois plus rapide que l'ajustement de [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) (toutes deux avec recherche sur grille). Cependant, la pr√©diction de 100 000 valeurs cibles est plus de trois fois plus rapide avec [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR), car il a appris un mod√®le parcimonieux en n'utilisant qu'environ 1/3 des 100 points de donn√©es d'entra√Ænement comme vecteurs de support.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_kernel_ridge_regression_001.png\"\n",
    "    alt=\"SVR versus Kernel Ridge\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "La figure suivante compare le temps n√©cessaire pour l'ajustement et la pr√©diction de [**`KernelRidge`**](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge) et [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) pour diff√©rentes tailles de l'ensemble d'entra√Ænement. L'ajustement de [**`KernelRidge`**](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge) est plus rapide que [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) pour les ensembles d'entra√Ænement de taille moyenne (moins de 1000 √©chantillons) ; cependant, pour des ensembles d'entra√Ænement plus grands, [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) s'√©chelonne mieux. En ce qui concerne le temps de pr√©diction, [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) est plus rapide que [**`KernelRidge`**](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge) pour toutes les tailles de l'ensemble d'entra√Ænement en raison de la solution parcimonieuse apprise. Notez que le degr√© de parcimonie et donc le temps de pr√©diction d√©pendent des param√®tres et de [**`SVR`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) ; il correspondrait √† un mod√®le dense.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_kernel_ridge_regression_002.png\"\n",
    "    alt=\"SVR versus Kernel Ridge Execution Time\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "### R√©f√©rences\n",
    "\n",
    "üìö [M2012] [**\"Machine Learning: A Probabilistic Perspective\"**](https://github.com/probml/pml-book/blob/main/transition-guide-2012-to-2022.pdf) Murphy, K. P. - chapitre 14.4.3, pp. 492-493, The MIT Press, 2012"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
