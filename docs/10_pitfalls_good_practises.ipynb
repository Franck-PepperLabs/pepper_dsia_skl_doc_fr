{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✔ 10\\. [**Pièges courants et pratiques recommandées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb)<br/>([*Common pitfalls and recommended practices*](https://scikit-learn.org/stable/common_pitfalls.html))\n",
    "\n",
    "Le but de ce chapitre est d'illustrer certains pièges et anti-modèles courants qui se produisent lors de l'utilisation de scikit-learn. Il fournit des exemples de ce qu'il **ne faut pas** faire, ainsi qu'un exemple correct correspondant.\n",
    "\n",
    "\n",
    "✔ 10.1. [**Prétraitement incohérent**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#inconsistent-preprocessing)\n",
    "([*Inconsistent preprocessing*](https://scikit-learn.org/stable/common_pitfalls.html#inconsistent-preprocessing))\n",
    "\n",
    "✔ 10.2. [**Fuite de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#data-leakage)\n",
    "([*Data leakage*](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage))\n",
    "* ✔ 10.2.1. [**Fuite de données lors du prétraitement**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#data-leakage-during-pre-processing)\n",
    "([*Data leakage during pre-processing*](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage-during-pre-processing))\n",
    "* ✔ 10.2.2. [**Comment éviter les fuites de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#how-to-avoid-data-leakage)\n",
    "([*How to avoid data leakage*](https://scikit-learn.org/stable/common_pitfalls.html#how-to-avoid-data-leakage))\n",
    "\n",
    "✔ 10.3. [**Contrôle de l'aléatoire**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#controlling-randomness)\n",
    "([*Controlling randomness*](https://scikit-learn.org/stable/common_pitfalls.html#controlling-randomness))\n",
    "* ✔ 10.3.1. [**Utilisation d'instances None ou RandomState, et appels répétés pour ajuster et diviser**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#using-none-or-randomstate-instances-and-repeated-calls-to-fit-and-split)\n",
    "([*Using None or RandomState instances, and repeated calls to fit and split*](https://scikit-learn.org/stable/common_pitfalls.html#using-none-or-randomstate-instances-and-repeated-calls-to-fit-and-split))\n",
    "* ✔ 10.3.2. [**Pièges et subtilités courants**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#common-pitfalls-and-subtleties)\n",
    "([*Common pitfalls and subtleties*](https://scikit-learn.org/stable/common_pitfalls.html#common-pitfalls-and-subtleties))\n",
    "* ✔ 10.3.3. [**Recommandations générales**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#general-recommendations)\n",
    "([*General recommendations*](https://scikit-learn.org/stable/common_pitfalls.html#general-recommendations))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='common-pitfalls-and-recommended-practices'></a> 10.1. Prétraitement incohérent\n",
    "\n",
    "scikit-learn fournit une bibliothèque de [**transformations d'ensembles de données** (6)](https://scikit-learn.org/stable/data_transforms.html#data-transforms), qui peuvent nettoyer (voir [**Prétraitement des données** (6.3)](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)), réduire (voir [**Réduction de dimensionnalité non supervisée** (6.5)](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#data-reduction)), étendre (voir [**Approximation du noyau** (6.7)](https://scikit-learn.org/stable/modules/kernel_approximation.html#kernel-approximation)) ou générer (voir [**Extraction de caractéristiques** (6.2)](https://scikit-learn.org/stable/modules/feature_extraction.html#feature-extraction)) des représentations de caractéristiques. Si ces transformations de données sont utilisées lors de l'entraînement' d'un modèle, elles doivent également être utilisées sur les ensembles de données suivants, qu'il s'agisse de données de test ou de données dans un système de production. Sinon, l'espace des caractéristiques changera et le modèle ne pourra pas fonctionner efficacement.\n",
    "\n",
    "Pour l'exemple suivant, créons un jeu de données synthétique avec une seule caractéristique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "X, y = make_regression(random_state=random_state, n_features=1, noise=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A ne pas faire**\n",
    "\n",
    "L'ensemble de données d'entraînement est mis à l'échelle, mais pas l'ensemble de données de test, de sorte que les performances du modèle sur l'ensemble de données de test sont moins bonnes que prévu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.80867119249539"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "model = LinearRegression().fit(X_train_transformed, y_train)\n",
    "mean_squared_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Correct**\n",
    "\n",
    "Au lieu de passer le `X_test` non transformé à `predict`, nous devrions transformer les données de test, de la même manière que nous avons transformé les données d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902797546636954"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed = scaler.transform(X_test)\n",
    "mean_squared_error(y_test, model.predict(X_test_transformed))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativement, nous recommandons d'utiliser un [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline), qui facilite l'enchaînement des transformations avec les estimateurs, et réduit la possibilité d'oublier une transformation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902797546636954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline #, Pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "# Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "#               ('linearregression', LinearRegression())])\n",
    "mean_squared_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les pipelines permettent également d'éviter un autre écueil courant : la fuite des données de test dans les données d'apprentissage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data-leakage'></a>\n",
    "\n",
    "# 10.2. Fuite de données\n",
    "\n",
    "Une fuite de données se produit lorsque des informations qui ne seraient pas disponibles au moment de la prédiction sont utilisées lors de la construction du modèle. Cela se traduit par des estimations de performances trop optimistes, par exemple à partir de la [3.1. validation croisée](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation), et donc des performances plus faibles lorsque le modèle est utilisé sur des données réellement nouvelles, par exemple pendant la production.\n",
    "\n",
    "Une cause courante est de ne pas séparer les sous-ensembles de données de test et d'entraînement. Les données de test ne doivent jamais être utilisées pour faire des choix sur le modèle. **La règle générale est de ne jamais appeler** `fit` **sur les données de test**. Bien que cela puisse sembler évident, il est facile de passer à côté dans certains cas, par exemple lors de l'application de certaines étapes de prétraitement.\n",
    "\n",
    "Bien que les sous-ensembles de données d'apprentissage et de test doivent recevoir la même transformation de prétraitement (comme décrit dans la section précédente), il est important que ces transformations ne soient apprises qu'à partir des données d'apprentissage. Par exemple, si vous avez une étape de normalisation dans laquelle vous divisez par la valeur moyenne, la moyenne doit être la moyenne du sous-ensemble d'nentraînement, et non la moyenne de toutes les données. Si le sous-ensemble de test est inclus dans le calcul de la moyenne, les informations du sous-ensemble de test influencent le modèle.\n",
    "\n",
    "Un exemple de fuite de données lors du prétraitement est détaillé ci-dessous."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data-leakage-during-pre-processing'></a>\n",
    "\n",
    "## 10.2.1. Fuite de données lors du prétraitement\n",
    "\n",
    "**NB** - Nous choisissons ici d'illustrer la fuite de données avec une étape de sélection des caractéristiques. Ce risque de fuite est cependant pertinent avec presque toutes les transformations dans scikit-learn, y compris (mais sans s'y limiter) [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler), [`SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer) et [`PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA).\n",
    "\n",
    "Un certain nombre de [1.13. fonctions de sélection de caractéristiques](https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection) sont disponibles dans scikit-learn. Elles peuvent aider à supprimer les caractéristiques non pertinentes, redondantes et bruyantes, ainsi qu'à améliorer le temps de construction et les performances de votre modèle. Comme pour tout autre type de prétraitement, la sélection des caractéristiques ne doit utiliser que les données d'apprentissage. L'inclusion des données de test dans la sélection des caractéristiques biaisera votre modèle de manière optimiste.\n",
    "\n",
    "Pour le démontrer, nous allons créer ce problème de classification binaire avec 10 000 caractéristiques générées aléatoirement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_samples, n_features, n_classes = 200, 10000, 2\n",
    "rng = np.random.RandomState(42)\n",
    "X = rng.standard_normal((n_samples, n_features))\n",
    "y = rng.choice(n_classes, n_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A ne pas faire**\n",
    "\n",
    "L'utilisation de toutes les données pour effectuer la sélection des caractéristiques donne un score de précision bien supérieur au hasard, même si nos cibles sont complètement aléatoires. Ce caractère aléatoire signifie que nos `X` et `y` sont indépendants et nous nous attendons donc à ce que la précision soit d'environ 0,5. Cependant, puisque l'étape de sélection des caractéristiques \"voit\" les données de test, le modèle a un avantage injuste. Dans l'exemple incorrect ci-dessous, nous utilisons d'abord toutes les données pour la sélection des caractéristiques, puis nous divisons les données en sous-ensembles d'apprentissage et de test pour l'ajustement du modèle. Le résultat est un score de précision beaucoup plus élevé que prévu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Incorrect preprocessing: the entire data is transformed\n",
    "X_selected = SelectKBest(k=25).fit_transform(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, random_state=42)\n",
    "gbc = GradientBoostingClassifier(random_state=1)\n",
    "gbc.fit(X_train, y_train)\n",
    "# GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "y_pred = gbc.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correct**\n",
    "\n",
    "Pour éviter les fuites de données, il est recommandé de diviser d'abord vos données en sous-ensembles d'entraînement et de test. La sélection dde caractéristiques peut ensuite être entraînée en utilisant uniquement l'ensemble de données d'apprentissage. Notez que chaque fois que nous utilisons `fit` ou `fit_transform`, nous n'utilisons que le jeu de données d'apprentissage. Le score est à présent ce à quoi nous nous attendions pour les données, proche du hasard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)\n",
    "select = SelectKBest(k=25)\n",
    "X_train_selected = select.fit_transform(X_train, y_train)\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=1)\n",
    "gbc.fit(X_train_selected, y_train)\n",
    "# GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "X_test_selected = select.transform(X_test)\n",
    "y_pred = gbc.predict(X_test_selected)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là encore, nous vous recommandons d'utiliser un [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) pour enchaîner la sélection de caractéristiques et les estimateurs de modèle. Le pipeline garantit que seules les données d'entraînement sont utilisées lors de l'ajustement et que les données de test sont utilisées uniquement pour calculer le score de précision :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)\n",
    "pipeline = make_pipeline(SelectKBest(k=25),\n",
    "    GradientBoostingClassifier(random_state=1))\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Pipeline(steps=[('selectkbest', SelectKBest(k=25)),\n",
    "#                ('gradientboostingclassifier',\n",
    "#                GradientBoostingClassifier(random_state=1))])\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le pipeline peut également être introduit dans une fonction de validation croisée telle que [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score). Là encore, le pipeline garantit que le sous-ensemble de données et la méthode d'estimation corrects sont utilisés lors de l'ajustement et de la prédiction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.45+/-0.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipeline, X, y)\n",
    "print(f\"Mean accuracy: {scores.mean():.2f}+/-{scores.std():.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='how-to-avoid-data-leakage'></a>\n",
    "\n",
    "## 10.2.2. Comment éviter les fuites de données\n",
    "\n",
    "Voici quelques conseils pour éviter les fuites de données :\n",
    "\n",
    "* Commencez toujours par diviser les données en sous-ensembles d'entraînement et de test, en particulier avant toute étape de prétraitement.\n",
    "\n",
    "* N'incluez jamais de données de test lorsque vous utilisez les méthodes `fit` et `fit_transform`. L'utilisation de toutes les données, par exemple `fit(X)`, peut entraîner des scores trop optimistes.\n",
    "\n",
    "* À l'inverse, la méthode de transformation doit être utilisée à la fois sur les sous-ensembles d'entraînement et de test, car le même prétraitement doit être appliqué à toutes les données. Ceci peut être réalisé en utilisant `fit_transform` sur le sous-ensemble d'entraînement et `transform` sur le sous-ensemble de test.\n",
    "\n",
    "* Le [6.1.1. pipeline](https://scikit-learn.org/stable/modules/compose.html#pipeline) scikit-learn est un excellent moyen d'éviter les fuites de données car il garantit que la méthode appropriée est exécutée sur le sous-ensemble de données approprié. Le pipeline est idéal pour une utilisation dans les fonctions de validation croisée et de réglage des hyperparamètres."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='controlling-randomness'></a>\n",
    "\n",
    "# 10.3. Contrôler l'aléatoire | Controlling randomness\n",
    "\n",
    "Certains objets scikit-learn sont intrinsèquement aléatoires. Il s'agit généralement d'estimateurs (par exemple, [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)) et de séparateurs de validation croisée (par exemple, [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)). Le caractère aléatoire de ces objets est contrôlé via leur paramètre `random_state`, comme décrit dans le glossaire. Cette section développe l'entrée du glossaire et décrit les bonnes pratiques et les pièges courants par rapport à à ce paramètre subtil.\n",
    "\n",
    "**NB** Résumé de la recommandation\n",
    "\n",
    "Pour une robustesse optimale des résultats de la validation croisée (CV), transmettez des instances RandomState lors de la création d'estimateurs, ou laissez `random_state` sur None. Passer des entiers aux séparateurs de CV est généralement l'option la plus sûre et est préférable ; le passage d'instances RandomState à des séparateurs peut parfois être utile pour atteindre des cas d'utilisation très spécifiques. Pour les estimateurs et les séparateurs, la transmission d'un entier par rapport à la transmission d'une instance (ou `None`) entraîne des différences subtiles mais significatives, en particulier pour les procédures CV. Il est important de comprendre ces différences lors de la communication des résultats.\n",
    "\n",
    "Pour des résultats reproductibles d'une exécution à l'autre, supprimez toute utilisation de `random_state=None`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='using-none-or-randomstate-instances-and-repeated-calls-to-fit-and-split'></a>\n",
    "\n",
    "## 10.3.1. Utilisation d'instances `None` ou `RandomState`, et appels répétés à `fit` et `split`\n",
    "\n",
    "Le paramètre `random_state` détermine si plusieurs appels à [`fit`](https://scikit-learn.org/stable/glossary.html#term-fit) (pour les estimateurs) ou à [`split`](https://scikit-learn.org/stable/glossary.html#term-split) (pour les séparateurs de CV) produiront les mêmes résultats, selon ces règles :\n",
    "\n",
    "* Si un entier est passé, appeler `fit` ou `split` plusieurs fois donne toujours les mêmes résultats.\n",
    "* Si `None` ou une instance `RandomState` est passée : `fit` et `split` donneront des résultats différents à chaque appel, et la succession d'appels explore toutes les sources d'entropie. `None` est la valeur par défaut pour tous les paramètres `random_state`.\n",
    "\n",
    "Nous illustrons ici ces règles pour les estimateurs et les séparateurs de CV.\n",
    "\n",
    "**NB** Puisque passer `random_state=None` équivaut à passer l'instance globale `RandomState` de `numpy` (`random_state=np.random.mtrand._rand`), nous ne mentionnerons pas explicitement `None` ici. Tout ce qui s'applique aux instances s'applique également à l'utilisation de `None`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimateurs\n",
    "\n",
    "Passer des instances signifie qu'appeler `fit` plusieurs fois ne donnera pas les mêmes résultats, même si l'estimateur est ajusté sur les mêmes données et avec les mêmes hyper-paramètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.70814003,  5.25291366, -7.55212743,  5.18197458,  1.37845099]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X, y = make_classification(n_features=5, random_state=rng)\n",
    "sgd = SGDClassifier(random_state=rng)\n",
    "\n",
    "sgd.fit(X, y).coef_\n",
    "# array([[ 8.85418642,  4.79084103, -3.13077794,  8.11915045, -0.56479934]])\n",
    "\n",
    "sgd.fit(X, y).coef_\n",
    "# array([[ 6.70814003,  5.25291366, -7.55212743,  5.18197458,  1.37845099]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir à partir de l'extrait ci-dessus que l'appel répété à `sgd.fit` a produit différents modèles, même si les données étaient les mêmes. En effet, le générateur de nombres aléatoires (RNG) de l'estimateur est consommé (c'est-à-dire muté) lorsque `fit` est appelé, et ce RNG muté sera utilisé dans les appels ultérieurs à `fit`. De plus, l'objet `rng` est partagé par tous les objets qui l'utilisent et, par conséquent, ces objets deviennent quelque peu interdépendants. Par exemple, deux estimateurs qui partagent la même instance `RandomState` s'influenceront mutuellement, comme nous le verrons plus tard lorsque nous discuterons du clonage. Ce point est important à garder à l'esprit lors du débogage.\n",
    "\n",
    "Si nous avions passé un entier au paramètre `random_state` du [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier), nous aurions obtenu les mêmes modèles, et donc les mêmes scores à chaque fois. Lorsque nous passons un entier, le même RNG est utilisé dans tous les appels à `fit`. Ce qui se passe en interne, c'est que même si le RNG est consommé lorsque `fit` est appelé, il est toujours réinitialisé à son état d'origine au début de `fit`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparateurs de CV\n",
    "\n",
    "Les séparateurs de CV aléatoires ont un comportement similaire lorsqu'une instance `RandomState` est transmise ; appeler `split` plusieurs fois donne différentes divisions de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "X = y = np.arange(10)\n",
    "rng = np.random.RandomState(0)\n",
    "cv = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "        print(train, test)\n",
    "# [0 3 5 6 7] [1 2 4 8 9]\n",
    "# [1 2 4 8 9] [0 3 5 6 7]\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "        print(train, test)\n",
    "# [0 4 6 7 8] [1 2 3 5 9]\n",
    "# [1 2 3 5 9] [0 4 6 7 8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que les divisions sont différentes à partir de la deuxième fois que `split` est appelée. Cela peut conduire à des résultats inattendus si vous comparez les performances de plusieurs estimateurs en appelant plusieurs fois `split`, comme nous le verrons dans la section suivante."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='common-pitfalls-and-subtleties'></a>\n",
    "\n",
    "## 10.3.2. Pièges et subtilités courants\n",
    "\n",
    "Bien que les règles qui régissent le paramètre `random_state` soient apparemment simples, elles ont cependant des implications subtiles. Dans certains cas, cela peut même conduire à des conclusions erronées.\n",
    "\n",
    "### Estimateurs\n",
    "\n",
    "#### Différents types ``random_state`` conduisent à différentes procédures de validation croisée\n",
    "\n",
    "Selon le type du paramètre `random_state`, les estimateurs se comporteront différemment, en particulier dans les procédures de validation croisée. Considérez l'extrait suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9 , 0.95, 0.95, 0.9 , 0.9 ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "\n",
    "rf_123 = RandomForestClassifier(random_state=123)\n",
    "cross_val_score(rf_123, X, y)\n",
    "# array([0.85, 0.95, 0.95, 0.9 , 0.9 ])\n",
    "\n",
    "rf_inst = RandomForestClassifier(random_state=np.random.RandomState(0))\n",
    "cross_val_score(rf_inst, X, y)\n",
    "# array([0.9 , 0.95, 0.95, 0.9 , 0.9 ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que les scores validés croisés de `rf_123` et `rf_inst` sont différents, comme on pouvait s'y attendre puisque nous n'avons pas passé le même paramètre `random_state`. Cependant, la différence entre ces scores est plus subtile qu'il n'y paraît, et **les procédures de validation croisée qui ont été effectuées par [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) diffèrent considérablement dans chaque cas** :\n",
    "\n",
    "* Puisque `rf_123` a reçu un entier, chaque appel à fit utilise le même RNG : cela signifie que toutes les caractéristiques aléatoires de l'estimateur de forêt aléatoire seront les mêmes pour chacun des 5 plis de la procédure CV. En particulier, le sous-ensemble (choisi au hasard) de caractéristiques de l'estimateur sera le même dans tous les plis.\n",
    "\n",
    "* Étant donné que `rf_inst` a reçu une instance `RandomState`, chaque appel à `fit` démarre à partir d'un RNG différent. En conséquence, le sous-ensemble aléatoire de caractéristiques sera différent pour chaque pli.\n",
    "\n",
    "Bien qu'avoir un RNG d'estimateur constant à travers les plis ne soit pas intrinsèquement faux, nous voulons généralement des résultats de CV qui sont robustes en ce qui concerne le caractère aléatoire de l'estimateur. Par conséquent, passer une instance au lieu d'un entier peut être préférable, car cela permettra à l'estimateur RNG de varier pour chaque pli."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clonage\n",
    "\n",
    "Un autre effet secondaire subtil du passage d'instances `RandomState` est le fonctionnement de `clone` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "a = RandomForestClassifier(random_state=rng)\n",
    "b = clone(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisqu'une instance `RandomState` a été passée à `a`, `a` et `b` ne sont pas des clones au sens strict, mais plutôt des clones au sens statistique : `a` et `b` seront toujours des modèles différents, même en appelant `fit(X, y)` sur les mêmes données . De plus, `a` et `b` s'influenceront mutuellement puisqu'ils partagent le même RNG interne : appeler `a.fit` consommera le RNG de `b`, et appeler `b.fit` consommera le RNG de `a`, puisqu'ils sont identiques. Ce petit peu est vrai pour tous les estimateurs qui partagent un paramètre `random_state` ; elle n'est pas spécifique aux clones.\n",
    "\n",
    "Si un entier était passé, `a` et `b` seraient des clones exacts et ils ne s'influenceraient pas l'un l'autre.\n",
    "\n",
    "**Avertissement** - Même si `clone` est rarement utilisé dans le code utilisateur, il est appelé de manière omniprésente dans la base de code scikit-learn : en particulier, la plupart des méta-estimateurs qui acceptent des estimateurs non ajustés appellent `clone` en interne ([`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), [`StackingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier), [`CalibratedClassifierCV`](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV), etc.)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparateurs de CV\n",
    "\n",
    "Lorsqu'une instance `RandomState` est transmise, les séparateurs de CV génèrent des divisions différentes à chaque fois que `split` est appelée. Lorsque l'on compare différents estimateurs, cela peut conduire à surestimer la variance de la différence de performance entre les estimateurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8  0.75 0.75 0.7  0.85]\n",
      "[0.85 0.95 0.95 0.85 0.95]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X, y = make_classification(random_state=rng)\n",
    "cv = KFold(shuffle=True, random_state=rng)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "nb = GaussianNB()\n",
    "\n",
    "for est in (lda, nb):\n",
    "    print(cross_val_score(est, X, y, cv=cv))\n",
    "# [0.8  0.75 0.75 0.7  0.85]\n",
    "# [0.85 0.95 0.95 0.85 0.95]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer directement les performances de l'estimateur [`LinearDiscriminantAnalysis`](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis) vs l'estimateur [`GaussianNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) sur **chaque pli** serait une erreur : **les splits sur lesquels les estimateurs sont évalués sont différents**. En effet, [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) appellera en interne `cv.split` sur la même instance de [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold), mais les splits seront différents à chaque fois. Cela est également vrai pour tout outil qui effectue une sélection de modèle via une validation croisée, par ex. [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) et [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV) : les scores ne sont pas comparables entre les différents appels à `search.fit`, car `cv.split` aurait été appelé plusieurs fois. Dans un seul appel à `search.fit`, cependant, la comparaison de pli à pli est possible puisque l'estimateur de recherche n'appelle `cv.split` qu'une seule fois.\n",
    "\n",
    "Pour obtenir des résultats pli à pli comparables dans tous les scénarios, il convient de transmettre un entier au séparateur de CV : `cv = KFold(shuffle=True, random_state=0)`.\n",
    "\n",
    "**NB** - Bien que la comparaison pli à pli ne soit pas recommandée avec les instances `RandomState`, on peut cependant s'attendre à ce que les scores moyens permettent de conclure si un estimateur est meilleur qu'un autre, tant que suffisamment de plis et de données sont utilisés.\n",
    "\n",
    "**NB** - Ce qui compte dans cet exemple, c'est ce qui a été passé à [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold). Que nous transmettions une instance `RandomState` ou un entier à [`make_classification`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification) n'est pas pertinent pour notre objectif d'illustration. De plus, ni [`LinearDiscriminantAnalysis`](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis) ni [`GaussianNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) ne sont des estimateurs randomisés."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='general-recommendations'></a>\n",
    "\n",
    "## 10.3.3. Recommandations générales\n",
    "\n",
    "<a id='getting-reproducible-results-across-multiple-executions'></a>\n",
    "\n",
    "### Obtenir des résultats reproductibles sur plusieurs exécutions\n",
    "\n",
    "Afin d'obtenir des résultats reproductibles (c'est-à-dire constants) sur plusieurs *exécutions de programme*, nous devons supprimer toutes les utilisations de `random_state=None`, qui est la valeur par défaut. La méthode recommandée consiste à déclarer une variable `rng` en haut du programme et à la transmettre à tout objet acceptant un paramètre `random_state` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X, y = make_classification(random_state=rng)\n",
    "rf = RandomForestClassifier(random_state=rng)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=rng)\n",
    "rf.fit(X_train, y_train).score(X_test, y_test)\n",
    "# 0.84"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes désormais assurés que le résultat de ce script sera toujours de 0,84, quel que soit le nombre de fois que nous l'exécuterons. La modification de la variable globale `rng` à une valeur différente devrait affecter les résultats, comme prévu.\n",
    "\n",
    "Il est également possible de déclarer la variable `rng` comme un entier. Cela peut cependant conduire à des résultats de validation croisée moins robustes, comme nous le verrons dans la section suivante.\n",
    "\n",
    "**NB** - Nous ne recommandons pas de définir la graine `numpy` globale en appelant `np.random.seed(0)`. Voir [ici](https://stackoverflow.com/questions/5836335/consistently-create-same-random-numpy-array/5837352#comment6712034_5837352) pour une discussion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='robustness-of-cross-validation-results'></a>\n",
    "\n",
    "### Robustesse des résultats de la validation croisée\n",
    "\n",
    "Lorsque nous évaluons les performances d'un estimateur randomisé par validation croisée, nous voulons nous assurer que l'estimateur peut produire des prédictions précises pour de nouvelles données, mais nous voulons également nous assurer que l'estimateur est robuste en ce qui concerne son initialisation aléatoire. Par exemple, nous aimerions que l'initialisation des poids aléatoires d'un `SGDCLassifier` soit toujours bonne dans tous les plis : sinon, lorsque nous entraînons cet estimateur sur de nouvelles données, nous risquons d'avoir de la malchance et l'initialisation aléatoire peut entraîner de mauvaises performances. De même, nous voulons qu'une forêt aléatoire soit robuste par rapport à l'ensemble de caractéristiques sélectionnées au hasard que chaque arbre utilisera.\n",
    "\n",
    "Pour ces raisons, il est préférable d'évaluer les performances de la validation croisée en laissant l'estimateur utiliser un RNG différent sur chaque pli. Cela se fait en passant une instance `RandomState` (ou `None`) à l'initialisation de l'estimateur.\n",
    "\n",
    "Lorsque nous passons un entier, l'estimateur utilisera le même RNG sur chaque pli : si l'estimateur fonctionne bien (ou mal), tel qu'évalué par CV, c'est peut-être simplement parce que nous avons eu de la chance (ou de la malchance) avec cette graine spécifique. Le passage d'instances conduit à des résultats de CV plus robustes et rend la comparaison entre différents algorithmes plus juste. **Cela aide également à limiter la tentation de traiter le RNG de l'estimateur comme un hyper-paramètre qui peut être réglé**.\n",
    "\n",
    "Que nous transmettions des instances `RandomState` ou des entiers aux séparateurs de CV n'a aucun impact sur la robustesse, tant que split n'est appelé qu'une seule fois. Lorsque split est appelé plusieurs fois, la comparaison pli à pli n'est plus possible. Par conséquent, le passage d'un entier aux séparateurs de CV est généralement plus sûr et couvre la plupart des cas d'utilisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e03b612d84ba21ce95ed447e81b3062e1eb99b56c6d885cdab4aaa12f1b8e240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
