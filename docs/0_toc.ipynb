{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif d'accès rapide.\n",
    "\n",
    "Objectif d'apprentissage des vocabulaires FR | EN mis en correspondance.\n",
    "\n",
    "Et pour le temps du reste à étudier et traduire, pour point d'avancement / reste à faire.\n",
    "\n",
    "# TODO LIST\n",
    "\n",
    "* Compléter la TOC v1 (FR | EN)\n",
    "* ✔ Ajouter des ancres\n",
    "    * soluce : https://stackoverflow.com/questions/38132862/html-anchors-in-a-jupyter-notebook-on-github\n",
    "* Déporter les exemples dans le dossier examples et leur ajouter un index préfixe\n",
    "* Scinder le chapitre 1, dans un premier temps en un nb par niveau 2 (niveau 3 plus tard si pertinent)\n",
    "* Recommit\n",
    "* Liens vers Github (c'est très lisible)\n",
    "* Pointer le fait et le reste à faire\n",
    "\n",
    "# Chapitres et sections\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Apprentissage supervisé** | [Supervised learning](https://scikit-learn.org/stable/supervised_learning.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Modèles linéaires | [Linear Models](https://scikit-learn.org/stable/modules/linear_model.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Moindres carrés ordinaires | [Ordinary Least Squares]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Régression et classification de crête | [Ridge regression and classification]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Lasso | [Lasso]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4. Lasso multi-tâches | [Multi-task Lasso]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5. Elastic-Net | [Elastic-Net]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6. Elastic-Net multi-tâches | [Multi-task Elastic-Net]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7. Régression au moindre angle (LAR) | [Least Angle Regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.8. LARS Lasso | [LARS Lasso]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.9. Poursuite par correspondance orthogonale (OMP) | [Orthogonal Matching Pursuit]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.10. Régression bayésienne | [Bayesian Regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.11. Régression logistique | [Logistic regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.12. Régression linéaire généralisée (GLR) | [Generalized Linear Regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.13. Descente de gradient stochastique (SGD) | [Stochastic Gradient Descent]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.14. Perceptron | [Perceptron]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.15. Algorithmes passifs agressifs | [Passive Aggressive Algorithms]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.16. Régression de robustesse : valeurs aberrantes et erreurs de modélisation | [Robustness regression: outliers and modeling errors]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.17. Régression quantile | [Quantile Regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.18. Régression polynomiale : extension des modèles linéaires avec des fonctions de base | [Polynomial regression: extending linear models with basis functions](https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Analyse discriminante linéaire et quadratique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Régression de crête à noyau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Machines à vecteurs de support"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Descente de gradient stochastique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Plus proches voisins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Processus gaussiens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Décomposition croisée"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9. Bayes naïf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10. Arbres de décision | [Decision Trees](https://scikit-learn.org/stable/modules/tree.html#)\n",
    "\n",
    "* 1.10.1. Classification | [Classification](https://scikit-learn.org/stable/modules/tree.html#classification)\n",
    "* 1.10.2. Régression | [Regression](https://scikit-learn.org/stable/modules/tree.html#regression)\n",
    "* 1.10.3. Problèmes multi-sorties | [Multi-output problems](https://scikit-learn.org/stable/modules/tree.html#multi-output-problems)\n",
    "* 1.10.4. Complexité | [Complexity](https://scikit-learn.org/stable/modules/tree.html#complexity)\n",
    "* 1.10.5. Conseils d'utilisation pratique | [Tips on practical use](https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use)\n",
    "* 1.10.6. Algorithmes d'arbre : ID3, C4.5, C5.0 et CART | [Tree algorithms: ID3, C4.5, C5.0 and CART](https://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart)\n",
    "* 1.10.7. Formulation mathématique | [Mathematical formulation](https://scikit-learn.org/stable/modules/tree.html#mathematical-formulation)\n",
    "* 1.10.8. Élagage à coût-complexité minimal | [Minimal Cost-Complexity Pruning](https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11. Méthodes ensemblistes\n",
    "\n",
    "* 1.11.1. Méta-estimateur de bagging | Bagging meta-estimator\n",
    "* 1.11.2. Forêts d'arbres aléatoires | Forests of randomized trees\n",
    "* 1.11.3. AdaBoost | AdaBoost\n",
    "* 1.11.4. Amélioration de l'arbre par gradient | Gradient Tree Boosting\n",
    "* 1.11.5. Amplification du gradient basée sur l'histogramme | Histogram-Based Gradient Boosting\n",
    "* 1.11.6. Classifieur de vote | Voting Classifier\n",
    "* 1.11.7. Régresseur de vote | Voting Regressor\n",
    "* 1.11.8. Généralisation empilée | Stacked generalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12. Algorithmes multiclasses et multisorties | Multiclass and multioutput algorithms\n",
    "\n",
    "* 1.12.1. Classification multiclasse | Multiclass classification\n",
    "* 1.12.2. Classement multilabel | Multilabel classification\n",
    "* 1.12.3. Classification multiclasses-multisorties | Multiclass-multioutput classification\n",
    "* 1.12.4. Régression multi-sorties | Multioutput regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13. Sélection de caractéristiques\n",
    "\n",
    "* 1.13.1. Suppression des caractéristiques à faible variance | Removing features with low variance\n",
    "* 1.13.2. Sélection de caractéristiques univariées | Univariate feature selection\n",
    "* 1.13.3. Élimination récursive des caractéristiques | Recursive feature elimination\n",
    "* 1.13.4. Sélection de caractéristiques à l'aide de SelectFromModel | Feature selection using SelectFromModel\n",
    "* 1.13.5. Sélection séquentielle des caractéristiques | Sequential Feature Selection\n",
    "* 1.13.6. Sélection de caractéristiques dans le cadre d'un pipeline | Feature selection as part of a pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14. Apprentissage semi-supervisé | Semi-supervised learning\n",
    "\n",
    "* 1.14.1. Auto entrainement | Self Training\n",
    "* 1.14.2. Propagation des étiquettes | Label Propagation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15. Régression isotonique | Isotonic regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.16. Étalonnage de probabilité | Probability calibration\n",
    "\n",
    "* 1.16.1. Courbes d'étalonnage | Calibration curves\n",
    "* 1.16.2. Calibrer un classifieur | Calibrating a classifier\n",
    "* 1.16.3. Usage | Usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.17. Modèles de réseaux de neurones (supervisés) | Neural network models (supervised)\n",
    "\n",
    "* 1.17.1. Perceptron multicouche | Multi-layer Perceptron\n",
    "* 1.17.2. Classification | Classification\n",
    "* 1.17.3. Régression | Regression\n",
    "* 1.17.4. Régularisation | Regularization\n",
    "* 1.17.5. Algorithmes | Algorithms\n",
    "* 1.17.6. Complexité | Complexity\n",
    "* 1.17.7. Formulation mathématique | Mathematical formulation\n",
    "* 1.17.8. Conseils d'utilisation pratique | Tips on Practical Use\n",
    "* 1.17.9. Plus de contrôle avec warm_start | More control with warm_start\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Unsupervised learning**\n",
    "\n",
    "## 2.1. Modèles de mélange gaussien | Gaussian mixture models\n",
    "\n",
    "* 2.1.1. Mélange gaussien | Gaussian Mixture\n",
    "* 2.1.2. Mélange gaussien bayésien variationnel | Variational Bayesian Gaussian Mixture\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 2.2. [**Apprentissage des variétés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_2_manifold.ipynb)</br>([*Manifold learning*](https://scikit-learn.org/stable/modules/manifold.html))\n",
    "\n",
    "* ✔ 2.2.1. Introduction\n",
    "* ✔ 2.2.2. Isocarte\n",
    "* ✔ 2.2.3. Incorporation localement linéaire (LLE))\n",
    "* ✔ 2.2.4. Incorporation localement linéaire modifiée (MLLE)\n",
    "* ✔ 2.2.5. LLE Hessien (HLLE, Hessian Eigenmapping)\n",
    "* ✔ 2.2.6. Intégration spectrale (Spectral Embedding)\n",
    "* ✔ 2.2.7. Alignement de l'espace tangent local (LTSA)\n",
    "* ✔ 2.2.8. Analyse en dimensions multiples (MDS)\n",
    "* ✔ 2.2.9. Algorithme t-SNE\n",
    "* ✔ 2.2.10. Conseils d'utilisation pratique\n",
    "\n",
    "Compléments :\n",
    "\n",
    "* Wikipédia :\n",
    "    * [Variété (géométrie)](https://fr.wikipedia.org/wiki/Variété_(géométrie)) | [Manifold](https://en.wikipedia.org/wiki/Manifold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. [**Partitionnement**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_3_clustering.ipynb)</br>([*Clustering*](https://scikit-learn.org/stable/modules/clustering.html))\n",
    "\n",
    "* 2.3.1. Présentation des méthodes de partitionnement | Overview of clustering methods\n",
    "* 2.3.2. K-moyennes | K-means\n",
    "* 2.3.3. Propagation par affinité | Affinity Propagation\n",
    "* 2.3.4. Décalage moyen | Mean Shift\n",
    "* 2.3.5. Partitionnement spectral | Spectral clustering\n",
    "* 2.3.6. Partitionnement hiérarchique | Hierarchical clustering\n",
    "* 2.3.7. DBSCAN | DBSCAN\n",
    "* 2.3.8. OPTICS | OPTICS\n",
    "* 2.3.9. BIRCH | BIRCH\n",
    "* 2.3.10. Évaluation des performances de partitionnement | Clustering performance evaluation\n",
    "\n",
    "Compléments :\n",
    "\n",
    "* Wikipédia :\n",
    "    * [K-moyennes](https://fr.wikipedia.org/wiki/K-moyennes) | [$k$-means clustering](https://en.wikipedia.org/wiki/K-means_clustering)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Classification double | Biclustering\n",
    "\n",
    "* 2.4.1. Co-classification spectrale | Spectral Co-Clustering\n",
    "* 2.4.2. Classification double spectrale | Spectral Biclustering\n",
    "* 2.4.3. Évaluation de la classification double | Biclustering evaluation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 2.5. [**Décomposer les signaux en composantes (problèmes de factorisation matricielle)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb)</br>([*Decomposing signals in components (matrix factorization problems)*](https://scikit-learn.org/stable/modules/decomposition.html))\n",
    "\n",
    "* **Volume** : 26 pages, 19 exemples\n",
    "\n",
    "✔ 2.5.1 [**Analyse en composantes principales (ACP)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#principal-component-analysis-pca)\n",
    "([*Principal component analysis (PCA)*](https://scikit-learn.org/stable/modules/decomposition.html#principal-component-analysis-pca))\n",
    "* **Volume** : 8 pages, 6 exemples\n",
    "\n",
    "✔ 2.5.2. [**Analyse en composantes principales à noyau (kACP)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#kernel-principal-component-analysis-kpca)\n",
    "([*Kernel Principal Component Analysis (kPCA)*](https://scikit-learn.org/stable/modules/decomposition.html#kernel-principal-component-analysis-kpca))\n",
    "* **Volume** : 2 pages, 1 exemples\n",
    "\n",
    "✔ 2.5.3. [**Décomposition en valeurs singulières tronquées et analyse sémantique latente**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#truncated-singular-value-decomposition-and-latent-semantic-analysis)\n",
    "([*Truncated singular value decomposition and latent semantic analysis*](https://scikit-learn.org/stable/modules/decomposition.html#truncated-singular-value-decomposition-and-latent-semantic-analysis))\n",
    "* **Volume** : 1 pages, 1 exemples\n",
    "\n",
    "✔ 2.5.4. [**Apprentissage de dictionnaire**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#dictionary-learning)\n",
    "([*Dictionary Learning*](https://scikit-learn.org/stable/modules/decomposition.html#dictionary-learning))\n",
    "* **Volume** : 4 pages, 3 exemples\n",
    "\n",
    "✔ 2.5.5. [**Analyse factorielle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#factor-analysis)\n",
    "([*Factor Analysis*](https://scikit-learn.org/stable/modules/decomposition.html#factor-analysis))\n",
    "* **Volume** : 3 pages, 2 exemples\n",
    "\n",
    "✔ 2.5.6. [**Analyse en composantes indépendantes (ICA)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#independent-component-analysis-ica)\n",
    "([*Independent component analysis (ICA)*](https://scikit-learn.org/stable/modules/decomposition.html#independent-component-analysis-ica))\n",
    "* **Volume** : 1 pages, 3 exemples\n",
    "\n",
    "✔ 2.5.7. [**Factorisation matricielle non négative (NMF ou NNMF)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#non-negative-matrix-factorization-nmf-or-nnmf)\n",
    "([*Non-negative matrix factorization (NMF or NNMF)*](https://scikit-learn.org/stable/modules/decomposition.html#non-negative-matrix-factorization-nmf-or-nnmf))\n",
    "* **Volume** : 4 pages, 3 exemples\n",
    "\n",
    "✔ 2.5.8. [**Allocation de Dirichlet latente (LDA)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#latent-dirichlet-allocation-lda)\n",
    "([*Latent Dirichlet Allocation (LDA)*](https://scikit-learn.org/stable/modules/decomposition.html#latent-dirichlet-allocation-lda))\n",
    "* **Volume** : 3 pages, 1 exemples\n",
    "\n",
    "Compléments :\n",
    "\n",
    "* Wikipédia :\n",
    "    * [**Allocation de Dirichlet latente**](https://fr.wikipedia.org/wiki/Allocation_de_Dirichlet_latente)<br/>([*Latent Dirichlet allocation*](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Estimation de la covariance| Covariance estimation\n",
    "\n",
    "* 2.6.1. Covariance empirique | Empirical covariance\n",
    "* 2.6.2. Covariance réduite | Shrunk Covariance\n",
    "* 2.6.3. Covariance inverse parcimonieuse | Sparse inverse covariance\n",
    "* 2.6.4. Estimation robuste de la covariance | Robust Covariance Estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Détection de nouveauté et de valeurs aberrantes | Novelty and Outlier Detection\n",
    "\n",
    "* 2.7.1. Présentation des méthodes de détection des valeurs aberrantes | Overview of outlier detection methods\n",
    "* 2.7.2. Détection de nouveauté | Novelty Detection\n",
    "* 2.7.3. Détection des valeurs aberrantes | Outlier Detection\n",
    "* 2.7.4. Détection de nouveauté avec Local Outlier Factor | Novelty detection with Local Outlier Factor\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Estimation de la densité | Density Estimation\n",
    "\n",
    "* 2.8.1. Estimation de la densité : histogrammes | Density Estimation: Histograms\n",
    "* 2.8.2. Estimation de la densité du noyau (KDE) | Kernel Density Estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Modèles de réseaux de neurones (non supervisés) | Neural network models (unsupervised)\n",
    "\n",
    "* 2.9.1. Machines Boltzmann restreintes | Restricted Boltzmann machines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _3. Model selection and evaluation\n",
    "\n",
    "3.1. Cross-validation: evaluating estimator performance\n",
    "\n",
    "3.2. Tuning the hyper-parameters of an estimator\n",
    "\n",
    "3.3. Metrics and scoring: quantifying the quality of predictions\n",
    "\n",
    "3.4. Validation curves: plotting scores to evaluate models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 4. [**Inspection**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb)</br>([*Inspection*](https://scikit-learn.org/stable/inspection.html))\n",
    "\n",
    "La performance prédictive est souvent l'objectif principal du développement de modèles d'apprentissage automatique. Pourtant, résumer les performances avec une métrique d'évaluation est souvent insuffisant : cela suppose que la métrique d'évaluation et l'ensemble de données de test reflètent parfaitement le domaine cible, ce qui est rarement vrai. Dans certains domaines, un modèle a besoin d'un certain niveau d'interprétabilité avant de pouvoir être déployé. Un modèle qui présente des problèmes de performances doit être débogué pour comprendre le problème sous-jacent du modèle. Le module sklearn.inspection fournit des outils pour aider à comprendre les prédictions d'un modèle et ce qui les affecte. Cela peut être utilisé pour évaluer les hypothèses et les biais d'un modèle, concevoir un meilleur modèle ou diagnostiquer les problèmes de performances du modèle.\n",
    "\n",
    "✔ 4.1. [**Graphiques de dépendance partielle et d'espérance conditionnelle individuelle**](https://scikit-learn.org/stable/modules/partial_dependence.html)\n",
    "\n",
    "* ✔ 4.1.1. Graphiques de dépendance partielle\n",
    "* ✔ 4.1.2. Diagramme d'espérance conditionnelle individuelle (ICE)\n",
    "* ✔ 4.1.3. Définition mathématique\n",
    "* ✔ 4.1.4. Méthodes de calcul\n",
    "\n",
    "✔ 4.2. [**Importance des caractéristiques de permutation**](https://scikit-learn.org/stable/modules/permutation_importance.html)\n",
    "\n",
    "* ✔ 4.2.1. Aperçu de l'algorithme d'importance de permutation\n",
    "* ✔ 4.2.2. Relation avec l'importance basée sur les impuretés dans les arbres\n",
    "* ✔ 4.2.3. Valeurs trompeuses sur les caractéristiques fortement corrélées\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 5. [**Visualisations**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb)</br>([*Visualizations*](https://scikit-learn.org/stable/visualizations.html))\n",
    "\n",
    "Scikit-learn définit une API simple pour créer des visualisations pour l'apprentissage automatique. La principale caractéristique de cette API est de permettre un traçage rapide et des ajustements visuels sans recalcul. Nous fournissons des classes `Display` qui exposent deux méthodes de création de tracés : `from_estimator` et `from_predictions`.\n",
    "\n",
    "✔ 5.0. [**Exemples**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#examples)\n",
    "\n",
    "✔ 5.1. [**Utilitaires de traçage disponibles**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#available-plotting-utilities)\n",
    "([Available Plotting Utilities](https://scikit-learn.org/stable/visualizations.html#available-plotting-utilities))\n",
    "\n",
    "* ✔ 5.1.1. [**Fonctions**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#functions)\n",
    "([*Functions*](https://scikit-learn.org/stable/visualizations.html#functions))\n",
    "\n",
    "* ✔ 5.1.1. [**Objets d'affichage**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#display-objects)\n",
    "([*Display Objects*](https://scikit-learn.org/stable/visualizations.html#display-objects))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\\. [**Transformations d'ensembles de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_dataset_transformations.ipynb)</br>([*Dataset transformations*](https://scikit-learn.org/stable/data_transforms.html))\n",
    "\n",
    "* **Volume** : 89 pages, 32 exemples\n",
    "* **Reste** : 24 pages, 3 exemples\n",
    "\n",
    "✔ 6.1. [**Pipelines et estimateurs composites**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_1_compose.ipynb)\n",
    "([*Pipelines and composite estimators*](https://scikit-learn.org/stable/modules/compose.html))\n",
    "* **Volume** : 13 pages, 12 exemples\n",
    "* ✔ 6.1.1. [**Pipeline : chaînage d'estimateurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_1_compose.ipynb#pipeline-chaining-estimators)\n",
    "([*Pipeline: chaining estimators*](https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators))\n",
    "* ✔ 6.1.2. [**Transformation de la cible en régression**]()\n",
    "([*Transforming target in regression*]())\n",
    "* ✔ 6.1.3. [**FeatureUnion: composite feature spaces**]()\n",
    "([*FeatureUnion : espaces d'entités composites*]()) \n",
    "* ✔ 6.1.4. [**ColumnTransformer pour les données hétérogènes**]()\n",
    "([*ColumnTransformer for heterogeneous data*]())\n",
    "* ✔ 6.1.5. [**Visualisation des estimateurs composites**]()\n",
    "([*Visualizing Composite Estimators*]())\n",
    "\n",
    "✔ 6.2. [**Extraction de caractéristiques**]()\n",
    "([*Feature extraction*]())\n",
    "* **Volume** : 23 pages, 8 exemples\n",
    "* ✔ 6.2.1. [**Chargement de fonctionnalités à partir de dicts**]()\n",
    "([*Loading features from dicts*]())\n",
    "* ✔ 6.2.2. [**Hachage des fonctionnalités**]()\n",
    "([*Feature hashing*]())\n",
    "* ✔ 6.2.3. [**Extraction de caractéristiques de texte**]()\n",
    "([*Text feature extraction*]())\n",
    "* ✔ 6.2.4. [**Extraction de caractéristiques d'image**]()\n",
    "([*Image feature extraction*]())\n",
    "\n",
    "✔ 6.3. [**Prétraitement des données**]()\n",
    "([*Preprocessing data*]())\n",
    "* **Volume** : 26 pages, 5 exemples\n",
    "* ✔ 6.3.1. [**Standardisation, ou suppression de la moyenne et mise à l'échelle de la variance**]()\n",
    "([*Standardization, or mean removal and variance scaling*]())\n",
    "* ✔ 6.3.2. [**Transformation non linéaire**]()\n",
    "([*Non-linear transformation*]())\n",
    "* ✔ 6.3.3. [**Normalisation**]()\n",
    "([*Normalization*]())\n",
    "* ✔ 6.3.4. [**Encodage des caractéristiques catégorielles**]()\n",
    "([*Encoding categorical features*]())\n",
    "* ✔ 6.3.5. [**Discrétisation**]()\n",
    "([*Discretization*]())\n",
    "* ✔ 6.3.6. [**Imputation des valeurs manquantes**]()\n",
    "([*Imputation of missing values*]())\n",
    "* ✔ 6.3.7. [**Génération de caractéristiques polynomiales**]()\n",
    "([*Generating polynomial features*]())\n",
    "* ✔ 6.3.8. [**Transformateurs personnalisés**]()\n",
    "([*Custom transformers*]())\n",
    "\n",
    "✔ 6.4. [**Imputation des valeurs manquantes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#imputation-of-missing-values)\n",
    "([*Imputation of missing values*](https://scikit-learn.org/stable/modules/impute.html))\n",
    "* **Volume** : 8 pages, 2 exemples, 3 papiers\n",
    "* ✔ 6.4.1. [**Imputation univariée vs imputation multivariée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#univariate-vs-multivariate-imputation)\n",
    "([*Univariate vs. Multivariate Imputation*](https://scikit-learn.org/stable/modules/impute.html#univariate-vs-multivariate-imputation))\n",
    "* ✔ 6.4.2. [**Imputation de caractéristique univariée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#univariate-feature-imputation)\n",
    "([*Univariate feature imputation*](https://scikit-learn.org/stable/modules/impute.html#univariate-feature-imputation))\n",
    "* ✔ 6.4.3. [**Imputation de caractéristiques multivariées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#multivariate-feature-imputation)\n",
    "([*Multivariate feature imputation*](https://scikit-learn.org/stable/modules/impute.html#multivariate-feature-imputation))\n",
    "* ✔ 6.4.4. [**Imputation des plus proches voisins**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#nearest-neighbors-imputation)\n",
    "([*Nearest neighbors imputation*](https://scikit-learn.org/stable/modules/impute.html#nearest-neighbors-imputation))\n",
    "* ✔ 6.4.5. [**Maintenir le nombre de caractéristiques constant**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#keeping-the-number-of-features-constants)\n",
    "([*Keeping the number of features constants*](https://scikit-learn.org/stable/modules/impute.html#keeping-the-number-of-features-constants))\n",
    "* ✔ 6.4.6. [**Marquage des valeurs imputées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#marking-imputed-values)\n",
    "([*Marking imputed values*](https://scikit-learn.org/stable/modules/impute.html#marking-imputed-values))\n",
    "* ✔ 6.4.7. [**Estimateurs qui gèrent les valeurs NaN**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#estimators-that-handle-nan-values)\n",
    "([*Estimators that handle NaN values*](https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values))\n",
    "\n",
    "✔ 6.5. [**Réduction de dimensionnalité non supervisée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_5_unsupervised_reduction.ipynb)\n",
    "([*Unsupervised dimensionality reduction*](https://scikit-learn.org/stable/modules/unsupervised_reduction.html))\n",
    "* **Volume** : 1 pages, 4 exemples\n",
    "* ✔ 6.5.1. [**ACP : analyse en composantes principales**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_5_unsupervised_reduction.ipynb#pca-principal-component-analysis)\n",
    "([*PCA: principal component analysis*](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#pca-principal-component-analysis))\n",
    "* ✔ 6.5.2. [**Projections aléatoires**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_5_unsupervised_reduction.ipynb#random-projections)\n",
    "([*Random projections*](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#random-projections))\n",
    "* ✔ 6.5.3. [**Agglomération de fonctionnalités**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_5_unsupervised_reduction.ipynb#feature-agglomeration)\n",
    "([*Feature agglomeration*](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#feature-agglomeration))\n",
    "\n",
    "✘ 6.6. [**Projection aléatoire**]()\n",
    "([*Random Projection*]())\n",
    "* **Volume** : 5 pages, 1 exemples\n",
    "* **Reste** : 5 pages, 1 exemples\n",
    "* ✘ 6.6.1. [**Le lemme de Johnson-Lindenstrauss**]()\n",
    "([*The Johnson-Lindenstrauss lemma*]())\n",
    "* ✘ 6.6.2. [**Projection aléatoire gaussienne**]()\n",
    "([*Gaussian random projection*]())\n",
    "* ✘ 6.6.3. [**Projection aléatoire parcimonieuse**]()\n",
    "([*Sparse random projection*]())\n",
    "* ✘ 6.6.4. [**Transformation inverse**]()\n",
    "([*Inverse Transform*]())\n",
    "\n",
    "✘ 6.7. [**Approximation du noyau**]()\n",
    "([*Kernel Approximation*]())\n",
    "* **Volume** : 6 pages, 2 exemples\n",
    "* **Reste** : 6 pages, 2 exemples\n",
    "* ✘ 6.7.1. [**Méthode Nystroem pour l'approximation du noyau**]()\n",
    "([*Nystroem Method for Kernel Approximation*]())\n",
    "* ✘ 6.7.2. [**Noyau de fonction de base radiale**]()\n",
    "([*Radial Basis Function Kernel*]())\n",
    "* ✘ 6.7.3. [**Additif Chi Squared Kernel**]()\n",
    "([*Additive Chi Squared Kernel*]())\n",
    "* ✘ 6.7.4. [**Noyau au carré de chi asymétrique**]()\n",
    "([*Skewed Chi Squared Kernel*]())\n",
    "* ✘ 6.7.5. [**Approximation du noyau polynomial via Tensor Sketch**]()\n",
    "([*Polynomial Kernel Approximation via Tensor Sketch*]())\n",
    "* ✘ 6.7.6. [**Détails mathématiques**]()\n",
    "([*Mathematical Details*]())\n",
    "\n",
    "✘ 6.8. [**Métriques par paires, affinités et noyaux**]()\n",
    "([*Pairwise metrics, Affinities and Kernels*]())\n",
    "* **Volume** : 5 pages, 0 exemples\n",
    "* **Reste** : 5 pages, 0 exemples\n",
    "* ✘ 6.8.1. [**Similitude cosinus**]()\n",
    "([*Cosine similarity*]())\n",
    "* ✘ 6.8.2. [**Noyau linéaire**]()\n",
    "([*Linear kernel*]())\n",
    "* ✘ 6.8.3. [**Noyau polynomial**]()\n",
    "([*Polynomial kernel*]())\n",
    "* ✘ 6.8.4. [**Noyau sigmoïde**]()\n",
    "([*Sigmoid kernel*]())\n",
    "* ✘ 6.8.5. [**Noyau RBF**]()\n",
    "([*RBF kernel*]())\n",
    "* ✘ 6.8.6. [**Noyau laplacien**]()\n",
    "([*Laplacian kernel*]())\n",
    "* ✘ 6.8.7. [**Noyau du chi carré**]()\n",
    "([*Chi-squared kernel*]())\n",
    "\n",
    "✔ 6.9. [**Transformation de la cible de prédiction (y)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_9_preprocessing_targets.ipynb)\n",
    "([*Transforming the prediction target (y)*](https://scikit-learn.org/stable/modules/preprocessing_targets.html))\n",
    "* **Volume** : 2 pages, 0 exemples\n",
    "* ✔ 6.9.1. [**Binarisation des étiquettes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_9_preprocessing_targets.ipynb#label-binarization)\n",
    "([*Label binarization*](https://scikit-learn.org/stable/modules/preprocessing_targets.html#label-binarization))\n",
    "* ✔ 6.9.2. [**Encodage des étiquettes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_9_preprocessing_targets.ipynb#label-encoding)\n",
    "([*Label encoding*](https://scikit-learn.org/stable/modules/preprocessing_targets.html#label-encoding))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✘ 7. [**Utilitaires de chargement de jeux de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb)</br>([*Dataset loading utilities*](https://scikit-learn.org/stable/datasets.html))\n",
    "\n",
    "* **Volume** : 35 pages, 6 exemples, 28 papiers\n",
    "\n",
    "Attention, les exemples sont sous-estimés. Pour parcourir l'ensemble des exemples utilisant tel ou tel jeu de données intégré, consulter la page de documentation de chaque méthode de chargement.\n",
    "\n",
    "✔ 7.1. [**Jeux de données jouets**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#toy_dataset)\n",
    "([*Toy datasets*](https://scikit-learn.org/stable/datasets/toy_dataset.html))\n",
    "* **Volume** : 11 pages, 0 exemples, 22 papiers\n",
    "* ✔ 7.1.1. [**Jeu de données des plantes d'Iris**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#iris-plants-dataset)\n",
    "([*Iris plants dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-plants-dataset))\n",
    "* ✔ 7.1.2. [**Jeu de données sur le diabète**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#diabetes-dataset)\n",
    "([*Diabetes dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset))\n",
    "* ✔ 7.1.3. [**Jeu de données de reconnaissance optique de chiffres écrits à la main**](https://scikit-learn.org/stable/datasets/toy_dataset.html#optical-recognition-of-handwritten-digits-dataset)\n",
    "([*Optical recognition of handwritten digits dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#optical-recognition-of-handwritten-digits-dataset))\n",
    "* ✔ 7.1.4. [**Jeu de données de Linnerrud**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#linnerrud-dataset)\n",
    "([*Linnerrud dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#linnerrud-dataset))\n",
    "* ✔ 7.1.5. [**Jeu de données de reconnaissance de vins**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#wine-recognition-dataset)\n",
    "([*Wine recognition dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset))\n",
    "* ✔ 7.1.6. [**Jeu de données du Wisconsin pour le diagnostic du cancer du sein**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#breast-cancer-wisconsin-diagnostic-dataset)\n",
    "([*Breast cancer Wisconsin (diagnostic) dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset))\n",
    "\n",
    "✔ 7.2. [**Jeux de données du monde réel**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#real-world-datasets)\n",
    "([*Real world datasets*](https://scikit-learn.org/stable/datasets/real_world.html#real-world-datasets))\n",
    "* **Volume** : 15 pages, 5 exemples, 5 papiers\n",
    "* ✔ 7.2.1. [**Jeu de données des visages Olivetti**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-olivetti-faces-dataset)\n",
    "([*The Olivetti faces dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-olivetti-faces-dataset))\n",
    "* ✔ 7.2.2. [**Jeu de données de texte des 20 newsgroups**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-20-newsgroups-text-dataset)\n",
    "([*The 20 newsgroups text dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset))\n",
    "* ✔ 7.2.3. [**Jeu de données de reconnaissance faciale Labeled Faces in the Wild**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-labeled-faces-in-the-wild-face-recognition-dataset)\n",
    "([*The Labeled Faces in the Wild face recognition dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-labeled-faces-in-the-wild-face-recognition-dataset))\n",
    "* ✔ 7.2.4. [**Jeu de données des types de couverture forestière**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#forest-covertypes)\n",
    "([*Forest covertypes*](https://scikit-learn.org/stable/datasets/real_world.html#forest-covertypes))\n",
    "* ✔ 7.2.5. [**Jeu de données RCV1**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#rcv1-dataset)\n",
    "([*RCV1 dataset*](https://scikit-learn.org/stable/datasets/real_world.html#rcv1-dataset))\n",
    "* ✔ 7.2.6. [**Jeu de données Kddcup 99**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#kddcup-99-dataset)\n",
    "([*Kddcup 99 dataset*](https://scikit-learn.org/stable/datasets/real_world.html#kddcup-99-dataset))\n",
    "* ✔ 7.2.7. [**Jeu de données de l'immobilier californien**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#california-housing-dataset)\n",
    "([*California Housing dataset*](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset))\n",
    "\n",
    "✔ 7.3. [**Jeux de données générés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generated-datasets)\n",
    "([*Generated datasets*](https://scikit-learn.org/stable/datasets/sample_generators.html#generated-datasets))\n",
    "* **Volume** : 3 pages, 0 exemples, 0 papiers\n",
    "* ✔ 7.3.1. [**Générateurs pour la classification et le clustering**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-classification-and-clustering)\n",
    "([*Generators for classification and clustering*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-classification-and-clustering))\n",
    "* ✔ 7.3.2. [**Générateurs pour la régression**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-regression)\n",
    "([*Generators for regression*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-regression))\n",
    "* ✔ 7.3.3. [**Générateurs pour l'apprentissage de variétés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-manifold-learning)\n",
    "([*Generators for manifold learning*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-manifold-learning))\n",
    "* ✔ 7.3.4. [**Générateurs pour la décomposition**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-decomposition)\n",
    "([*Generators for decomposition*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-decomposition))\n",
    "\n",
    "✔ 7.4. [**Chargement d'autres jeux de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#loading-other-datasets)\n",
    "([*Loading other datasets*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#loading-other-datasets))\n",
    "* **Volume** : 6 pages, 1 exemples, 1 papiers\n",
    "* ✔ 7.4.1. [**Images d'exemple**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#sample-images)\n",
    "([*Sample images*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#sample-images))\n",
    "* ✔ 7.4.2. [**Jeux de données au format svmlight / libsvm**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#datasets-in-svmlight-libsvm-format)\n",
    "([*Datasets in svmlight / libsvm format*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#datasets-in-svmlight-libsvm-format))\n",
    "* ✔ 7.4.3. [**Téléchargement de jeux de données depuis le dépôt openml.org**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#downloading-datasets-from-the-openml-org-repository)\n",
    "([*Downloading datasets from the openml.org repository*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#downloading-datasets-from-the-openml-org-repository))\n",
    "* ✔ 7.4.4. [**Chargement depuis des jeux de données externes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#loading-from-external-datasets)\n",
    "([*Loading from external datasets*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#loading-from-external-datasets))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✘ 8\\. [**Calculer avec scikit-learn**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb)</br>([*Computing with scikit-learn*](https://scikit-learn.org/stable/computing.html))\n",
    "\n",
    "**Volume** : 21 pages, 2 exemples\n",
    "\n",
    "<mark>**Reste** : 2 exemples</mark>\n",
    "\n",
    "✔ 8.1. [**Stratégies de mise à l'échelle informatique : données plus volumineuses**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#strategies-to-scale-computationally-bigger-data)\n",
    "([*Strategies to scale computationally: bigger data*](https://scikit-learn.org/stable/computing.html#strategies-to-scale-computationally-bigger-data))\n",
    "* **Volume** : 4 pages, <mark>1 exemples</mark>\n",
    "* ✔ 8.1.1. [**Mise à l'échelle avec des instances utilisant l'apprentissage hors cœur**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#scaling-with-instances-using-out-of-core-learning)\n",
    "([*Scaling with instances using out-of-core learning*](https://scikit-learn.org/stable/computing.html#scaling-with-instances-using-out-of-core-learning))\n",
    "\n",
    "✔ 8.2. [**Performances informatiques**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#)\n",
    "([*Computational Performance*](https://scikit-learn.org/stable/computing.html#))\n",
    "* **Volume** : 11 pages, <mark>1 exemples</mark>\n",
    "* ✔ 8.2.1. [**Latence de prédiction**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#)\n",
    "([*Prediction Latency*](https://scikit-learn.org/stable/computing.html#))\n",
    "* ✔ 8.2.2. [**Débit de prédiction**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#)\n",
    "([*Prediction Throughput*](https://scikit-learn.org/stable/computing.html#))\n",
    "* ✔ 8.2.3. [**Trucs et astuces**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#)\n",
    "([*Tips and Tricks*](https://scikit-learn.org/stable/computing.html#))\n",
    "\n",
    "✔ 8.3. [**Parallélisme, gestion des ressources et configuration**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#)\n",
    "([*Parallelism, resource management, and configuration*]())\n",
    "* **Volume** : 6 pages, 0 exemples\n",
    "* ✔ 8.3.1. [**Parallélisme**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#)\n",
    "([*Parallelism*]())\n",
    "* ✔ 8.3.2. [**Commutateurs de configuration**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#)\n",
    "([*Configuration switches*]())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 9\\. [**Persistance de modèle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb)<br/>([*Model persistence*](https://scikit-learn.org/stable/model_persistence.html))\n",
    "\n",
    "**Volume** : 3 pages, 0 exemples\n",
    "\n",
    "✔ 9.1. [**Sérialisation spécifique Python**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb#python-specific-serialization)\n",
    "([*Python specific serialization*](https://scikit-learn.org/stable/model_persistence.html#python-specific-serialization))\n",
    "\n",
    "* ✔ 9.1.1. [**Limites de sécurité et de maintenabilité**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb#security-maintainability-limitations)\n",
    "([*Security & maintainability limitations*](https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations))\n",
    "\n",
    "✔ 9.2. [**Formats interopérables**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb#interoperable-formats)\n",
    "([*Interoperable formats*](https://scikit-learn.org/stable/model_persistence.html#interoperable-formats))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 10\\. [**Pièges courants et pratiques recommandées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb)<br/>([*Common pitfalls and recommended practices*](https://scikit-learn.org/stable/common_pitfalls.html))\n",
    "\n",
    "**Volume** : 12 pages, 0 exemples\n",
    "\n",
    "✔ 10.1. [**Prétraitement incohérent**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#inconsistent-preprocessing)\n",
    "([*Inconsistent preprocessing*](https://scikit-learn.org/stable/common_pitfalls.html#inconsistent-preprocessing))\n",
    "\n",
    "✔ 10.2. [**Fuite de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#data-leakage)\n",
    "([*Data leakage*](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage))\n",
    "* ✔ 10.2.1. [**Fuite de données lors du prétraitement**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#data-leakage-during-pre-processing)\n",
    "([*Data leakage during pre-processing*](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage-during-pre-processing))\n",
    "* ✔ 10.2.2. [**Comment éviter les fuites de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#how-to-avoid-data-leakage)\n",
    "([*How to avoid data leakage*](https://scikit-learn.org/stable/common_pitfalls.html#how-to-avoid-data-leakage))\n",
    "\n",
    "✔ 10.3. [**Contrôle de l'aléatoire**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#controlling-randomness)\n",
    "([*Controlling randomness*](https://scikit-learn.org/stable/common_pitfalls.html#controlling-randomness))\n",
    "* ✔ 10.3.1. [**Utilisation d'instances None ou RandomState, et appels répétés pour ajuster et diviser**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#using-none-or-randomstate-instances-and-repeated-calls-to-fit-and-split)\n",
    "([*Using None or RandomState instances, and repeated calls to fit and split*](https://scikit-learn.org/stable/common_pitfalls.html#using-none-or-randomstate-instances-and-repeated-calls-to-fit-and-split))\n",
    "* ✔ 10.3.2. [**Pièges et subtilités courants**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#common-pitfalls-and-subtleties)\n",
    "([*Common pitfalls and subtleties*](https://scikit-learn.org/stable/common_pitfalls.html#common-pitfalls-and-subtleties))\n",
    "* ✔ 10.3.3. [**Recommandations générales**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#general-recommendations)\n",
    "([*General recommendations*](https://scikit-learn.org/stable/common_pitfalls.html#general-recommendations))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 11\\. [**Répartition**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_dispatching.ipynb)<br/>([*Dispatching*](https://scikit-learn.org/stable/modules/array_api.html))\n",
    "\n",
    "**Reste** : 2 pages, 0 exemples\n",
    "\n",
    "✔ 11.1. [**Prise en charge de l'API Array (expérimental)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_1_array_api.ipynb#array-api-support-experimental) ([*Array API support (experimental)*](https://scikit-learn.org/stable/modules/array_api.html#array-api-support-experimental))\n",
    "* ✔ 11.1.1. [**Exemple d'utilisation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_1_array_api.ipynb#example-usage) ([*Example usage*](https://scikit-learn.org/stable/modules/array_api.html#example-usage))\n",
    "* ✔ 11.1.2. [**Estimateurs avec prise en charge des entrées compatibles avec l'API Array**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_1_array_api.ipynb#estimators-with-support-for-array-api-compatible-inputs) ([*Estimators with support for Array API-compatible inputs*](https://scikit-learn.org/stable/modules/array_api.html#estimators-with-support-for-array-api-compatible-inputs#estimators-with-support-for-array-api-compatible-inputs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrêt précoce de la descente de gradient stochastique\n",
    "\n",
    "User Guide | [Early stopping of Stochastic Gradient Descent](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_early_stopping.html?highlight=ignore_warnings#)\n",
    "\n",
    "Traduction | ... lien vers Github\n",
    "\n",
    "In :\n",
    "* [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aff9e50adfaa9e30c910fb3872ffdc72747acb5f50803ca0504f00e980f7c25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
