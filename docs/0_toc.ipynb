{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif d'accès rapide.\n",
    "\n",
    "Objectif d'apprentissage des vocabulaires FR | EN mis en correspondance.\n",
    "\n",
    "Et pour le temps du reste à étudier et traduire, pour point d'avancement / reste à faire.\n",
    "\n",
    "# TODO LIST\n",
    "\n",
    "* Compléter la TOC v1 (FR | EN)\n",
    "* ✔ Ajouter des ancres\n",
    "    * soluce : https://stackoverflow.com/questions/38132862/html-anchors-in-a-jupyter-notebook-on-github\n",
    "* Déporter les exemples dans le dossier examples et leur ajouter un index préfixe\n",
    "* Scinder le chapitre 1, dans un premier temps en un nb par niveau 2 (niveau 3 plus tard si pertinent)\n",
    "* Recommit\n",
    "* Liens vers Github (c'est très lisible)\n",
    "* Pointer le fait et le reste à faire\n",
    "\n",
    "# Chapitres et sections\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Apprentissage supervisé** | [Supervised learning](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "Nouvelle passe fin août, septembre 2023 : estimation de la charge :\n",
    "\n",
    "Partie 1 : tout est à réviser, mais une bonne partie reste à faire\n",
    "- Total : 189p, 112e, 118r\n",
    "- 1.1. Linear Models\n",
    "    - 33p, 30e, r40\n",
    "- 1.2. Linear and Quadratic Discriminant Analysis\n",
    "    - 6p, 3e, 3r\n",
    "- 1.3. Kernel ridge regression\n",
    "    - 2p, 0e, 1r\n",
    "- 1.4. Support Vector Machines\n",
    "    - 13p, 9e, 8r\n",
    "- 1.5. Stochastic Gradient Descent\n",
    "    - 11p, 6e, 7r\n",
    "- 1.6. Nearest Neighbors\n",
    "    - 16p, 9e, 3r\n",
    "- 1.7. Gaussian Processes\n",
    "    - 19p, 8e, 2r\n",
    "- 1.8. Cross decomposition\n",
    "    - 4p, 2e, 1r\n",
    "- 1.9. Naive Bayes\n",
    "    - 5p, 0e, 5r\n",
    "- 1.10. Decision Trees\n",
    "    - 15p, 6e, 6r\n",
    "- 1.11. Ensemble methods\n",
    "    - 31p, 24e, 19r\n",
    "- 1.12. Multiclass and multioutput algorithms\n",
    "    - 11p, 1e, 5r\n",
    "- 1.13. Feature selection\n",
    "    - 6p, 9e, 2r\n",
    "- 1.14. Semi-supervised learning\n",
    "    - 3p, 6e, 3r\n",
    "- 1.15. Isotonic regression\n",
    "    - 1p, 0e, 0r\n",
    "- 1.16. Probability calibration\n",
    "    - 6p, 4e, 8r\n",
    "- 1.17. Neural network models (supervised)\n",
    "    - 7p, 3e, 5r\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Modèles linéaires | [Linear Models](https://scikit-learn.org/stable/modules/linear_model.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Moindres carrés ordinaires | [Ordinary Least Squares]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Régression et classification de crête | [Ridge regression and classification]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Lasso | [Lasso]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4. Lasso multi-tâches | [Multi-task Lasso]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5. Elastic-Net | [Elastic-Net]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6. Elastic-Net multi-tâches | [Multi-task Elastic-Net]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7. Régression au moindre angle (LAR) | [Least Angle Regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.8. LARS Lasso | [LARS Lasso]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.9. Poursuite par correspondance orthogonale (OMP) | [Orthogonal Matching Pursuit]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.10. Régression bayésienne | [Bayesian Regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.11. Régression logistique | [Logistic regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.12. Régression linéaire généralisée (GLR) | [Generalized Linear Regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.13. Descente de gradient stochastique (SGD) | [Stochastic Gradient Descent]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.14. Perceptron | [Perceptron]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.15. Algorithmes passifs agressifs | [Passive Aggressive Algorithms]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.16. Régression de robustesse : valeurs aberrantes et erreurs de modélisation | [Robustness regression: outliers and modeling errors]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.17. Régression quantile | [Quantile Regression]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.18. Régression polynomiale : extension des modèles linéaires avec des fonctions de base | [Polynomial regression: extending linear models with basis functions](https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Analyse discriminante linéaire et quadratique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Régression de crête à noyau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Machines à vecteurs de support"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Descente de gradient stochastique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Plus proches voisins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Processus gaussiens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Décomposition croisée"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9. Bayes naïf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10. Arbres de décision | [Decision Trees](https://scikit-learn.org/stable/modules/tree.html#)\n",
    "\n",
    "* 1.10.1. Classification | [Classification](https://scikit-learn.org/stable/modules/tree.html#classification)\n",
    "* 1.10.2. Régression | [Regression](https://scikit-learn.org/stable/modules/tree.html#regression)\n",
    "* 1.10.3. Problèmes multi-sorties | [Multi-output problems](https://scikit-learn.org/stable/modules/tree.html#multi-output-problems)\n",
    "* 1.10.4. Complexité | [Complexity](https://scikit-learn.org/stable/modules/tree.html#complexity)\n",
    "* 1.10.5. Conseils d'utilisation pratique | [Tips on practical use](https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use)\n",
    "* 1.10.6. Algorithmes d'arbre : ID3, C4.5, C5.0 et CART | [Tree algorithms: ID3, C4.5, C5.0 and CART](https://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart)\n",
    "* 1.10.7. Formulation mathématique | [Mathematical formulation](https://scikit-learn.org/stable/modules/tree.html#mathematical-formulation)\n",
    "* 1.10.8. Élagage à coût-complexité minimal | [Minimal Cost-Complexity Pruning](https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11. Méthodes ensemblistes\n",
    "\n",
    "* 1.11.1. Méta-estimateur de bagging | Bagging meta-estimator\n",
    "* 1.11.2. Forêts d'arbres aléatoires | Forests of randomized trees\n",
    "* 1.11.3. AdaBoost | AdaBoost\n",
    "* 1.11.4. Amélioration de l'arbre par gradient | Gradient Tree Boosting\n",
    "* 1.11.5. Amplification du gradient basée sur l'histogramme | Histogram-Based Gradient Boosting\n",
    "* 1.11.6. Classifieur de vote | Voting Classifier\n",
    "* 1.11.7. Régresseur de vote | Voting Regressor\n",
    "* 1.11.8. Généralisation empilée | Stacked generalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12. Algorithmes multiclasses et multisorties | Multiclass and multioutput algorithms\n",
    "\n",
    "* 1.12.1. Classification multiclasse | Multiclass classification\n",
    "* 1.12.2. Classement multilabel | Multilabel classification\n",
    "* 1.12.3. Classification multiclasses-multisorties | Multiclass-multioutput classification\n",
    "* 1.12.4. Régression multi-sorties | Multioutput regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13. Sélection de caractéristiques\n",
    "\n",
    "* 1.13.1. Suppression des caractéristiques à faible variance | Removing features with low variance\n",
    "* 1.13.2. Sélection de caractéristiques univariées | Univariate feature selection\n",
    "* 1.13.3. Élimination récursive des caractéristiques | Recursive feature elimination\n",
    "* 1.13.4. Sélection de caractéristiques à l'aide de SelectFromModel | Feature selection using SelectFromModel\n",
    "* 1.13.5. Sélection séquentielle des caractéristiques | Sequential Feature Selection\n",
    "* 1.13.6. Sélection de caractéristiques dans le cadre d'un pipeline | Feature selection as part of a pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14. Apprentissage semi-supervisé | Semi-supervised learning\n",
    "\n",
    "* 1.14.1. Auto entrainement | Self Training\n",
    "* 1.14.2. Propagation des étiquettes | Label Propagation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15. Régression isotonique | Isotonic regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.16. Étalonnage de probabilité | Probability calibration\n",
    "\n",
    "* 1.16.1. Courbes d'étalonnage | Calibration curves\n",
    "* 1.16.2. Calibrer un classifieur | Calibrating a classifier\n",
    "* 1.16.3. Usage | Usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.17. Modèles de réseaux de neurones (supervisés) | Neural network models (supervised)\n",
    "\n",
    "* 1.17.1. Perceptron multicouche | Multi-layer Perceptron\n",
    "* 1.17.2. Classification | Classification\n",
    "* 1.17.3. Régression | Regression\n",
    "* 1.17.4. Régularisation | Regularization\n",
    "* 1.17.5. Algorithmes | Algorithms\n",
    "* 1.17.6. Complexité | Complexity\n",
    "* 1.17.7. Formulation mathématique | Mathematical formulation\n",
    "* 1.17.8. Conseils d'utilisation pratique | Tips on Practical Use\n",
    "* 1.17.9. Plus de contrôle avec warm_start | More control with warm_start\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\\. **Unsupervised learning**\n",
    "\n",
    "## 2.1. Modèles de mélange gaussien | Gaussian mixture models\n",
    "\n",
    "* 2.1.1. Mélange gaussien | Gaussian Mixture\n",
    "* 2.1.2. Mélange gaussien bayésien variationnel | Variational Bayesian Gaussian Mixture\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 2.2. [**Apprentissage des variétés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_2_manifold.ipynb)</br>([*Manifold learning*](https://scikit-learn.org/stable/modules/manifold.html))\n",
    "\n",
    "* ✔ 2.2.1. Introduction\n",
    "* ✔ 2.2.2. Isocarte\n",
    "* ✔ 2.2.3. Incorporation localement linéaire (LLE))\n",
    "* ✔ 2.2.4. Incorporation localement linéaire modifiée (MLLE)\n",
    "* ✔ 2.2.5. LLE Hessien (HLLE, Hessian Eigenmapping)\n",
    "* ✔ 2.2.6. Intégration spectrale (Spectral Embedding)\n",
    "* ✔ 2.2.7. Alignement de l'espace tangent local (LTSA)\n",
    "* ✔ 2.2.8. Analyse en dimensions multiples (MDS)\n",
    "* ✔ 2.2.9. Algorithme t-SNE\n",
    "* ✔ 2.2.10. Conseils d'utilisation pratique\n",
    "\n",
    "Compléments :\n",
    "\n",
    "* Wikipédia :\n",
    "    * [Variété (géométrie)](https://fr.wikipedia.org/wiki/Variété_(géométrie)) | [Manifold](https://en.wikipedia.org/wiki/Manifold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. [**Partitionnement**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_3_clustering.ipynb)</br>([*Clustering*](https://scikit-learn.org/stable/modules/clustering.html))\n",
    "\n",
    "* 2.3.1. Présentation des méthodes de partitionnement | Overview of clustering methods\n",
    "* 2.3.2. K-moyennes | K-means\n",
    "* 2.3.3. Propagation par affinité | Affinity Propagation\n",
    "* 2.3.4. Décalage moyen | Mean Shift\n",
    "* 2.3.5. Partitionnement spectral | Spectral clustering\n",
    "* 2.3.6. Partitionnement hiérarchique | Hierarchical clustering\n",
    "* 2.3.7. DBSCAN | DBSCAN\n",
    "* 2.3.8. OPTICS | OPTICS\n",
    "* 2.3.9. BIRCH | BIRCH\n",
    "* 2.3.10. Évaluation des performances de partitionnement | Clustering performance evaluation\n",
    "\n",
    "Compléments :\n",
    "\n",
    "* Wikipédia :\n",
    "    * [K-moyennes](https://fr.wikipedia.org/wiki/K-moyennes) | [$k$-means clustering](https://en.wikipedia.org/wiki/K-means_clustering)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Classification double | Biclustering\n",
    "\n",
    "* 2.4.1. Co-classification spectrale | Spectral Co-Clustering\n",
    "* 2.4.2. Classification double spectrale | Spectral Biclustering\n",
    "* 2.4.3. Évaluation de la classification double | Biclustering evaluation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 2.5. [**Décomposer les signaux en composantes (problèmes de factorisation matricielle)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb)</br>([*Decomposing signals in components (matrix factorization problems)*](https://scikit-learn.org/stable/modules/decomposition.html))\n",
    "\n",
    "* **Volume** : 26 pages, 19 exemples\n",
    "\n",
    "✔ 2.5.1 [**Analyse en composantes principales (ACP)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#principal-component-analysis-pca)\n",
    "([*Principal component analysis (PCA)*](https://scikit-learn.org/stable/modules/decomposition.html#principal-component-analysis-pca))\n",
    "* **Volume** : 8 pages, 6 exemples\n",
    "\n",
    "✔ 2.5.2. [**Analyse en composantes principales à noyau (kACP)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#kernel-principal-component-analysis-kpca)\n",
    "([*Kernel Principal Component Analysis (kPCA)*](https://scikit-learn.org/stable/modules/decomposition.html#kernel-principal-component-analysis-kpca))\n",
    "* **Volume** : 2 pages, 1 exemples\n",
    "\n",
    "✔ 2.5.3. [**Décomposition en valeurs singulières tronquées et analyse sémantique latente**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#truncated-singular-value-decomposition-and-latent-semantic-analysis)\n",
    "([*Truncated singular value decomposition and latent semantic analysis*](https://scikit-learn.org/stable/modules/decomposition.html#truncated-singular-value-decomposition-and-latent-semantic-analysis))\n",
    "* **Volume** : 1 pages, 1 exemples\n",
    "\n",
    "✔ 2.5.4. [**Apprentissage de dictionnaire**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#dictionary-learning)\n",
    "([*Dictionary Learning*](https://scikit-learn.org/stable/modules/decomposition.html#dictionary-learning))\n",
    "* **Volume** : 4 pages, 3 exemples\n",
    "\n",
    "✔ 2.5.5. [**Analyse factorielle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#factor-analysis)\n",
    "([*Factor Analysis*](https://scikit-learn.org/stable/modules/decomposition.html#factor-analysis))\n",
    "* **Volume** : 3 pages, 2 exemples\n",
    "\n",
    "✔ 2.5.6. [**Analyse en composantes indépendantes (ICA)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#independent-component-analysis-ica)\n",
    "([*Independent component analysis (ICA)*](https://scikit-learn.org/stable/modules/decomposition.html#independent-component-analysis-ica))\n",
    "* **Volume** : 1 pages, 3 exemples\n",
    "\n",
    "✔ 2.5.7. [**Factorisation matricielle non négative (NMF ou NNMF)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#non-negative-matrix-factorization-nmf-or-nnmf)\n",
    "([*Non-negative matrix factorization (NMF or NNMF)*](https://scikit-learn.org/stable/modules/decomposition.html#non-negative-matrix-factorization-nmf-or-nnmf))\n",
    "* **Volume** : 4 pages, 3 exemples\n",
    "\n",
    "✔ 2.5.8. [**Allocation de Dirichlet latente (LDA)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/2_5_decomposition.ipynb#latent-dirichlet-allocation-lda)\n",
    "([*Latent Dirichlet Allocation (LDA)*](https://scikit-learn.org/stable/modules/decomposition.html#latent-dirichlet-allocation-lda))\n",
    "* **Volume** : 3 pages, 1 exemples\n",
    "\n",
    "Compléments :\n",
    "\n",
    "* Wikipédia :\n",
    "    * [**Allocation de Dirichlet latente**](https://fr.wikipedia.org/wiki/Allocation_de_Dirichlet_latente)<br/>([*Latent Dirichlet allocation*](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Estimation de la covariance| Covariance estimation\n",
    "\n",
    "* 2.6.1. Covariance empirique | Empirical covariance\n",
    "* 2.6.2. Covariance réduite | Shrunk Covariance\n",
    "* 2.6.3. Covariance inverse parcimonieuse | Sparse inverse covariance\n",
    "* 2.6.4. Estimation robuste de la covariance | Robust Covariance Estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Détection de nouveauté et de valeurs aberrantes | Novelty and Outlier Detection\n",
    "\n",
    "* 2.7.1. Présentation des méthodes de détection des valeurs aberrantes | Overview of outlier detection methods\n",
    "* 2.7.2. Détection de nouveauté | Novelty Detection\n",
    "* 2.7.3. Détection des valeurs aberrantes | Outlier Detection\n",
    "* 2.7.4. Détection de nouveauté avec Local Outlier Factor | Novelty detection with Local Outlier Factor\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Estimation de la densité | Density Estimation\n",
    "\n",
    "* 2.8.1. Estimation de la densité : histogrammes | Density Estimation: Histograms\n",
    "* 2.8.2. Estimation de la densité du noyau (KDE) | Kernel Density Estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Modèles de réseaux de neurones (non supervisés) | Neural network models (unsupervised)\n",
    "\n",
    "* 2.9.1. Machines Boltzmann restreintes | Restricted Boltzmann machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 3. [**Sélection et évaluation de modèle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#model-selection-and-evaluation)</br>([*Model selection and evaluation*](https://scikit-learn.org/stable/model_selection.html#model-selection-and-evaluation))\n",
    "\n",
    "L'évaluation des performances d'un modèle est essentielle pour mesurer sa capacité à généraliser les prédictions sur de nouveaux exemples. Le module [**`sklearn.model_selection`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) de scikit-learn fournit des méthodes pour effectuer une évaluation approfondie des performances des modèles.\n",
    "\n",
    "scikit-learn propose des outils pour évaluer et sélectionner les modèles d'apprentissage automatique les plus performants. Les techniques outillées sont les suivantes :\n",
    "\n",
    "- La section 3.1 présente la validation croisée, une technique permettant d'évaluer la performance d'un modèle en utilisant plusieurs partitions de l'ensemble de données. Différentes métriques d'évaluation peuvent être calculées pour mesurer la précision, le rappel, la F-mesure et d'autres indicateurs de performance. Des itérateurs de validation croisée sont disponibles pour personnaliser la façon dont les données sont divisées.\n",
    "\n",
    "- La section 3.2 aborde l'ajustement des hyperparamètres d'un modèle. Il existe plusieurs approches pour trouver les meilleurs hyperparamètres, notamment la recherche exhaustive sur une grille prédéfinie et l'optimisation aléatoire des paramètres. Des techniques telles que la recherche successive par élimination sont également disponibles pour réduire le coût de calcul de la recherche des meilleurs paramètres.\n",
    "\n",
    "- La section 3.3 présente différentes métriques et méthodes d'évaluation pour quantifier la qualité des prédictions d'un modèle. Des métriques spécifiques sont disponibles pour les problèmes de classification, de régression et de regroupement, permettant de mesurer la précision, le score R2, l'indice de Rand, etc. Des estimateurs fictifs sont également disponibles pour établir des points de référence lors de l'évaluation des performances d'un modèle.\n",
    "\n",
    "- Enfin, la section 3.4 introduit les courbes de validation, qui permettent de visualiser les performances d'un modèle en faisant varier un hyperparamètre spécifique. Ces courbes permettent de détecter le surajustement (overfitting) et le sous-ajustement (underfitting) d'un modèle, ainsi que de déterminer le point optimal de généralisation.\n",
    "\n",
    "Les fonctionnalités du module `sklearn.model_selection` permettent d'évaluer de manière rigoureuse les performances des modèles, sélectionner les meilleurs hyperparamètres et métriques d'évaluation, et obtenir une compréhension approfondie de la qualité de leurs prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 3.1. [**Validation croisée : évaluer les performances des estimateurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-evaluating-estimator-performance)<br/>([_Cross-validation: evaluating estimator performance_](https://scikit-learn.org/stable/model_selection.html#cross-validation-evaluating-estimator-performance))\n",
    "\n",
    "- **Volume** : 25 pages, 7 exemples, 7 papiers\n",
    "- 3.1.1. [**Calcul de métriques à validation croisée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#computing-cross-validated-metrics)<br/>([_computing-cross-validated-metrics_](https://scikit-learn.org/stable/model_selection.html#computing-cross-validated-metrics))\n",
    "- 3.1.2. [**Itérateurs de validation croisée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-iterators)<br/>([_Cross validation iterators_](https://scikit-learn.org/stable/model_selection.html#cross-validation-iterators))\n",
    "- 3.1.3. [**Une note sur le brassage**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#a-note-on-shuffling)<br/>([_A note on shuffling_](https://scikit-learn.org/stable/model_selection.html#a-note-on-shuffling))\n",
    "- 3.1.4. [**Validation croisée et sélection de modèles**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-and-model-selection)<br/>([_cross-validation-and-model-selection_](https://scikit-learn.org/stable/model_selection.html#cross-validation-and-model-selection))\n",
    "- 3.1.5. [**Résultat du test de permutation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#permutation-test-score)<br/>([_Permutation test score_](https://scikit-learn.org/stable/model_selection.html#permutation-test-score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 3.2. [**Ajustement des hyper-paramètres d'un estimateur**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#tuning-the-hyper-parameters-of-an-estimator)<br/>([_Tuning the hyper-parameters of an estimator_](https://scikit-learn.org/stable/model_selection.html#tuning-the-hyper-parameters-of-an-estimator))\n",
    "\n",
    "- **Volume** : 18 pages, 9 exemples, 3 papiers\n",
    "- 3.2.1. [**Recherche exhaustive en grille**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#exhaustive-grid-search)<br/>([_Exhaustive Grid Search_](https://scikit-learn.org/stable/model_selection.html#exhaustive-grid-search))\n",
    "- 3.2.2. [**Optimisation aléatoire des paramètres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#randomized-parameter-optimization)<br/>([_Randomized Parameter Optimization_](https://scikit-learn.org/stable/model_selection.html#randomized-parameter-optimization))\n",
    "- 3.2.3. [**Recherche de paramètres optimaux par halving successifs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#searching-for-optimal-parameters-with-successive-halving)<br/>([_Searching for optimal parameters with successive halving_](https://scikit-learn.org/stable/model_selection.html#searching-for-optimal-parameters-with-successive-halving))\n",
    "- 3.2.4. [**Conseils pour la recherche de paramètres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#tips-for-parameter-search)<br/>([_Tips for parameter search_](https://scikit-learn.org/stable/model_selection.html#tips-for-parameter-search))\n",
    "- 3.2.5. [**Alternatives à la recherche de paramètres par force brute**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#alternatives-to-brute-force-parameter-search)<br/>([_Alternatives to brute force parameter search_](https://scikit-learn.org/stable/model_selection.html#alternatives-to-brute-force-parameter-search))\n",
    "\n",
    "**Wikipédia** :\n",
    "- [**Optimisation des hyperparamètres**](https://fr.wikipedia.org/wiki/Allocation_de_Dirichlet_latente)<br/>([_Hyperparameter optimization_](https://en.wikipedia.org/wiki/Hyperparameter_optimization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 3.3. [**Métriques et scoring : quantifier la qualité des prédictions**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#metrics-and-scoring-quantifying-the-quality-of-predictions)<br/>([_Metrics and scoring: quantifying the quality of predictions_](https://scikit-learn.org/stable/model_selection.html#metrics-and-scoring-quantifying-the-quality-of-predictions))\n",
    "\n",
    "- **Volume** : 63 pages, 19 exemples, 24 papiers\n",
    "- 3.3.1. [**Le paramètre `scoring` : définir les règles d'évaluation du modèle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#the-scoring-parameter-defining-model-evaluation-rules)<br/>([_The `scoring` parameter: defining model evaluation rules_](https://scikit-learn.org/stable/model_selection.html#the-scoring-parameter-defining-model-evaluation-rules))\n",
    "- 3.3.2. [**Métriques de classification**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#classification-metrics)<br/>([_Classification metrics_](https://scikit-learn.org/stable/model_selection.html#classification-metrics))\n",
    "- 3.3.3. [**Métriques de classement multi-étiquettes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#multilabel-ranking-metrics)<br/>([_Multilabel ranking metrics_](https://scikit-learn.org/stable/model_selection.html#multilabel-ranking-metrics))\n",
    "- 3.3.4. [**Métriques de régression**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#regression-metrics)<br/>([_Regression metrics_](https://scikit-learn.org/stable/model_selection.html#regression-metrics))\n",
    "- 3.3.5. [**Métriques de clustering**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#clustering-metrics)<br/>([_Clustering metrics_](https://scikit-learn.org/stable/model_selection.html#clustering-metrics))\n",
    "- 3.3.6. [**Estimateurs factices**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#dummy-estimators)<br/>([_Dummy estimators_](https://scikit-learn.org/stable/model_selection.html#dummy-estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 3.4. [**Courbes de validation : tracer des scores pour évaluer des modèles**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#validation-curves-plotting-scores-to-evaluate-models)<br/>([_Validation curves: plotting scores to evaluate models_](https://scikit-learn.org/stable/model_selection.html#validation-curves-plotting-scores-to-evaluate-models))\n",
    "\n",
    "- **Volume** : 6 pages, 3 exemples, 0 papiers\n",
    "- 3.4.1. [**Courbe de validation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#validation-curve)<br/>([_Validation curve_](https://scikit-learn.org/stable/model_selection.html#validation-curve))\n",
    "- 3.4.2. [**Courbe d'apprentissage**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#learning-curve)<br/>([_Learning curve_](https://scikit-learn.org/stable/model_selection.html#learning-curve))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 4. [**Inspection**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb)</br>([*Inspection*](https://scikit-learn.org/stable/inspection.html))\n",
    "\n",
    "La performance prédictive est souvent l'objectif principal du développement de modèles d'apprentissage automatique. Pourtant, résumer les performances avec une métrique d'évaluation est souvent insuffisant : cela suppose que la métrique d'évaluation et l'ensemble de données de test reflètent parfaitement le domaine cible, ce qui est rarement vrai. Dans certains domaines, un modèle a besoin d'un certain niveau d'**interprétabilité** avant de pouvoir être déployé. Un modèle qui présente des problèmes de performances doit être débogué pour comprendre le problème sous-jacent du modèle. Le module [**`sklearn.inspection`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.inspection) fournit des outils pour aider à comprendre les prédictions d'un modèle et ce qui les affecte. Cela peut être utilisé pour évaluer les hypothèses et les biais d'un modèle, concevoir un meilleur modèle ou diagnostiquer les problèmes de performances du modèle.\n",
    "\n",
    "\n",
    "**Volume** : 13 pages, 4 (+ 1 ancien) exemples, 3 papiers et 1 ouvrage de référence\n",
    "\n",
    "- ✔ [**Exemples**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#examples)\n",
    "- ✔ 4.1. [**Graphiques de dépendance partielle et d'espérance conditionnelle individuelle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#partial-dependence-and-individual-conditional-expectation-plots)<br/>([Partial Dependence and Individual Conditional Expectation plots](https://scikit-learn.org/stable/modules/partial_dependence.html#partial-dependence-and-individual-conditional-expectation-plots))\n",
    "    - ✔ 4.1.1. [**Graphiques de dépendance partielle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#partial-dependence-plots)<br/>([*Partial dependence plots*](https://scikit-learn.org/stable/modules/partial_dependence.html#partial-dependence-plots))\n",
    "    - ✔ 4.1.2. [**Diagramme d'espérance conditionnelle individuelle (ICE)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#individual-conditional-expectation-ice-plot)<br/>([*Individual conditional expectation (ICE) plot*](https://scikit-learn.org/stable/modules/partial_dependence.html#individual-conditional-expectation-ice-plot))\n",
    "    - ✔ 4.1.3. [**Définition mathématique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#mathematical-definition)<br/>([*Mathematical Definition*](https://scikit-learn.org/stable/modules/partial_dependence.html#mathematical-definition))\n",
    "    - ✔ 4.1.4. [**Méthodes de calcul**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#computation-methods)<br/>([*Computation methods*](https://scikit-learn.org/stable/modules/partial_dependence.html#computation-methods))\n",
    "- ✔ 4.2. [**Importance des caractéristiques par permutation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#permutation-feature-importance)<br/>([Permutation feature importance](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance))\n",
    "    - ✔ 4.2.1. [**Aperçu de l'algorithme d'importance par permutation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#outline-of-the-permutation-importance-algorithm)<br/>([*Outline of the permutation importance algorithm*](https://scikit-learn.org/stable/modules/permutation_importance.html#outline-of-the-permutation-importance-algorithm))\n",
    "    - ✔ 4.2.2. [**Relation avec l'importance basée sur les impuretés dans les arbres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#relation-to-impurity-based-importance-in-trees)<br/>([*Relation to impurity-based importance in trees*](https://scikit-learn.org/stable/modules/permutation_importance.html#relation-to-impurity-based-importance-in-trees))\n",
    "    - ✔ 4.2.3. [**Valeurs trompeuses sur les caractéristiques fortement corrélées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/4_inspection.ipynb#misleading-values-on-strongly-correlated-features)<br/>([*Misleading values on strongly correlated features*](https://scikit-learn.org/stable/modules/permutation_importance.html#misleading-values-on-strongly-correlated-features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 5. [**Visualisations**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb)</br>([*Visualizations*](https://scikit-learn.org/stable/visualizations.html))\n",
    "\n",
    "Scikit-learn définit une API simple pour créer des visualisations pour l'apprentissage automatique. La principale caractéristique de cette API est de permettre un traçage rapide et des ajustements visuels sans recalcul. Nous fournissons des classes `Display` qui exposent deux méthodes de création de tracés : `from_estimator` et `from_predictions`.\n",
    "\n",
    "- **Volume** : 3 pages, 4 exemples, 3 papiers (dans le dernier exemples)\n",
    "- ✔ [**Exemples**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#examples)\n",
    "- ✔ 5.1. [**Utilitaires de traçage disponibles**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#available-plotting-utilities)<br/>([Available Plotting Utilities](https://scikit-learn.org/stable/visualizations.html#available-plotting-utilities))\n",
    "    - ✔ 5.1.0. [**Fonctions**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#functions)<br/>([*Functions*](https://scikit-learn.org/stable/visualizations.html#functions))\n",
    "    - ✔ 5.1.1. [**Objets d'affichage**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/5_visualizations.ipynb#display-objects)<br/>([*Display Objects*](https://scikit-learn.org/stable/visualizations.html#display-objects))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 6\\. [**Transformations d'ensembles de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_dataset_transformations.ipynb)</br>([*Dataset transformations*](https://scikit-learn.org/stable/data_transforms.html))\n",
    "\n",
    "**Volume** : 87 pages, 38 exemples, 25 papiers\n",
    "\n",
    "- ✔ 6.1. [**Pipelines et estimateurs composites**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_1_compose.ipynb#pipelines-and-composite-estimators)<br/>([*Pipelines and composite estimators*](https://scikit-learn.org/stable/modules/compose.html#pipelines-and-composite-estimators))\n",
    "    - **Volume** : 13 pages, 12 exemples, 0 papiers\n",
    "    - ✔ 6.1.1. [**Pipeline : chaînage d'estimateurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_1_compose.ipynb#pipeline-chaining-estimators)<br/>([*Pipeline: chaining estimators*](https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators))\n",
    "    - ✔ 6.1.2. [**Transformation de la cible en régression**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_1_compose.ipynb#transforming-target-in-regression)<br/>([*Transforming target in regression*](https://scikit-learn.org/stable/modules/compose.html#transforming-target-in-regression))\n",
    "    - ✔ 6.1.3. [**FeatureUnion: composite feature spaces**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_1_compose.ipynb#featureunion-composite-feature-spaces)<br/>([*FeatureUnion : espaces d'entités composites*](https://scikit-learn.org/stable/modules/compose.html#featureunion-composite-feature-spaces)) \n",
    "    - ✔ 6.1.4. [**ColumnTransformer pour les données hétérogènes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_1_compose.ipynb#columntransformer-for-heterogeneous-data)<br/>([*ColumnTransformer for heterogeneous data*](https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data))\n",
    "    - ✔ 6.1.5. [**Visualisation des estimateurs composites**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_1_compose.ipynb#visualizing-composite-estimators)<br/>([*Visualizing Composite Estimators*](https://scikit-learn.org/stable/modules/compose.html#visualizing-composite-estimators))\n",
    "- ✔ 6.2. [**Extraction de caractéristiques**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_2_feature_extraction.ipynb#feature-extraction)<br/>([*Feature extraction*](https://scikit-learn.org/stable/modules/feature_extraction.html#feature-extraction))\n",
    "    - **Volume** : 23 pages, 10 exemples, 2 papiers\n",
    "    - ✔ 6.2.1. [**Chargement de fonctionnalités à partir de dicts**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_2_feature_extraction.ipynb#loading-features-from-dicts)<br/>([*Loading features from dicts*](https://scikit-learn.org/stable/modules/feature_extraction.html#loading-features-from-dicts))\n",
    "    - ✔ 6.2.2. [**Hachage des fonctionnalités**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_2_feature_extraction.ipynb#feature-hashing)<br/>([*Feature hashing*](https://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing))\n",
    "    - ✔ 6.2.3. [**Extraction de caractéristiques de texte**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_2_feature_extraction.ipynb#text-feature-extraction)<br/>([*Text feature extraction*](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction))\n",
    "    - ✔ 6.2.4. [**Extraction de caractéristiques d'image**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_2_feature_extraction.ipynb#image-feature-extraction)<br/>([*Image feature extraction*](https://scikit-learn.org/stable/modules/feature_extraction.html#image-feature-extraction))\n",
    "- ✔ 6.3. [**Prétraitement des données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#preprocessing-data)<br/>([*Preprocessing data*](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data))\n",
    "    - **Volume** : 26 pages, 7 exemples, 5 papiers\n",
    "    - ✔ 6.3.1. [**Standardisation, ou suppression de la moyenne et mise à l'échelle de la variance**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#standardization-or-mean-removal-and-variance-scaling)<br/>([*Standardization, or mean removal and variance scaling*](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling))\n",
    "    - ✔ 6.3.2. [**Transformation non linéaire**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#non-linear-transformation)<br/>([*Non-linear transformation*](https://scikit-learn.org/stable/modules/preprocessing.html#non-linear-transformation))\n",
    "    - ✔ 6.3.3. [**Normalisation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#normalization)<br/>([*Normalization*](https://scikit-learn.org/stable/modules/preprocessing.html#normalization))\n",
    "    - ✔ 6.3.4. [**Encodage des caractéristiques catégorielles**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#encoding-categorical-features)<br/>([*Encoding categorical features*](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features))\n",
    "    - ✔ 6.3.5. [**Discrétisation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#discretization)<br/>([*Discretization*](https://scikit-learn.org/stable/modules/preprocessing.html#discretization))\n",
    "    - ✔ 6.3.6. [**Imputation des valeurs manquantes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#imputation-of-missing-values)<br/>([*Imputation of missing values*](https://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values))\n",
    "    - ✔ 6.3.7. [**Génération de caractéristiques polynomiales**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#generating-polynomial-features)<br/>([*Generating polynomial features*](https://scikit-learn.org/stable/modules/preprocessing.html#generating-polynomial-features))\n",
    "    - ✔ 6.3.8. [**Transformateurs personnalisés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_3_preprocessing.ipynb#custom-transformers)<br/>([*Custom transformers*](https://scikit-learn.org/stable/modules/preprocessing.html#custom-transformers))\n",
    "- ✔ 6.4. [**Imputation des valeurs manquantes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#imputation-of-missing-values)<br/>([*Imputation of missing values*](https://scikit-learn.org/stable/modules/impute.html))\n",
    "    - **Volume** : 8 pages, 2 exemples, 3 papiers\n",
    "    - ✔ 6.4.1. [**Imputation univariée vs imputation multivariée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#univariate-vs-multivariate-imputation)<br/>([*Univariate vs. Multivariate Imputation*](https://scikit-learn.org/stable/modules/impute.html#univariate-vs-multivariate-imputation))\n",
    "    - ✔ 6.4.2. [**Imputation de caractéristique univariée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#univariate-feature-imputation)<br/>([*Univariate feature imputation*](https://scikit-learn.org/stable/modules/impute.html#univariate-feature-imputation))\n",
    "    - ✔ 6.4.3. [**Imputation de caractéristiques multivariées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#multivariate-feature-imputation)<br/>([*Multivariate feature imputation*](https://scikit-learn.org/stable/modules/impute.html#multivariate-feature-imputation))\n",
    "    - ✔ 6.4.4. [**Imputation des plus proches voisins**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#nearest-neighbors-imputation)<br/>([*Nearest neighbors imputation*](https://scikit-learn.org/stable/modules/impute.html#nearest-neighbors-imputation))\n",
    "    - ✔ 6.4.5. [**Maintenir le nombre de caractéristiques constant**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#keeping-the-number-of-features-constants)<br/>([*Keeping the number of features constants*](https://scikit-learn.org/stable/modules/impute.html#keeping-the-number-of-features-constants))\n",
    "    - ✔ 6.4.6. [**Marquage des valeurs imputées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#marking-imputed-values)<br/>([*Marking imputed values*](https://scikit-learn.org/stable/modules/impute.html#marking-imputed-values))\n",
    "    - ✔ 6.4.7. [**Estimateurs qui gèrent les valeurs NaN**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_4_impute.ipynb#estimators-that-handle-nan-values)<br/>([*Estimators that handle NaN values*](https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values))\n",
    "- ✔ 6.5. [**Réduction de dimensionnalité non supervisée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_5_unsupervised_reduction.ipynb)<br/>([*Unsupervised dimensionality reduction*](https://scikit-learn.org/stable/modules/unsupervised_reduction.html))\n",
    "    - **Volume** : 1 pages, 4 exemples, 0 papiers\n",
    "    - ✔ 6.5.1. [**ACP : analyse en composantes principales**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_5_unsupervised_reduction.ipynb#pca-principal-component-analysis)<br/>([*PCA: principal component analysis*](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#pca-principal-component-analysis))\n",
    "    - ✔ 6.5.2. [**Projections aléatoires**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_5_unsupervised_reduction.ipynb#random-projections)<br/>([*Random projections*](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#random-projections))\n",
    "    - ✔ 6.5.3. [**Agglomération de fonctionnalités**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_5_unsupervised_reduction.ipynb#feature-agglomeration)<br/>([*Feature agglomeration*](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#feature-agglomeration))\n",
    "- ✔  6.6. [**Projection aléatoire**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_6_random_projection.ipynb#random-projection)<br/>([*Random Projection*](https://scikit-learn.org/stable/modules/random_projection.html#random-projection))\n",
    "    - **Volume** : 5 pages, 1 exemples, 5 papiers\n",
    "    - ✔ 6.6.1. [**Le lemme de Johnson-Lindenstrauss**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_6_random_projection.ipynb#the-johnson-lindenstrauss-lemma)<br/>([*The Johnson-Lindenstrauss lemma*](https://scikit-learn.org/stable/modules/random_projection.html#the-johnson-lindenstrauss-lemma))\n",
    "    - ✔ 6.6.2. [**Projection aléatoire gaussienne**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_6_random_projection.ipynb#gaussian-random-projection)<br/>([*Gaussian random projection*](https://scikit-learn.org/stable/modules/random_projection.html#gaussian-random-projection))\n",
    "    - ✔ 6.6.3. [**Projection aléatoire creuse**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_6_random_projection.ipynb#sparse-random-projection)<br/>([*Sparse random projection*](https://scikit-learn.org/stable/modules/random_projection.html#sparse-random-projection))\n",
    "    - ✔ 6.6.4. [**Transformation inverse**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_6_random_projection.ipynb#inverse-transform)<br/>([*Inverse Transform*](https://scikit-learn.org/stable/modules/random_projection.html#inverse-transform))\n",
    "- ✔  6.7. [**Approximation du noyau**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_7_kernel_approximation.ipynb#kernel-approximation)\n",
    "([*Kernel Approximation*](https://scikit-learn.org/stable/modules/kernel_approximation.html#kernel-approximation))\n",
    "    - **Volume** : 6 pages, 2 exemples, 7 papiers\n",
    "    - ✔ 6.7.1. [**Méthode Nystroem pour l'approximation du noyau**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_7_kernel_approximation.ipynb#nystroem-method-for-kernel-approximation)<br/>([_Nystroem Method for Kernel Approximation_](https://scikit-learn.org/stable/modules/kernel_approximation.html#nystroem-method-for-kernel-approximation))\n",
    "    - ✔ 6.7.2. [**Noyau de fonction de base radiale**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_7_kernel_approximation.ipynb#radial-basis-function-kernel)<br/>([_Radial Basis Function Kernel_](https://scikit-learn.org/stable/modules/kernel_approximation.html#radial-basis-function-kernel))\n",
    "    - ✔ 6.7.3. [**Additif Chi Squared Kernel**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_7_kernel_approximation.ipynb#additive-chi-squared-kernel)<br/>([_Additive Chi Squared Kernel_](https://scikit-learn.org/stable/modules/kernel_approximation.html#additive-chi-squared-kernel))\n",
    "    - ✔ 6.7.4. [**Noyau au carré de chi asymétrique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_7_kernel_approximation.ipynb#skewed-chi-squared-kernel)<br/>([_Skewed Chi Squared Kernel_](https://scikit-learn.org/stable/modules/kernel_approximation.html#skewed-chi-squared-kernel))\n",
    "    - ✔ 6.7.5. [**Approximation du noyau polynomial via Tensor Sketch**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_7_kernel_approximation.ipynb#polynomial-kernel-approximation-via-tensor-sketch)<br/>([_Polynomial Kernel Approximation via Tensor Sketch_](https://scikit-learn.org/stable/modules/kernel_approximation.html#polynomial-kernel-approximation-via-tensor-sketch))\n",
    "    - ✔ 6.7.6. [**Détails mathématiques**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_7_kernel_approximation.ipynb#mathematical-details)<br/>([_Mathematical Details_](https://scikit-learn.org/stable/modules/kernel_approximation.html#mathematical-details))\n",
    "- ✔ 6.8. [**Métriques par paires, affinités et noyaux**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_8_pairwise_metrics.ipynb#pairwise-metrics-affinities-and-kernels)<br/>([*Pairwise metrics, Affinities and Kernels*](https://scikit-learn.org/stable/modules/metrics.html#pairwise-metrics-affinities-and-kernels))\n",
    "    - **Volume** : 5 pages, 0 exemples, 3 papiers\n",
    "    - ✔ 6.8.1. [**Similitude cosinus**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_8_pairwise_metrics.ipynb#cosine-similarity)<br/>([*Cosine similarity*](https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity))\n",
    "    - ✔ 6.8.2. [**Noyau linéaire**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_8_pairwise_metrics.ipynb#linear-kernel)<br/>([*Linear kernel*](https://scikit-learn.org/stable/modules/metrics.html#linear-kernel))\n",
    "    - ✔ 6.8.3. [**Noyau polynomial**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_8_pairwise_metrics.ipynb#polynomial-kernel)<br/>([*Polynomial kernel*](https://scikit-learn.org/stable/modules/metrics.html#polynomial-kernel))\n",
    "    - ✔ 6.8.4. [**Noyau sigmoïde**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_8_pairwise_metrics.ipynb#sigmoid-kernel)<br/>([*Sigmoid kernel*](https://scikit-learn.org/stable/modules/metrics.html#sigmoid-kernel))\n",
    "    - ✔ 6.8.5. [**Noyau RBF**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_8_pairwise_metrics.ipynb#rbf-kernel)<br/>([*RBF kernel*](https://scikit-learn.org/stable/modules/metrics.html#rbf-kernel))\n",
    "    - ✔ 6.8.6. [**Noyau laplacien**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_8_pairwise_metrics.ipynb#laplacian-kernel)<br/>([*Laplacian kernel*](https://scikit-learn.org/stable/modules/metrics.html#laplacian-kernel))\n",
    "    - ✔ 6.8.7. [**Noyau du chi carré**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_8_pairwise_metrics.ipynb#chi-squared-kernel)<br/>([*Chi-squared kernel*](https://scikit-learn.org/stable/modules/metrics.html#chi-squared-kernel))\n",
    "- ✔ 6.9. [**Transformation de la cible de prédiction (y)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_9_preprocessing_targets.ipynb)<br/>([*Transforming the prediction target (y)*](https://scikit-learn.org/stable/modules/preprocessing_targets.html))\n",
    "    - **Volume** : 2 pages, 0 exemples, 0 papiers\n",
    "    - ✔ 6.9.1. [**Binarisation des étiquettes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_9_preprocessing_targets.ipynb#label-binarization)<br/>([*Label binarization*](https://scikit-learn.org/stable/modules/preprocessing_targets.html#label-binarization))\n",
    "    - ✔ 6.9.2. [**Encodage des étiquettes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_9_preprocessing_targets.ipynb#label-encoding)<br/>([*Label encoding*](https://scikit-learn.org/stable/modules/preprocessing_targets.html#label-encoding))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✘ 7. [**Utilitaires de chargement de jeux de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb)</br>([*Dataset loading utilities*](https://scikit-learn.org/stable/datasets.html))\n",
    "\n",
    "**Volume** : 35 pages, 6 exemples, 28 papiers\n",
    "\n",
    "<mark>Attention, les exemples sont sous-estimés. Pour parcourir l'ensemble des exemples utilisant tel ou tel jeu de données intégré, consulter la page de documentation de chaque méthode de chargement.</mark>\n",
    "\n",
    "- 7.1. [**Jeux de données jouets**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#toy_dataset)<br/>([*Toy datasets*](https://scikit-learn.org/stable/datasets/toy_dataset.html))\n",
    "    - **Volume** : 11 pages, 0 exemples, 22 papiers\n",
    "    - ✔ 7.1.1. [**Jeu de données des plantes d'Iris**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#iris-plants-dataset)<br/>([*Iris plants dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-plants-dataset))\n",
    "    - ✔ 7.1.2. [**Jeu de données sur le diabète**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#diabetes-dataset)<br/>([*Diabetes dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset))\n",
    "    - ✔ 7.1.3. [**Jeu de données de reconnaissance optique de chiffres écrits à la main**](https://scikit-learn.org/stable/datasets/toy_dataset.html#optical-recognition-of-handwritten-digits-dataset)<br/>([*Optical recognition of handwritten digits dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#optical-recognition-of-handwritten-digits-dataset))\n",
    "    - ✔ 7.1.4. [**Jeu de données de Linnerrud**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#linnerrud-dataset)<br/>([*Linnerrud dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#linnerrud-dataset))\n",
    "    - ✔ 7.1.5. [**Jeu de données de reconnaissance de vins**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#wine-recognition-dataset)<br/>([*Wine recognition dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset))\n",
    "    - ✔ 7.1.6. [**Jeu de données du Wisconsin pour le diagnostic du cancer du sein**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#breast-cancer-wisconsin-diagnostic-dataset)<br/>([*Breast cancer Wisconsin (diagnostic) dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset))\n",
    "- ✔ 7.2. [**Jeux de données du monde réel**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#real-world-datasets)<br/>([*Real world datasets*](https://scikit-learn.org/stable/datasets/real_world.html#real-world-datasets))\n",
    "    - **Volume** : 15 pages, 5 exemples, 5 papiers\n",
    "    - ✔ 7.2.1. [**Jeu de données des visages Olivetti**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-olivetti-faces-dataset)<br/>([*The Olivetti faces dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-olivetti-faces-dataset))\n",
    "    - ✔ 7.2.2. [**Jeu de données de texte des 20 newsgroups**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-20-newsgroups-text-dataset)<br/>([*The 20 newsgroups text dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset))\n",
    "    - ✔ 7.2.3. [**Jeu de données de reconnaissance faciale Labeled Faces in the Wild**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-labeled-faces-in-the-wild-face-recognition-dataset)<br/>([*The Labeled Faces in the Wild face recognition dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-labeled-faces-in-the-wild-face-recognition-dataset))\n",
    "    - ✔ 7.2.4. [**Jeu de données des types de couverture forestière**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#forest-covertypes)<br/>([*Forest covertypes*](https://scikit-learn.org/stable/datasets/real_world.html#forest-covertypes))\n",
    "    - ✔ 7.2.5. [**Jeu de données RCV1**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#rcv1-dataset)<br/>([*RCV1 dataset*](https://scikit-learn.org/stable/datasets/real_world.html#rcv1-dataset))\n",
    "    - ✔ 7.2.6. [**Jeu de données Kddcup 99**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#kddcup-99-dataset)<br/>([*Kddcup 99 dataset*](https://scikit-learn.org/stable/datasets/real_world.html#kddcup-99-dataset))\n",
    "    - ✔ 7.2.7. [**Jeu de données de l'immobilier californien**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#california-housing-dataset)<br/>([*California Housing dataset*](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset))\n",
    "- ✔ 7.3. [**Jeux de données générés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generated-datasets)<br/>([*Generated datasets*](https://scikit-learn.org/stable/datasets/sample_generators.html#generated-datasets))\n",
    "    - **Volume** : 3 pages, 0 exemples, 0 papiers\n",
    "    - ✔ 7.3.1. [**Générateurs pour la classification et le clustering**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-classification-and-clustering)<br/>([*Generators for classification and clustering*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-classification-and-clustering))\n",
    "    - ✔ 7.3.2. [**Générateurs pour la régression**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-regression)<br/>([*Generators for regression*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-regression))\n",
    "    - ✔ 7.3.3. [**Générateurs pour l'apprentissage de variétés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-manifold-learning)<br/>([*Generators for manifold learning*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-manifold-learning))\n",
    "    - ✔ 7.3.4. [**Générateurs pour la décomposition**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-decomposition)<br/>([*Generators for decomposition*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-decomposition))\n",
    "- ✔ 7.4. [**Chargement d'autres jeux de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#loading-other-datasets)<br/>([*Loading other datasets*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#loading-other-datasets))\n",
    "    - **Volume** : 6 pages, 1 exemples, 1 papiers\n",
    "    - ✔ 7.4.1. [**Images d'exemple**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#sample-images)<br/>([*Sample images*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#sample-images))\n",
    "    - ✔ 7.4.2. [**Jeux de données au format svmlight / libsvm**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#datasets-in-svmlight-libsvm-format)<br/>([*Datasets in svmlight / libsvm format*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#datasets-in-svmlight-libsvm-format))\n",
    "    - ✔ 7.4.3. [**Téléchargement de jeux de données depuis le dépôt openml.org**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#downloading-datasets-from-the-openml-org-repository)<br/>([*Downloading datasets from the openml.org repository*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#downloading-datasets-from-the-openml-org-repository))\n",
    "    - ✔ 7.4.4. [**Chargement depuis des jeux de données externes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#loading-from-external-datasets)<br/>([*Loading from external datasets*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#loading-from-external-datasets))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 8\\. [**Calculer avec scikit-learn**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb)</br>([*Computing with scikit-learn*](https://scikit-learn.org/stable/computing.html))\n",
    "\n",
    "**Volume** : 21 pages, 2 exemples, 0 papiers\n",
    "\n",
    "- ✔ 8.1. [**Stratégies de mise à l'échelle calculatoire : données plus volumineuses**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#strategies-to-scale-computationally-bigger-data)<br/>([*Strategies to scale computationally: bigger data*](https://scikit-learn.org/stable/computing.html#strategies-to-scale-computationally-bigger-data))\n",
    "    - ✔ 8.1.1. [**Mise à l'échelle avec des instances utilisant l'apprentissage hors cœur**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#scaling-with-instances-using-out-of-core-learning)<br/>([*Scaling with instances using out-of-core learning*](https://scikit-learn.org/stable/computing.html#scaling-with-instances-using-out-of-core-learning))\n",
    "- ✔ 8.2. [**Performances calculatoires**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#computational-performance)<br/>([*Computational Performance*](https://scikit-learn.org/stable/computing/computational_performance.html#computational-performance))\n",
    "    - ✔ 8.2.1. [**Latence de prédiction**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#prediction-latency)<br/>([*Prediction Latency*](https://scikit-learn.org/stable/computing.html#prediction-latency))\n",
    "    - ✔ 8.2.2. [**Débit de prédiction**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#prediction-throughput)<br/>([*Prediction Throughput*](https://scikit-learn.org/stable/computing.html#prediction-throughput))\n",
    "    - ✔ 8.2.3. [**Trucs et astuces**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#tips-and-tricks)<br/>([*Tips and Tricks*](https://scikit-learn.org/stable/computing.html#tips-and-tricks))\n",
    "- ✔ 8.3. [**Parallélisme, gestion des ressources et configuration**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#parallelism-resource-management-and-configuration)<br/>([*Parallelism, resource management, and configuration*](https://scikit-learn.org/stable/computing/parallelism.html#parallelism-resource-management-and-configuration))\n",
    "    - ✔ 8.3.1. [**Parallélisme**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#parallelism)<br/>([*Parallelism*](https://scikit-learn.org/stable/computing/parallelism.html#parallelism))\n",
    "    - ✔ 8.3.2. [**Commutateurs de configuration**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/8_computing.ipynb#configuration-switches)<br/>([*Configuration switches*](https://scikit-learn.org/stable/computing/parallelism.html#configuration-switches))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 9\\. [**Persistance de modèle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb)<br/>([*Model persistence*](https://scikit-learn.org/stable/model_persistence.html))\n",
    "\n",
    "**Volume** : 3 pages, 0 exemples, 0 papiers\n",
    "- ✔ 9.1. [**Sérialisation spécifique Python**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb#python-specific-serialization)<br/>([*Python specific serialization*](https://scikit-learn.org/stable/model_persistence.html#python-specific-serialization))\n",
    "    - ✔ 9.1.1. [**Limites de sécurité et de maintenabilité**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb#security-maintainability-limitations)<br/>([*Security & maintainability limitations*](https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations))\n",
    "    - ✔ 9.1.2 [**Un format plus sécurisé : `skops`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb#\"a-more-secure-format-skops)<br/>([*A more secure format: `skops`*](https://scikit-learn.org/stable/model_persistence.html#\"a-more-secure-format-skops))\n",
    "- ✔ 9.2. [**Formats interopérables**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/9_model_persistence.ipynb#interoperable-formats)<br/>([*Interoperable formats*](https://scikit-learn.org/stable/model_persistence.html#interoperable-formats))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 10\\. [**Pièges courants et pratiques recommandées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb)<br/>([*Common pitfalls and recommended practices*](https://scikit-learn.org/stable/common_pitfalls.html))\n",
    "\n",
    "Le but de ce chapitre est d'illustrer certains pièges et anti-modèles courants qui se produisent lors de l'utilisation de scikit-learn. Il fournit des exemples de ce qu'il **ne faut pas** faire, ainsi qu'un exemple correct correspondant.\n",
    "\n",
    "**Volume** : 12 pages, 0 exemples, 0 papiers\n",
    "\n",
    "- ✔ 10.1. [**Prétraitement incohérent**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#inconsistent-preprocessing)<br/>([*Inconsistent preprocessing*](https://scikit-learn.org/stable/common_pitfalls.html#inconsistent-preprocessing))\n",
    "- ✔ 10.2. [**Fuite de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#data-leakage)<br/>([*Data leakage*](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage))\n",
    "    - ✔ 10.2.1. [**Fuite de données lors du prétraitement**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#data-leakage-during-pre-processing)<br/>([*Data leakage during pre-processing*](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage-during-pre-processing))\n",
    "    - ✔ 10.2.2. [**Comment éviter les fuites de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#how-to-avoid-data-leakage)<br/>([*How to avoid data leakage*](https://scikit-learn.org/stable/common_pitfalls.html#how-to-avoid-data-leakage))\n",
    "- ✔ 10.3. [**Contrôle de l'aléatoire**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#controlling-randomness)<br/>([*Controlling randomness*](https://scikit-learn.org/stable/common_pitfalls.html#controlling-randomness))\n",
    "    - ✔ 10.3.1. [**Utilisation d'instances None ou RandomState, et appels répétés pour ajuster et diviser**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#using-none-or-randomstate-instances-and-repeated-calls-to-fit-and-split)<br/>([*Using None or RandomState instances, and repeated calls to fit and split*](https://scikit-learn.org/stable/common_pitfalls.html#using-none-or-randomstate-instances-and-repeated-calls-to-fit-and-split))\n",
    "    - ✔ 10.3.2. [**Pièges et subtilités courants**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#common-pitfalls-and-subtleties)<br/>([*Common pitfalls and subtleties*](https://scikit-learn.org/stable/common_pitfalls.html#common-pitfalls-and-subtleties))\n",
    "    - ✔ 10.3.3. [**Recommandations générales**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/10_pitfalls_good_practises.ipynb#general-recommendations)<br/>([*General recommendations*](https://scikit-learn.org/stable/common_pitfalls.html#general-recommendations))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ 11\\. [**Répartition**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_dispatching.ipynb)<br/>([*Dispatching*](https://scikit-learn.org/stable/modules/array_api.html))\n",
    "\n",
    "**Volume** : 3 pages, 0 exemples, 0 papiers\n",
    "\n",
    "- ✔ 11.1. [**Prise en charge de l'API Array (expérimental)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_1_array_api.ipynb#array-api-support-experimental)<br/>([_Array API support (experimental)_](https://scikit-learn.org/stable/modules/array_api.html#array-api-support-experimental))\n",
    "    - ✔ 11.1.1. [**Exemple d'utilisation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_1_array_api.ipynb#example-usage)<br/>([_Example usage_](https://scikit-learn.org/stable/modules/array_api.html#example-usage))\n",
    "    - ✔ 11.1.2. [**Estimateurs avec prise en charge des entrées compatibles avec l'API Array**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_1_array_api.ipynb#estimators-with-support-for-array-api-compatible-inputs)<br/>([_Estimators with support for Array API-compatible inputs_](https://scikit-learn.org/stable/modules/array_api.html#estimators-with-support-for-array-api-compatible-inputs#estimators-with-support-for-array-api-compatible-inputs))\n",
    "    - ✔ 11.1.3. [**Vérifications communes des estimateurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/11_1_array_api.ipynb#common-estimator-checks)<br/>([_Common estimator checks_](https://scikit-learn.org/stable/modules/array_api.html#common-estimator-checks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ E1\\. [**Équilibrage de classes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/E1_imbalanced_learn.ipynb)<br/>([*Imbalanced-Learn*](https://imbalanced-learn.org/stable/))\n",
    "\n",
    "- E1.1 Introduction\n",
    "    - 1.1. API’s of imbalanced-learn samplers\n",
    "    - 1.2. Problem statement regarding imbalanced data sets\n",
    "- E1.2. Over-sampling\n",
    "    - 2.1. A practical guide\n",
    "        - 2.1.1. Naive random over-sampling\n",
    "        - 2.1.2. From random over-sampling to SMOTE and ADASYN\n",
    "        - 2.1.3. Ill-posed examples\n",
    "        - 2.1.4. SMOTE variants\n",
    "    - 2.2. Mathematical formulation\n",
    "- E1.3. Under-sampling\n",
    "    - 3.1. Prototype generation\n",
    "    - 3.2. Prototype selection\n",
    "- E1.4. Combination of over- and under-sampling\n",
    "- E1.5. Ensemble of samplers\n",
    "    - 5.1. Classifier including inner balancing samplers\n",
    "        - 5.1.1. Bagging classifier\n",
    "        - 5.1.2. Forest of randomized trees\n",
    "        - 5.1.3. Boosting\n",
    "- E1.6. Miscellaneous samplers\n",
    "    - 6.1. Custom samplers\n",
    "    - 6.2. Custom generators\n",
    "        - 6.2.1. TensorFlow generator\n",
    "        - 6.2.2. Keras generator\n",
    "- E1.7. Metrics\n",
    "    - 7.1. Classification metrics\n",
    "        - 7.1.1. Sensitivity and specificity metrics\n",
    "        - 7.1.2. Additional metrics specific to imbalanced datasets\n",
    "        - 7.1.3. Macro-Averaged Mean Absolute Error (MA-MAE)\n",
    "        - 7.1.4. Summary of important metrics\n",
    "    - 7.2. Pairwise metrics\n",
    "        - 7.2.1. Value Difference Metric\n",
    "- E1.8. Common pitfalls and recommended practices\n",
    "    - 8.1. Data leakage\n",
    "- E1.9. Dataset loading utilities\n",
    "    - 9.1. Imbalanced datasets for benchmark\n",
    "    - 9.2. Imbalanced generator\n",
    "- E1.10. Developer guideline\n",
    "    - 10.1. Developer utilities\n",
    "        - 10.1.1. Validation Tools\n",
    "        - 10.1.2. Deprecation\n",
    "    - 10.2. Making a release\n",
    "        - 10.2.1. Major release\n",
    "        - 10.2.2. Bug fix release\n",
    "- E1.11. References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrêt précoce de la descente de gradient stochastique\n",
    "\n",
    "User Guide | [Early stopping of Stochastic Gradient Descent](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_early_stopping.html?highlight=ignore_warnings#)\n",
    "\n",
    "Traduction | ... lien vers Github\n",
    "\n",
    "In :\n",
    "* [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aff9e50adfaa9e30c910fb3872ffdc72747acb5f50803ca0504f00e980f7c25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
