{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='supervised-learning'></a> 1. [**Apprentissage supervis√©**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_supervised_learning.ipynb#supervised-learning)</br>([*Supervised learning*](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning))\n",
    "\n",
    "# <a id='neural-network-models-supervised'></a> 1.17. [**Mod√®les de r√©seaux neuronaux (supervis√©s)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb)<br/>([_Neural network models (supervised)_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 7 pages, 3 exemples, 5 papiers\n",
    "- 1.17.1. [**Perceptron multi-couches**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#multi-layer-perceptron)<br/>([_Multi-layer Perceptron_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron))\n",
    "- 1.17.2. [**Classification**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#classification)<br/>([_Classification_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification))\n",
    "- 1.17.3. [**R√©gression**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#regression)<br/>([_Regression_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#regression))\n",
    "- 1.17.4. [**R√©gularisation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#regularization)<br/>([_Regularization_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#regularization))\n",
    "- 1.17.5. [**Algorithmes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#algorithms)<br/>([_Algorithms_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#algorithms))\n",
    "- 1.17.6. [**Complexit√©**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#complexity)<br/>([_Complexity_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#complexity))\n",
    "- 1.17.7. [**Formulation math√©matique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#mathematical-formulation)<br/>([_Mathematical formulation_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#mathematical-formulation))\n",
    "- 1.17.8. [**Conseils d'utilisation pratique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#tips-on-practical-use)<br/>([_Tips on Practical Use_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use))\n",
    "- 1.17.9. [**Plus de contr√¥le avec `warm_start`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_17_neural_networks_supervised.ipynb#more-control-with-warm-start)<br/>([_More control with `warm_start`_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#more-control-with-warm-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='neural-network-models-supervised'></a> 1.17. **Mod√®les de r√©seaux neuronaux (supervis√©s)**<br/>([_Neural network models (supervised)_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html))\n",
    "\n",
    "> **Attention :** Cette impl√©mentation n'est pas destin√©e aux applications √† grande √©chelle. En particulier, scikit-learn ne prend pas en charge les GPU. Pour des impl√©mentations beaucoup plus rapides bas√©es sur GPU, ainsi que des cadres offrant beaucoup plus de flexibilit√© pour construire des architectures d'apprentissage profond, consultez les [**Projets Connexes**](https://scikit-learn.org/stable/related_projects.html#related-projects).\n",
    "\n",
    "## <a id='multi-layer-perceptron'></a> 1.17.1. **Perceptron multi-couches**<br/>([_Multi-layer Perceptron_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron))\n",
    "\n",
    "Le Perceptron multi-couches (MLP) est un algorithme d'apprentissage supervis√© qui apprend une fonction $f(\\cdot) : R^m \\rightarrow R^o$ en s'entra√Ænant sur un ensemble de donn√©es, o√π $m$ est le nombre de dimensions en entr√©e et $o$ est le nombre de dimensions en sortie. √âtant donn√© un ensemble de caract√©ristiques $X = \\{x_1, x_2, \\ldots, x_m\\}$ et une cible $y$, il peut apprendre un approximateur de fonction non lin√©aire pour la classification ou la r√©gression. Il est diff√©rent de la r√©gression logistique en ce sens qu'entre la couche d'entr√©e et la couche de sortie, il peut y avoir une ou plusieurs couches non lin√©aires, appel√©es couches cach√©es. La Figure 1 montre un MLP √† une seule couche cach√©e avec une sortie scalaire.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/multilayerperceptron_network.png\"\n",
    "    alt=\"Perceptron multi-couches\"\n",
    "    style=\"max-width: 40%; height; auto;\"/>\n",
    "</div>\n",
    "\n",
    "**Figure 1 : Perceptron multi-couches √† une couche cach√©e.**\n",
    "\n",
    "La couche la plus √† gauche, appel√©e la couche d'entr√©e, est compos√©e d'un ensemble de neurones $\\{x_i | x_1, x_2, \\ldots, x_m\\}$ repr√©sentant les caract√©ristiques d'entr√©e. Chaque neurone de la couche cach√©e transforme les valeurs de la couche pr√©c√©dente avec une sommation lin√©aire pond√©r√©e $w_1x_1 + w_2x_2 + \\ldots + w_mx_m$, suivie d'une fonction d'activation non lin√©aire $g(\\cdot) : R \\rightarrow R$ - comme la fonction tangente hyperbolique. La couche de sortie re√ßoit les valeurs de la derni√®re couche cach√©e et les transforme en valeurs de sortie.\n",
    "\n",
    "Le module contient les attributs publics `coefs_` et `intercepts_`. `coefs_` est une liste de matrices de poids, o√π la matrice de poids d'indice $i$ repr√©sente les poids entre la couche $i$ et la couche $i + 1$. `intercepts_` est une liste de vecteurs de biais, o√π le vecteur d'indice $i$ repr√©sente les valeurs de biais ajout√©es √† la couche $i + 1$.\n",
    "\n",
    "Les avantages du Perceptron multi-couches sont les suivants :\n",
    "- Capacit√© √† apprendre des mod√®les non lin√©aires.\n",
    "- Capacit√© √† apprendre des mod√®les en temps r√©el (apprentissage en ligne) en utilisant `partial_fit`.\n",
    "\n",
    "Les inconv√©nients du Perceptron multi-couches (MLP) comprennent :\n",
    "- Les MLP avec des couches cach√©es ont une fonction de perte non convexe o√π il existe plus d'un minimum local. Par cons√©quent, diff√©rentes initialisations al√©atoires des poids peuvent conduire √† des pr√©cisions de validation diff√©rentes.\n",
    "- Le MLP n√©cessite le r√©glage de plusieurs hyperparam√®tres tels que le nombre de neurones cach√©s, les couches et les it√©rations.\n",
    "- Le MLP est sensible √† l'√©chelle des caract√©ristiques.\n",
    "\n",
    "Veuillez consulter la section [**Conseils sur l'utilisation pratique** (1.17.8)](#tips-on-practical-use) qui aborde certains de ces inconv√©nients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='classification'></a> 1.17.2. **Classification**<br/>([_Classification_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification))\n",
    "\n",
    "La classe [**`MLPClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) impl√©mente un algorithme de perceptron multi-couches (MLP) qui s'entra√Æne √† l'aide de la [**r√©tropropagation**](https://en.wikipedia.org/wiki/Backpropagation).\n",
    "\n",
    "MLP s'entra√Æne sur deux tableaux : le tableau `X` de taille `(n_samples, n_features)`, qui contient les √©chantillons d'entra√Ænement repr√©sent√©s sous forme de vecteurs de caract√©ristiques √† virgule flottante ; et le tableau `y` de taille `(n_samples,)`, qui contient les valeurs cibles (√©tiquettes de classe) pour les √©chantillons d'entra√Ænement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier(\n",
    "    solver=\"lbfgs\", alpha=1e-5,\n",
    "    hidden_layer_sizes=(5, 2), random_state=1\n",
    ")\n",
    "clf.fit(X, y)\n",
    "# MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
    "#               solver='lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apr√®s l'ajustement (l'entra√Ænement), le mod√®le peut pr√©dire des √©tiquettes pour de nouveaux √©chantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2., 2.], [-1., -2.]])\n",
    "# array([1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP peut ajuster un mod√®le non lin√©aire aux donn√©es d'entra√Ænement. `clf.coefs_` contient les matrices de poids qui constituent les param√®tres du mod√®le :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (5, 2), (2, 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[coef.shape for coef in clf.coefs_]\n",
    "# [(2, 5), (5, 2), (2, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actuellement, [**`MLPClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) ne prend en charge que la fonction de perte d'entropie crois√©e, qui permet d'estimer les probabilit√©s en ex√©cutant la m√©thode `predict_proba`.\n",
    "\n",
    "MLP s'entra√Æne en utilisant la r√©tropropagation. Plus pr√©cis√©ment, il s'entra√Æne √† l'aide d'une forme de descente de gradient et les gradients sont calcul√©s √† l'aide de la r√©tropropagation. Pour la classification, il minimise la fonction de perte d'entropie crois√©e, donnant un vecteur d'estimations de probabilit√© $P(y|x)$ par √©chantillon $x$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.96718015e-04, 9.99803282e-01],\n",
       "       [1.96718015e-04, 9.99803282e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([[2., 2.], [1., 2.]])\n",
    "# array([[1.967...e-04, 9.998...-01],\n",
    "#        [1.967...e-04, 9.998...-01]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`MLPClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) prend en charge la classification multi-classe en appliquant le [**Softmax**](https://en.wikipedia.org/wiki/Softmax_activation_function) comme fonction de sortie.\n",
    "\n",
    "De plus, le mod√®le prend en charge la [**classification multi-√©tiquette** (1.12)](https://scikit-learn.org/stable/modules/multiclass.html#multiclass) dans laquelle un √©chantillon peut appartenir √† plus d'une classe. Pour chaque classe, la sortie brute passe par la fonction logistique. Les valeurs sup√©rieures ou √©gales √† `0.5` sont arrondies √† `1`, sinon √† `0`. Pour une sortie pr√©dite d'un √©chantillon, les indices o√π la valeur est `1` repr√©sentent les classes assign√©es √† cet √©chantillon :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [[0, 1], [1, 1]]\n",
    "clf = MLPClassifier(\n",
    "    solver=\"lbfgs\", alpha=1e-5,\n",
    "    hidden_layer_sizes=(15,), random_state=1\n",
    ")\n",
    "clf.fit(X, y)\n",
    "# MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,), random_state=1,\n",
    "#               solver='lbfgs')\n",
    "clf.predict([[1., 2.]])\n",
    "# array([[1, 1]])\n",
    "clf.predict([[0., 0.]])\n",
    "# array([[0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultez les exemples ci-dessous et la docstring de [**`MLPClassifier.fit`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier.fit) pour plus d'informations.\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**Comparaison des strat√©gies d'apprentissage stochastique pour `MLPClassifier`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_17_neural_networks/plot_mlp_training_curves.ipynb)<br/>([_Compare Stochastic learning strategies for `MLPClassifier`_](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_training_curves.html))\n",
    "\n",
    "##### [**Visualisation des poids MLP sur MNIST**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_17_neural_networks/plot_mnist_filters.ipynb)<br/>([_Visualization of MLP weights on MNIST_](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mnist_filters.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='regression'></a> 1.17.3. **R√©gression**<br/>([_Regression_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#regression))\n",
    "\n",
    "La classe [**`MLPRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) impl√©mente un perceptron multicouche (MLP) qui s'entra√Æne en utilisant la r√©tropropagation sans fonction d'activation dans la couche de sortie, ce qui peut √©galement √™tre vu comme l'utilisation de la fonction d'activation identit√©. Par cons√©quent, il utilise l'erreur quadratique comme fonction de perte, et la sortie est un ensemble de valeurs continues.\n",
    "\n",
    "[**`MLPRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) prend √©galement en charge la r√©gression multi-sortie, dans laquelle un √©chantillon peut avoir plus d'une cible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='regularization'></a> 1.17.4. **R√©gularisation**<br/>([_Regularization_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#regularization))\n",
    "\n",
    "[**`MLPRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) et [**`MLPClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) utilisent le param√®tre `alpha` pour la r√©gularisation (r√©gularisation $\\ell_2$), ce qui aide √† √©viter le surajustement en p√©nalisant les poids de grande magnitude. Le graphique ci-dessous affiche la fonction de d√©cision variable en fonction de la valeur de `alpha`.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_mlp_alpha_001.png\"\n",
    "    alt=\"R√©gularisation variable dans le Perceptron multicouche\"\n",
    "    style=\"max-width: 100%; height; auto;\"/>\n",
    "</div>\n",
    "\n",
    "Consultez les exemples ci-dessous pour plus d'informations.\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**R√©gularisation variable dans le Perceptron multicouche**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_17_neural_networks/plot_mlp_alpha.ipynb)<br/>([_Varying regularization in Multi-layer Perceptron_](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='algorithms'></a> 1.17.5. **Algorithmes**<br/>([_Algorithms_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#algorithms))\n",
    "\n",
    "Le MLP s'entra√Æne en utilisant la [**Descente de Gradient Stochastique*$ (SGD)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent), [**Adam**](https://arxiv.org/abs/1412.6980), ou [**L-BFGS**](https://en.wikipedia.org/wiki/Limited-memory_BFGS). La Descente de Gradient Stochastique (SGD) met √† jour les param√®tres en utilisant le gradient de la fonction de perte par rapport √† un param√®tre qui n√©cessite une adaptation, c'est-√†-dire :\n",
    "\n",
    "$$w \\leftarrow w - \\eta (\\alpha \\frac{\\partial R(w)}{\\partial w} + \\frac{\\partial Loss}{\\partial w})$$\n",
    "\n",
    "o√π $\\eta$ est le taux d'apprentissage qui contr√¥le la taille du pas dans l'espace des param√®tres. $Loss$ est la fonction de perte utilis√©e pour le r√©seau.\n",
    "\n",
    "Vous pouvez trouver plus de d√©tails dans la documentation de [**SGD** (1.5)](https://scikit-learn.org/stable/modules/sgd.html).\n",
    "\n",
    "Adam est similaire √† SGD dans le sens o√π c'est un optimiseur stochastique, mais il peut ajuster automatiquement la quantit√© pour mettre √† jour les param√®tres en se basant sur des estimations adaptatives des moments d'ordre inf√©rieur.\n",
    "\n",
    "Avec SGD ou Adam, l'entra√Ænement prend en charge l'apprentissage en ligne et par mini-lots.\n",
    "\n",
    "L-BFGS est un solveur qui approxime la matrice Hessienne, qui repr√©sente la d√©riv√©e partielle d'ordre deux d'une fonction. De plus, il approxime l'inverse de la matrice Hessienne pour effectuer les mises √† jour des param√®tres. La mise en ≈ìuvre utilise la version Scipy de [**L-BFGS**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html).\n",
    "\n",
    "Si le solveur s√©lectionn√© est 'L-BFGS', l'entra√Ænement ne prend pas en charge l'apprentissage en ligne ni par mini-lots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='complexity'></a> 1.17.6. **Complexit√©**<br/>([_Complexity_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#complexity))\n",
    "\n",
    "Supposons qu'il y ait $n$ √©chantillons d'entra√Ænement, $m$ caract√©ristiques, $k$ couches cach√©es, chacune contenant $h$ neurones (pour simplifier), et $o$ neurones de sortie. La complexit√© temporelle de la r√©tropropagation est $\\mathcal{O}(n\\cdot m \\cdot h^k \\cdot o \\cdot i)$, o√π $i$ est le nombre d'it√©rations. Comme la r√©tropropagation a une complexit√© temporelle √©lev√©e, il est conseill√© de commencer avec un plus petit nombre de neurones cach√©s et quelques couches cach√©es lors de l'entra√Ænement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='mathematical-formulation'></a> 1.17.7. **Formulation math√©matique**<br/>([_Mathematical formulation_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#mathematical-formulation))\n",
    "\n",
    "√âtant donn√© un ensemble d'exemples d'entra√Ænement $(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)$ o√π $x_i \\in \\mathbf{R}^n$ et $y_i \\in \\{0, 1\\}$, un MLP √† une couche cach√©e et un neurone apprend la fonction $f(x) = W_2 g(W_1^T x + b_1) + b_2$ o√π $W_1 \\in \\mathbf{R}^m$ sont les param√®tres du mod√®le. $W_1, W_2$ repr√©sentent les poids de la couche d'entr√©e et de la couche cach√©e, respectivement ; et $b_1, b_2$ repr√©sentent les biais ajout√©s √† la couche cach√©e et √† la couche de sortie, respectivement. $g(\\cdot) : R \\rightarrow R$ est la fonction d'activation, d√©finie par d√©faut comme la tangente hyperbolique. Elle est donn√©e par,\n",
    "\n",
    "$$g(z)= \\frac{e^z-e^{-z}}{e^z+e^{-z}}$$\n",
    "\n",
    "Pour la classification binaire, $f(x)$ passe par la fonction logistique $g(z)=1/(1+e^{-z})$ pour obtenir des valeurs de sortie entre z√©ro et un. Un seuil, fix√© √† 0,5, attribuerait les √©chantillons de sortie sup√©rieurs ou √©gaux √† 0,5 √† la classe positive, et les autres √† la classe n√©gative.\n",
    "\n",
    "S'il y a plus de deux classes, $f(x)$ serait lui-m√™me un vecteur de taille `(n_classes,)`. Au lieu de passer par la fonction logistique, il passe par la fonction softmax, qui s'√©crit comme suit,\n",
    "\n",
    "$$\\text{softmax}(z)_i = \\frac{\\exp(z_i)}{\\sum_{l=1}^k\\exp(z_l)}$$\n",
    "\n",
    "o√π $z_i$ repr√©sente le $i$-√®me √©l√©ment de l'entr√©e de softmax, qui correspond √† la classe $i$, et $k$ est le nombre de classes. Le r√©sultat est un vecteur contenant les probabilit√©s que l'√©chantillon $x$ appartienne √† chaque classe. La classe ayant la probabilit√© la plus √©lev√©e est la sortie.\n",
    "\n",
    "En r√©gression, la sortie reste telle que $f(x)$ ; par cons√©quent, la fonction d'activation de sortie est simplement la fonction identit√©.\n",
    "\n",
    "MLP utilise diff√©rentes fonctions de perte suivant le type de probl√®me. La fonction de perte pour la classification est l'entropie crois√©e moyenne (ACE), qui dans le cas binaire est donn√©e par,\n",
    "\n",
    "$$Loss(\\hat{y},y,W) = -\\dfrac{1}{n}\\sum_{i=0}^n(y_i \\ln {\\hat{y_i}} + (1-y_i) \\ln{(1-\\hat{y_i})}) + \\dfrac{\\alpha}{2n} ||W||_2^2$$\n",
    "\n",
    "o√π $\\alpha ||W||_2^2$ est un terme de r√©gularisation $\\ell_2$ (√©galement appel√© p√©nalit√©) qui p√©nalise les mod√®les complexes ; et $\\alpha > 0$ est un hyperparam√®tre non n√©gatif qui contr√¥le l'amplitude de la p√©nalit√©.\n",
    "\n",
    "Pour la r√©gression, MLP utilise la fonction de perte de l'erreur quadratique moyenne (MSE) ; √©crite comme suit,\n",
    "\n",
    "$$Loss(\\hat{y},y,W) = \\frac{1}{2n}\\sum_{i=0}^n||\\hat{y}_i - y_i ||_2^2 + \\frac{\\alpha}{2n} ||W||_2^2$$\n",
    "\n",
    "√Ä partir de poids initiaux al√©atoires, le perceptron multicouche (MLP) minimise la fonction de perte en mettant √† jour ces poids de mani√®re r√©p√©t√©e. Apr√®s le calcul de la perte, une passe en arri√®re la propage de la couche de sortie aux couches pr√©c√©dentes, fournissant √† chaque param√®tre de poids une valeur de mise √† jour destin√©e √† r√©duire la perte.\n",
    "\n",
    "Dans la descente de gradient, le gradient $\\nabla Loss_{W}$ de la perte par rapport aux poids est calcul√© et soustrait √† $W$. Plus formellement, cela s'exprime comme suit,\n",
    "\n",
    "$$W^{i+1} = W^i - \\epsilon \\nabla {Loss}_{W}^{i}$$\n",
    "\n",
    "o√π $i$ est l'√©tape d'it√©ration, et $\\epsilon$ est le taux d'apprentissage avec une valeur sup√©rieure √† 0.\n",
    "\n",
    "L'algorithme s'arr√™te lorsqu'il atteint un nombre maximum d'it√©rations pr√©d√©fini ; ou lorsque l'am√©lioration de la perte est inf√©rieure √† un certain petit seuil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='mathematical-formulation'></a> 1.17.8. **Conseils d'utilisation pratique**<br/>([_Tips on Practical Use_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use))\n",
    "\n",
    "- Le perceptron multicouche est sensible √† l'√©chelle des caract√©ristiques, il est donc fortement recommand√© de mettre √† l'√©chelle vos donn√©es. Par exemple, mettez √† l'√©chelle chaque attribut du vecteur d'entr√©e $X$ dans l'intervalle $[0, 1]$ ou $[-1, +1]$, ou standardisez-le pour avoir une moyenne de 0 et une variance de 1. Notez que vous devez appliquer la m√™me mise √† l'√©chelle √† l'ensemble de test pour obtenir des r√©sultats significatifs. Vous pouvez utiliser le [**`StandardScaler`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) pour la standardisation.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une approche alternative et recommand√©e est d'utiliser le [**`StandardScaler`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) dans un [**`Pipeline`**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline).\n",
    "\n",
    "- Trouver un param√®tre de r√©gularisation $\\alpha$ raisonnable se fait g√©n√©ralement en utilisant [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), g√©n√©ralement dans la plage `10.0 ** -np.arange(1, 7)`.\n",
    "\n",
    "- De mani√®re empirique, nous avons observ√© que `L-BFGS` converge plus rapidement et donne de meilleures solutions sur de petits ensembles de donn√©es. Cependant, pour des ensembles de donn√©es relativement importants, `Adam` est tr√®s robuste. Il converge g√©n√©ralement rapidement et offre de tr√®s bonnes performances. `SGD` avec moment ou moment de Nesterov, d'autre part, peut mieux performer que ces deux algorithmes si le taux d'apprentissage est correctement r√©gl√©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='more-control-with-warm-start'></a> 1.17.9. **Plus de contr√¥le avec `warm_start`**<br/>([_More control with `warm_start`_](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#more-control-with-warm-start))\n",
    "\n",
    "Si vous souhaitez avoir plus de contr√¥le sur les crit√®res d'arr√™t ou le taux d'apprentissage dans SGD, ou si vous souhaitez effectuer une surveillance suppl√©mentaire, l'utilisation de `warm_start=True` et `max_iter=1` et it√©rer vous-m√™me peut √™tre utile :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier(hidden_layer_sizes=(15,), random_state=1, max_iter=1, warm_start=True)\n",
    "for _ in range(10):\n",
    "    clf.fit(X, y)\n",
    "    # additional monitoring / inspection\n",
    "# MLPClassifier(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©f√©rences\n",
    "\n",
    "üî¨ [**‚ÄúLearning representations by back-propagating errors‚Äù**](https://www.iro.umontreal.ca/~pift6266/A06/refs/backprop_old.pdf). Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams.\n",
    "\n",
    "üåê [**‚ÄúStochastic Gradient Descent‚Äù**](https://leon.bottou.org/projects/sgd) L. Bottou - Website, 2010.\n",
    "\n",
    "X üåê [**‚ÄúBackpropagation‚Äù**](http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm) Andrew Ng, Jiquan Ngiam, Chuan Yu Foo, Yifan Mai, Caroline Suen - Website, 2011.\n",
    "\n",
    "üî¨ [**‚ÄúEfficient BackProp‚Äù**](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) Y. LeCun, L. Bottou, G. Orr, K. M√ºller - In Neural Networks: Tricks of the Trade 1998.\n",
    "\n",
    "üî¨ [**‚ÄúAdam: A method for stochastic optimization‚Äù**](https://arxiv.org/pdf/1412.6980.pdf). Kingma, Diederik, and Jimmy Ba (2014)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
