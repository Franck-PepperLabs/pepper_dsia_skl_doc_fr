{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='model-selection-and-evaluation'></a> 3. [**S√©lection et √©valuation de mod√®le**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#model-selection-and-evaluation)</br>([*Model selection and evaluation*](https://scikit-learn.org/stable/model_selection.html#model-selection-and-evaluation))\n",
    "\n",
    "# 3.1. [**Validation crois√©e¬†: √©valuer les performances des estimateurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-evaluating-estimator-performance)<br/>([_Cross-validation: evaluating estimator performance_](https://scikit-learn.org/stable/model_selection.html#cross-validation-evaluating-estimator-performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 25 pages, 7 exemples, 8 papiers\n",
    "- 3.1.1. [**Calcul de m√©triques √† validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#computing-cross-validated-metrics)<br/>([_computing-cross-validated-metrics_](https://scikit-learn.org/stable/model_selection.html#computing-cross-validated-metrics))\n",
    "- 3.1.2. [**It√©rateurs de validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-iterators)<br/>([_Cross validation iterators_](https://scikit-learn.org/stable/model_selection.html#cross-validation-iterators))\n",
    "- 3.1.3. [**Une note sur le brassage**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#a-note-on-shuffling)<br/>([_A note on shuffling_](https://scikit-learn.org/stable/model_selection.html#a-note-on-shuffling))\n",
    "- 3.1.4. [**Validation crois√©e et s√©lection de mod√®les**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-and-model-selection)<br/>([_cross-validation-and-model-selection_](https://scikit-learn.org/stable/model_selection.html#cross-validation-and-model-selection))\n",
    "- 3.1.5. [**Score de test de permutation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#permutation-test-score)<br/>([_Permutation test score_](https://scikit-learn.org/stable/model_selection.html#permutation-test-score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='computing-cross-validated-metrics'></a> 3.1. Validation crois√©e¬†: √©valuer les performances des estimateurs\n",
    "\n",
    "Apprendre les param√®tres d'une fonction de pr√©diction et la tester sur les m√™mes donn√©es est une erreur m√©thodologique : un mod√®le qui se contenterait de r√©p√©ter les √©tiquettes des √©chantillons qu'il vient de voir aurait un score parfait mais ne parviendrait pas √† pr√©dire quoi que ce soit d'utile sur de nouvelles donn√©es. Cette situation s'appelle le **surajustement**. Pour l'√©viter, il est courant lors de la r√©alisation d'une exp√©rience d'apprentissage automatique (supervis√©e) de conserver une partie des donn√©es disponibles sous forme d'**ensemble de test** `X_test`, `y_test`. Notez que le mot \"exp√©rience\" n'est pas destin√© √† d√©signer uniquement un usage acad√©mique, car m√™me dans les environnements commerciaux, l'apprentissage automatique commence g√©n√©ralement de mani√®re exp√©rimentale. Voici un organigramme du flux de travail typique de validation crois√©e dans l'entra√Ænement de mod√®les. Les meilleurs param√®tres peuvent √™tre d√©termin√©s par des techniques comme la [**recherche en grille** (3.2.1)](https://scikit-learn.org/stable/modules/grid_search.html#grid-search).\n",
    "\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Dans scikit-learn, une r√©partition al√©atoire en ensembles d'apprentissage et de test peut √™tre rapidement calcul√©e avec la fonction utilitaire [**`train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split). Chargeons l'ensemble de donn√©es Iris pour y adapter une machine √† vecteurs de support lin√©aire¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons d√©sormais √©chantillonner rapidement un ensemble d'entra√Ænement tout en conservant 40¬†% des donn√©es pour tester (√©valuer) notre classifieur¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "# ((90, 4), (90,))\n",
    "X_test.shape, y_test.shape\n",
    "# ((60, 4), (60,))\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "# 0.96..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'√©valuation de diff√©rents param√©trages (\"hyperparam√®tres\") pour les estimateurs, tels que le param√®tre `C` qui doit √™tre d√©fini manuellement pour une SVM, il existe toujours un risque de surapprentissage sur l'_ensemble de test_ car les param√®tres peuvent √™tre modifi√©s jusqu'√† ce que l'estimateur fonctionne de mani√®re optimale. De cette fa√ßon, les connaissances sur l'ensemble de test peuvent \"fuir\" dans le mod√®le et les m√©triques d'√©valuation ne plus rendre compte des performances de g√©n√©ralisation. Pour r√©soudre ce probl√®me, une autre partie de l'ensemble de donn√©es peut √™tre isol√©e en tant qu'\"ensemble de validation\": l'entra√Ænement se d√©roule sur l'ensemble d'entra√Ænement, apr√®s quoi l'√©valuation est effectu√©e sur l'ensemble de validation, et quand l'exp√©rience semble √™tre r√©ussie, l'√©valuation finale peut √™tre effectu√©e sur l'ensemble de test.\n",
    "\n",
    "Cependant, en partitionnant les donn√©es disponibles en trois ensembles, nous r√©duisons consid√©rablement le nombre d'√©chantillons qui peuvent √™tre utilis√©s pour entra√Æner le mod√®le, et les r√©sultats peuvent d√©pendre d'un choix al√©atoire particulier pour la paire d'ensembles (entra√Ænement, validation).\n",
    "\n",
    "Une solution √† ce probl√®me est une proc√©dure appel√©e [‚¶ø **validation crois√©e**](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) (CV (_Cross validation_) en abr√©g√©). Un ensemble de test doit toujours √™tre conserv√© pour l'√©valuation finale, mais l'ensemble de validation n'est plus n√©cessaire lors de la r√©alisation de la CV. Dans l'approche de base, appel√©e $k$-fold CV, l'ensemble d'apprentissage est divis√© en $k$ ensembles plus petits (d'autres approches sont d√©crites ci-dessous, mais suivent g√©n√©ralement les m√™mes principes). La proc√©dure suivante est suivie pour chacun des $k$ \"plis\"¬†:\n",
    "\n",
    "- Un mod√®le est entra√Æn√© sur $k - 1$ plis en tant que donn√©es d'apprentissage¬†;\n",
    "- le mod√®le r√©sultant est valid√© sur le pli restant (il est utilis√© comme ensemble de test pour calculer une mesure de performance telle que l'exactitude).\n",
    "\n",
    "La mesure de performance rapport√©e par la validation crois√©e $k$-plis est alors la moyenne des valeurs calcul√©es dans la boucle. Cette approche peut √™tre co√ªteuse en calcul, mais ne gaspille pas trop de donn√©es (comme c'est le cas lors du choix d'un ensemble de validation arbitraire), ce qui est un avantage majeur dans des probl√®mes tels que l'inf√©rence inverse o√π le nombre d'√©chantillons est tr√®s petit.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='computing-cross-validated-metrics'></a> 3.1.1. Calcul de m√©triques √† validation crois√©e\n",
    "\n",
    "La mani√®re la plus simple d'utiliser la validation crois√©e consiste √† appeler la fonction utilitaire [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) sur l'estimateur et l'ensemble de donn√©es.\n",
    "\n",
    "L'exemple suivant montre comment estimer la pr√©cision d'une machine √† vecteurs de support √† noyau lin√©aire sur l'ensemble de donn√©es iris en divisant les donn√©es, en ajustant un mod√®le et en calculant le score 5 fois cons√©cutives (avec des divisions diff√©rentes √† chaque fois)¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores\n",
    "# array([0.96..., 1. , 0.96..., 0.96..., 1. ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score moyen et l'√©cart type sont alors donn√©s par :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "# 0.98 accuracy with a standard deviation of 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©faut, le score calcul√© √† chaque it√©ration de la CV est donn√© par la m√©thode `score` de l'estimateur. Il est possible de changer cela en utilisant le param√®tre `scoring`` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')\n",
    "scores\n",
    "# array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [**Le param√®tre `scoring` : d√©finir les r√®gles d'√©valuation du mod√®le** (3.3.1)](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) pour plus de d√©tails. Dans le cas de l'ensemble de donn√©es Iris, les √©chantillons sont √©quilibr√©s entre les classes cibles, d'o√π le fait que l'exactitude et le score F1 sont presque √©gaux.\n",
    "\n",
    "Lorsque l'argument `cv` est un entier, [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) utilise par d√©faut les strat√©gies [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) ou [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), cette derni√®re √©tant utilis√©e si l'estimateur d√©rive de [**`ClassifierMixin`**](https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html).\n",
    "\n",
    "Il est √©galement possible d'utiliser d'autres strat√©gies de validation crois√©e en passant un it√©rateur de validation crois√©e √† la place, par exemple¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = X.shape[0]\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, X, y, cv=cv)\n",
    "# array([0.977..., 0.977..., 1.  ..., 0.955..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre option consiste √† utiliser un it√©rable fournissant des s√©parations (entra√Ænement, test) sous forme de tableaux d'indices, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97333333])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_cv_2folds(X):\n",
    "    n = X.shape[0]\n",
    "    for i in range(1, 3):\n",
    "        idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
    "        yield idx, idx\n",
    "\n",
    "custom_cv = custom_cv_2folds(X)\n",
    "cross_val_score(clf, X, y, cv=custom_cv)\n",
    "# array([1.        , 0.973...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation de donn√©es avec des donn√©es conserv√©es**\n",
    "\n",
    "Tout comme il est important de tester un estimateur sur les donn√©es d'entra√Ænement conserv√©es, le pr√©traitement (comme la normalisation, la s√©lection de caract√©ristiques, etc.) et les [**Transformations de donn√©es** (6)](https://scikit-learn.org/stable/data_transforms.html#data-transforms) similaires doivent √©galement √™tre apprises √† partir d'un ensemble d'entra√Ænement puis appliqu√©es aux donn√©es conserv√©es pour la pr√©diction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "clf.score(X_test_transformed, y_test)\n",
    "# 0.9333..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un [**`Pipeline`**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) facilite la composition des estimateurs, offrant ce comportement sous validation crois√©e¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.93333333, 0.95555556, 0.93333333, 0.97777778])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, X, y, cv=cv)\n",
    "# array([0.977..., 0.933..., 0.955..., 0.933..., 0.977...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [**Pipelines et estimateurs composites** (6.1)](https://scikit-learn.org/stable/modules/compose.html#combining-estimators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='the-cross-validate-function-and-multiple-metric-evaluation'></a> 3.1.1.1. La fonction `cross_validate` et l'√©valuation de m√©triques multiples\n",
    "\n",
    "La fonction [**`cross_validate`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) diff√®re de [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) de deux mani√®res¬†:\n",
    "\n",
    "- Elle permet de sp√©cifier plusieurs m√©triques pour l'√©valuation.\n",
    "- Elle renvoie un dictionnaire contenant les temps d'ajustement, les temps d'√©valuation (et √©ventuellement les scores d'entra√Ænement, les estimateurs ajust√©s, les indices de la partition entra√Ænement-test) en plus du score du test.\n",
    "\n",
    "Pour une √©valuation √† m√©trique unique, o√π le param√®tre de score est une cha√Æne, un `callable` ou `None`, les cl√©s seront - `['test_score', 'fit_time', 'score_time']`\n",
    "\n",
    "Et pour l'√©valuation √† m√©triques multiples, la valeur de retour est un dictionnaire avec les cl√©s suivantes - `['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']`\n",
    "\n",
    "La valeur par d√©faut de `return_train_score` est `False` pour √©conomiser du temps de calcul. Pour √©valuer √©galement les scores sur l'ensemble d'entra√Ænement, vous devez le d√©finir sur `True`. Vous pouvez √©galement conserver l'estimateur ajust√© pour chaque ensemble d'entra√Ænement en d√©finissant `return_estimator=True`. De m√™me, vous pouvez d√©finir `return_indices=True` pour conserver les indices d'entra√Ænement et de test utilis√©s pour diviser le jeu de donn√©es en ensembles d'entra√Ænement et de test pour chaque partition CV.\n",
    "\n",
    "Les multiples m√©triques peuvent √™tre sp√©cifi√©es sous forme de liste, de tuple ou d'ensemble de noms d'√©valuateurs pr√©d√©finis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "sorted(scores.keys())\n",
    "# ['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n",
    "scores['test_recall_macro']\n",
    "# array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou sous la forme d'un dictionnaire qui fait correspondre le nom de l'√©valuateur √† une fonction d'√©valuation pr√©d√©finie ou personnalis√©e :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.975     , 0.975     , 0.99166667, 0.98333333, 0.98333333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "scoring = {\n",
    "    'prec_macro': 'precision_macro',\n",
    "    'rec_macro': make_scorer(recall_score, average='macro')\n",
    "}\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5, return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "# ['fit_time', 'score_time', 'test_prec_macro', 'test_rec_macro',\n",
    "#  'train_prec_macro', 'train_rec_macro']\n",
    "scores['train_rec_macro']\n",
    "# array([0.97..., 0.97..., 0.99..., 0.98..., 0.98...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un exemple de `cross_validate` utilisant une m√©trique unique¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimator', 'fit_time', 'score_time', 'test_score']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(clf, X, y,\n",
    "                        scoring='precision_macro', cv=5,\n",
    "                        return_estimator=True)\n",
    "sorted(scores.keys())\n",
    "# ['estimator', 'fit_time', 'score_time', 'test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='obtaining-predictions-by-cross-validation'></a> 3.1.1.2. Obtenir des pr√©dictions par validation crois√©e\n",
    "\n",
    "La fonction [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) a une interface similaire √† [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), mais renvoie, pour chaque √©l√©ment de l'entr√©e, la pr√©diction qui a √©t√© obtenue pour cet √©l√©ment lorsqu'il √©tait dans l'ensemble de test. Seules les strat√©gies de validation crois√©e qui affectent tous les √©l√©ments √† un ensemble de test exactement une fois peuvent √™tre utilis√©es (sinon, une exception est lev√©e).\n",
    "\n",
    "> **Avertissement** : Remarque sur l'utilisation inappropri√©e de [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)  \n",
    "> Le r√©sultat de [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) peut √™tre diff√©rent de ceux obtenus avec [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) car les √©l√©ments sont regroup√©s diff√©remment. La fonction [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) prend une moyenne sur les plis de validation crois√©e, tandis que [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) renvoie simplement les √©tiquettes (ou probabilit√©s) de plusieurs mod√®les distincts non distingu√©s. Ainsi, [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) n'est pas une mesure appropri√©e de l'erreur de g√©n√©ralisation.\n",
    "\n",
    "**La fonction [`cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict) convient pour :**\n",
    "\n",
    "- La visualisation des pr√©dictions obtenues √† partir de diff√©rents mod√®les.\n",
    "- Le m√©lange de mod√®les : lorsque les pr√©dictions d'un estimateur supervis√© sont utilis√©es pour entra√Æner un autre estimateur dans le cadre des m√©thodes ensemblistes.\n",
    "\n",
    "Les it√©rateurs de validation crois√©e disponibles sont pr√©sent√©s dans la section suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### [**Caract√©ristique de fonctionnement du r√©cepteur (Receiver Operating Characteristic - ROC) avec validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_roc_crossval.ipynb)<br/>([_Receiver Operating Characteristic (ROC) with cross validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html))\n",
    "\n",
    "#### [**√âlimination r√©cursive des caract√©ristiques (RFE) avec validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_13_feature_selection/plot_rfe_with_cross_validation.ipynb)<br/>([_Recursive Feature Elimination (RFE) with cross-validation_](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html))\n",
    "\n",
    "#### [**Strat√©gie personnalis√©e de r√©ajustement d'une recherche en grille avec validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_digits.ipynb)<br/>([_Custom refit strategy of a grid search with cross-validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html))\n",
    "\n",
    "#### [**Exemple de pipeline pour l'extraction et l'√©valuation de caract√©ristiques de texte**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_text_feature_extraction.ipynb)<br/>([_Sample pipeline for text feature extraction and evaluation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_text_feature_extraction.html))\n",
    "\n",
    "#### [**Trac√© de pr√©dictions valid√©es par validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_cv_predict.ipynb)<br/>([_Plotting Cross-Validated Predictions_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_predict.html))\n",
    "\n",
    "#### [**Validation crois√©e imbriqu√©e vs. non-imbriqu√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_nested_cross_validation_iris.ipynb)<br/>([_Nested versus non-nested cross-validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='cross-validation-iterators'></a> 3.1.2. It√©rateurs de validation crois√©e\n",
    "\n",
    "Les sections suivantes r√©pertorient les utilitaires pour g√©n√©rer des indices pouvant √™tre utilis√©s pour diviser un ensemble de donn√©es en diff√©rents sous-ensembles selon diff√©rentes strat√©gies de validation crois√©e.\n",
    "\n",
    "### <a id='cross-validation-iterators-for-i-i-d-data'></a> 3.1.2.1. It√©rateurs de validation crois√©e pour les donn√©es i.i.d.\n",
    "\n",
    "Lorsque l'on suppose que des donn√©es sont ind√©pendantes et identiquement distribu√©es (i.i.d.), on fait l'hypoth√®se que tous les √©chantillons proviennent du m√™me processus de g√©n√©ration et que ce processus de g√©n√©ration ne se souvient pas des √©chantillons g√©n√©r√©s pr√©c√©demment.\n",
    "\n",
    "Les validateurs crois√©s suivants peuvent √™tre utilis√©s dans de tels cas.\n",
    "\n",
    "> **Note** : Bien que les donn√©es i.i.d. soient une hypoth√®se courante en th√©orie de l'apprentissage automatique, elle est rarement v√©rifi√©e en pratique. Si l'on sait que les √©chantillons ont √©t√© g√©n√©r√©s √† l'aide d'un processus d√©pendant du temps, il est pr√©f√©rable d'utiliser un [**sch√©ma de validation crois√©e prenant en compte les s√©ries temporelles** (3.1.2.6)](https://scikit-learn.org/stable/modules/cross_validation.html#timeseries-cv). De m√™me, si l'on sait que le processus de g√©n√©ration pr√©sente une structure de groupe (√©chantillons collect√©s aupr√®s de diff√©rents sujets, exp√©riences, dispositifs de mesure), il est pr√©f√©rable d'utiliser [**la validation crois√©e par groupe** (3.1.2.3)](https://scikit-learn.org/stable/modules/cross_validation.html#group-cv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='k-fold'></a> K-fold\n",
    "\n",
    "[**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) divise tous les √©chantillons en $k$ groupes d'√©chantillons, appel√©s plis (si $k = n$, cela √©quivaut √† la strat√©gie _Leave One Out_), de tailles √©gales (si possible). La fonction de pr√©diction est entra√Æn√©e √† l'aide de $k - 1$ plis, et le pli laiss√© de c√¥t√© est utilis√© pour le test.\n",
    "\n",
    "Exemple de validation crois√©e √† 2 plis sur un ensemble de donn√©es avec 4 √©chantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [2 3] [0 1]\n",
    "# [0 1] [2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une visualisation du comportement de la validation crois√©e. Notez que [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) n'est pas affect√© par les classes ou les groupes.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_006.png)\n",
    "\n",
    "Chaque pli est constitu√© de deux tableaux : le premier est li√© √† l'_ensemble d'entra√Ænement_, et le second √† l'_ensemble de test_. Ainsi, on peut cr√©er les ensembles d'entra√Ænement/test en utilisant l'indexation numpy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='repeated-k-fold'></a> K-fold r√©p√©t√©e\n",
    "\n",
    "[**`RepeatedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html) r√©p√®te [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) $n$ fois. Il peut √™tre utilis√© lorsque l'on souhaite ex√©cuter KFold $n$ fois, en produisant diff√©rentes divisions √† chaque r√©p√©tition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de validation crois√©e √† 2 plis r√©p√©t√©e 2 fois :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n",
      "[0 2] [1 3]\n",
      "[1 3] [0 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "random_state = 12883823\n",
    "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)\n",
    "for train, test in rkf.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [2 3] [0 1]\n",
    "# [0 1] [2 3]\n",
    "# [0 2] [1 3]\n",
    "# [1 3] [0 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De m√™me, [**`RepeatedStratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html) r√©p√®te Stratified K-Fold $n$ fois avec une randomisation diff√©rente √† chaque r√©p√©tition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='leave-one-out-loo'></a> Leave One Out (LOO)\n",
    "\n",
    "[**`LeaveOneOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html) (ou LOO) est une validation crois√©e simple. Chaque ensemble d'apprentissage est cr√©√© en prenant tous les √©chantillons sauf un, l'ensemble de test √©tant l'√©chantillon exclu. Ainsi, pour $n$ √©chantillons, nous avons $n$ ensembles d'apprentissage diff√©rents et $n$ ensembles de test diff√©rents. Cette proc√©dure de validation crois√©e ne gaspille pas beaucoup de donn√©es car un seul √©chantillon est retir√© de l'ensemble d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [0]\n",
      "[0 2 3] [1]\n",
      "[0 1 3] [2]\n",
      "[0 1 2] [3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "X = [1, 2, 3, 4]\n",
    "loo = LeaveOneOut()\n",
    "for train, test in loo.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [1 2 3] [0]\n",
    "# [0 2 3] [1]\n",
    "# [0 1 3] [2]\n",
    "# [0 1 2] [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les utilisateurs potentiels de LOO pour la s√©lection de mod√®les doivent prendre en compte quelques avertissements connus. Par rapport √† la validation crois√©e $k$-fold, on construit $n$ mod√®les √† partir des √©chantillons au lieu de $k$ mod√®les, o√π $n \\gt k$. De plus, chaque mod√®le est entra√Æn√© sur $n - 1$ √©chantillons au lieu de $(k-1) n / k$. Dans les deux cas, en supposant que $k$ n'est pas trop grand et $k \\lt n$, LOO est plus co√ªteux en termes de calcul que la validation crois√©e $k$-fold.\n",
    "\n",
    "En termes de pr√©cision, LOO conduit souvent √† une grande variance en tant qu'estimateur de l'erreur de test. Intuitivement, √©tant donn√© que $n - 1$ des $n$ √©chantillons sont utilis√©s pour construire chaque mod√®le, les mod√®les construits √† partir des plis sont pratiquement identiques les uns aux autres et au mod√®le construit √† partir de l'ensemble d'apprentissage complet.\n",
    "\n",
    "Cependant, si la courbe d'apprentissage est raide pour la taille d'entra√Ænement consid√©r√©e, une validation crois√©e √† 5 ou 10 plis peut surestimer l'erreur de g√©n√©ralisation.\n",
    "\n",
    "En r√®gle g√©n√©rale, la plupart des auteurs et des preuves empiriques sugg√®rent que la validation crois√©e √† 5 ou 10 plis devrait √™tre pr√©f√©r√©e √† LOO.\n",
    "\n",
    "##### R√©f√©rences\n",
    "\n",
    "- http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html\n",
    "- üìö T. Hastie, R. Tibshirani et J. Friedman, [**‚ÄúElements of Statistical Learning Ed. 2‚Äù**](https://hastie.su.domains/Papers/ESLII.pdf), Springer, 2009.\n",
    "- üî¨ L. Breiman, P. Spector [**‚ÄúSubmodel selection and evaluation in regression: The X-random case‚Äù**](https://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf), International Statistical Review 1992.\n",
    "- üî¨ R. Kohavi, [**‚ÄúA Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection‚Äù**](http://ai.stanford.edu/~ronnyk/accEst.pdf), Intl. Jnt. Conf. AI.\n",
    "- üî¨ R. Bharat Rao, G. Fung, R. Rosales, [**‚ÄúOn the Dangers of Cross-Validation. An Experimental Evaluation‚Äù**](https://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf), SIAM 2008.\n",
    "- üìö G. James, D. Witten, T. Hastie, R Tibshirani, [**‚ÄúAn Introduction to Statistical Learning‚Äù**](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf), Springer 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='leave-p-out-lpo'></a> Leave P Out (LPO)\n",
    "\n",
    "[**`LeavePOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html) est tr√®s similaire √† [**`LeaveOneOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html) car il cr√©e tous les ensembles d'entra√Ænement/test possibles en supprimant $p$ √©chantillons de l'ensemble complet. Pour $n$ √©chantillons, cela produit ${n \\choose p}$ paires d'ensembles d'entra√Ænement/test. Contrairement √† [**`LeaveOneOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html) et [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), les ensembles de test se chevaucheront pour $p \\gt 1$.\n",
    "\n",
    "Exemple de Leave-2-Out sur un ensemble de donn√©es avec 4 √©chantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[1 3] [0 2]\n",
      "[1 2] [0 3]\n",
      "[0 3] [1 2]\n",
      "[0 2] [1 3]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "X = np.ones(4)\n",
    "lpo = LeavePOut(p=2)\n",
    "for train, test in lpo.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [2 3] [0 1]\n",
    "# [1 3] [0 2]\n",
    "# [1 2] [0 3]\n",
    "# [0 3] [1 2]\n",
    "# [0 2] [1 3]\n",
    "# [0 1] [2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='random-permutations-cross-validation-a-k-a-shuffle-split'></a> Validation crois√©e par permutations al√©atoires, alias Shuffle & Split\n",
    "\n",
    "L'it√©rateur [**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) g√©n√©rera un nombre d√©fini par l'utilisateur de jeux de donn√©es d'entra√Ænement/test ind√©pendants. Les √©chantillons sont d'abord m√©lang√©s, puis divis√©s en une paire d'ensembles d'entra√Ænement et de test.\n",
    "\n",
    "Il est possible de contr√¥ler l'al√©atoire pour assurer la reproductibilit√© des r√©sultats en initialisant explicitement le g√©n√©rateur de nombres pseudo-al√©atoires `random_state`.\n",
    "\n",
    "Voici un exemple d'utilisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 1 6 7 3 0 5] [2 8 4]\n",
      "[2 9 8 0 6 7 4] [3 5 1]\n",
      "[4 5 1 0 6 9 7] [2 3 8]\n",
      "[2 7 5 8 0 3 4] [6 1 9]\n",
      "[4 1 0 6 8 9 3] [5 2 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = np.arange(10)\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(X):\n",
    "    print(f\"{train_index} {test_index}\")\n",
    "# [9 1 6 7 3 0 5] [2 8 4]\n",
    "# [2 9 8 0 6 7 4] [3 5 1]\n",
    "# [4 5 1 0 6 9 7] [2 3 8]\n",
    "# [2 7 5 8 0 3 4] [6 1 9]\n",
    "# [4 1 0 6 8 9 3] [5 2 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une visualisation du comportement de la validation crois√©e. Notez que [**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) n'est pas influenc√© par les classes ou les groupes.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_008.png)\n",
    "\n",
    "[**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) est donc une bonne alternative √† la validation crois√©e [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) qui permet un contr√¥le plus pr√©cis du nombre d'it√©rations et de la proportion d'√©chantillons de chaque c√¥t√© de la division d'entra√Ænement/test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='cross-validation-iterators-with-stratification-based-on-class-labels'></a> 3.1.2.2. It√©rateurs de validation crois√©e avec stratification bas√©e sur les √©tiquettes de classe\n",
    "\n",
    "Certains probl√®mes de classification peuvent pr√©senter un d√©s√©quilibre important dans la distribution des classes cibles : par exemple, il peut y avoir plusieurs fois plus d'√©chantillons n√©gatifs que d'√©chantillons positifs. Dans de tels cas, il est recommand√© d'utiliser un √©chantillonnage stratifi√© tel qu'impl√©ment√© dans [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) et [**`StratifiedShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) pour garantir que les fr√©quences relatives des classes sont approximativement pr√©serv√©es dans chaque pli d'entra√Ænement et de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='stratified-k-fold'></a> K-fold stratifi√©\n",
    "\n",
    "[**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) est une variation de la validation crois√©e _k-fold_ qui renvoie des plis _stratifi√©s_ : chaque ensemble contient approximativement le m√™me pourcentage d'√©chantillons de chaque classe cible que l'ensemble complet.\n",
    "\n",
    "Voici un exemple de validation crois√©e stratifi√©e √† 3 plis sur un ensemble de donn√©es avec 50 √©chantillons provenant de deux classes d√©s√©quilibr√©es. Nous montrons le nombre d'√©chantillons dans chaque classe et comparons avec [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [30  3]   |   test -  [15  2]\n",
      "train -  [30  3]   |   test -  [15  2]\n",
      "train -  [30  4]   |   test -  [15  1]\n",
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [34]   |   test -  [11  5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n",
    "X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print(f'train -  {np.bincount(y[train])}   |   test -  {np.bincount(y[test])}')\n",
    "# train -  [30  3]   |   test -  [15  2]\n",
    "# train -  [30  3]   |   test -  [15  2]\n",
    "# train -  [30  4]   |   test -  [15  1]\n",
    "kf = KFold(n_splits=3)\n",
    "for train, test in kf.split(X, y):\n",
    "    print(f'train -  {np.bincount(y[train])}   |   test -  {np.bincount(y[test])}')\n",
    "# train -  [28  5]   |   test -  [17]\n",
    "# train -  [28  5]   |   test -  [17]\n",
    "# train -  [34]   |   test -  [11  5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) pr√©serve les ratios de classes (environ 1/10) √† la fois dans l'ensemble d'apprentissage et dans l'ensemble de test.\n",
    "\n",
    "Voici une visualisation du comportement de la validation crois√©e.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_009.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='stratified-shuffle-split'></a> Stratified Shuffle Split\n",
    "\n",
    "[**`StratifiedShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) est une variation de _ShuffleSplit_ qui renvoie des s√©parations stratifi√©es, c'est-√†-dire qui cr√©e des s√©parations en conservant le m√™me pourcentage pour chaque classe cible que dans l'ensemble complet.\n",
    "\n",
    "Voici une visualisation du comportement de la validation crois√©e.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_012.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='cross-validation-iterators-for-grouped-data'></a> 3.1.2.3. It√©rateurs de validation crois√©e pour les donn√©es regroup√©es\n",
    "\n",
    "L'hypoth√®se i.i.d. est rompue si le processus g√©n√©ratif sous-jacent produit des groupes d'√©chantillons d√©pendants.\n",
    "\n",
    "Un tel regroupement de donn√©es d√©pend du domaine. Par exemple, il peut y avoir des donn√©es m√©dicales collect√©es aupr√®s de plusieurs patients, avec plusieurs √©chantillons pr√©lev√©s sur chaque patient. Et de telles donn√©es sont susceptibles de d√©pendre du groupe individuel. Dans notre exemple, l'identifiant du patient pour chaque √©chantillon sera son identifiant de groupe.\n",
    "\n",
    "Dans ce cas, nous aimerions savoir si un mod√®le entra√Æn√© sur un ensemble particulier de groupes g√©n√©ralise bien aux groupes non vus. Pour mesurer cela, nous devons nous assurer que tous les √©chantillons dans le pli de validation proviennent de groupes qui ne sont pas du tout repr√©sent√©s dans le pli d'apprentissage associ√©.\n",
    "\n",
    "Les diviseurs de validation crois√©e suivants peuvent √™tre utilis√©s pour cela. L'identifiant de regroupement des √©chantillons est sp√©cifi√© via le param√®tre `groups`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='group-k-fold'></a> K-fold par groupe\n",
    "\n",
    "[**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) est une variation de la validation crois√©e _k-fold_ qui garantit que le m√™me groupe n'est pas repr√©sent√© √† la fois dans les ensembles de test et d'apprentissage. Par exemple, si les donn√©es sont obtenues √† partir de sujets diff√©rents avec plusieurs √©chantillons par sujet et si le mod√®le est suffisamment flexible pour apprendre √† partir de caract√©ristiques tr√®s sp√©cifiques √† chaque personne, il pourrait ne pas g√©n√©raliser √† de nouveaux sujets. [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) permet de d√©tecter ce type de situations de surajustement.\n",
    "\n",
    "Imaginez que vous ayez trois sujets, chacun avec un num√©ro associ√© de 1 √† 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5] [6 7 8 9]\n",
      "[0 1 2 6 7 8 9] [3 4 5]\n",
      "[3 4 5 6 7 8 9] [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"d\", \"d\", \"d\"]\n",
    "groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
    "\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "for train, test in gkf.split(X, y, groups=groups):\n",
    "    print(f\"{train} {test}\")\n",
    "# [0 1 2 3 4 5] [6 7 8 9]\n",
    "# [0 1 2 6 7 8 9] [3 4 5]\n",
    "# [3 4 5 6 7 8 9] [0 1 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque sujet se trouve dans un pli de test diff√©rent, et le m√™me sujet n'est jamais √† la fois dans le test et dans l'apprentissage. Notez que les plis n'ont pas exactement la m√™me taille en raison du d√©s√©quilibre dans les donn√©es. Si les proportions de classe doivent √™tre √©quilibr√©es dans les plis, [**`StratifiedGroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html) est une meilleure option.\n",
    "\n",
    "Voici une visualisation du comportement de la validation crois√©e.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_007.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similaire √† [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), les ensembles de test de [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) formeront une partition compl√®te de l'ensemble des donn√©es. Contrairement √† [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) n'est pas du tout al√©atoire, tandis que KFold est al√©atoire lorsque `shuffle=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='stratifiedgroupkfold'></a> StratifiedGroupKFold\n",
    "\n",
    "[**`StratifiedGroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html) est un sch√©ma de validation crois√©e qui combine √† la fois [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) et [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html). L'id√©e est de tenter de pr√©server la distribution des classes dans chaque s√©paration tout en maintenant chaque groupe dans une seule s√©paration. Cela peut √™tre utile lorsque vous disposez d'un ensemble de donn√©es d√©s√©quilibr√©, de sorte que l'utilisation uniquement de [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) pourrait produire des s√©parations biais√©es.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  3  4  5  6  7 10 11 15 16 17] [ 1  8  9 12 13 14]\n",
      "[ 0  1  4  5  6  7  8  9 11 12 13 14] [ 2  3 10 15 16 17]\n",
      "[ 1  2  3  8  9 10 12 13 14 15 16 17] [ 0  4  5  6  7 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "X = list(range(18))\n",
    "y = [1] * 6 + [0] * 12\n",
    "groups = [1, 2, 3, 3, 4, 4, 1, 1, 2, 2, 3, 4, 5, 5, 5, 6, 6, 6]\n",
    "sgkf = StratifiedGroupKFold(n_splits=3)\n",
    "for train, test in sgkf.split(X, y, groups=groups):\n",
    "    print(f\"{train} {test}\")\n",
    "# [ 0  2  3  4  5  6  7 10 11 15 16 17] [ 1  8  9 12 13 14]\n",
    "# [ 0  1  4  5  6  7  8  9 11 12 13 14] [ 2  3 10 15 16 17]\n",
    "# [ 1  2  3  8  9 10 12 13 14 15 16 17] [ 0  4  5  6  7 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes d'impl√©mentation :\n",
    "\n",
    "- Avec l'impl√©mentation actuelle, un m√©lange complet n'est pas possible dans la plupart des sc√©narios. Lorsque `shuffle=True`, les √©tapes suivantes se produisent :\n",
    "    1. Tous les groupes sont m√©lang√©s.\n",
    "    2. Les groupes sont tri√©s par √©cart type des classes en utilisant un tri stable.\n",
    "    3. Les groupes tri√©s sont parcourus et assign√©s aux plis.\n",
    "- Cela signifie que seuls les groupes ayant le m√™me √©cart type de distribution de classes seront m√©lang√©s, ce qui peut √™tre utile lorsque chaque groupe n'a qu'une seule classe.\n",
    "- L'algorithme attribue de mani√®re gloutonne chaque groupe √† un des `n_splits` ensembles de test, en choisissant l'ensemble de test qui minimise la variance de la distribution des classes entre les ensembles de test. L'assignation des groupes se fait des groupes avec la plus grande variance √† la plus faible variance en termes de fr√©quence des classes, c'est-√†-dire que les grands groupes ayant des valeurs concentr√©es sur une ou quelques classes sont assign√©s en premier.\n",
    "- Cette division est sous-optimale dans le sens o√π elle peut produire des s√©parations d√©s√©quilibr√©es m√™me si une stratification parfaite est possible. Si vous avez une r√©partition relativement proche des classes dans chaque groupe, il vaut mieux utiliser [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html).\n",
    "\n",
    "Voici une visualisation du comportement de la validation crois√©e pour des groupes in√©gaux :\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_005.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='leave-one-group-out'></a> Laisser un groupe de c√¥t√© (LOGO - _Leave One Group Out_)\n",
    "\n",
    "[**`LeaveOneGroupOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html) est un sch√©ma de validation crois√©e dans lequel chaque division exclut les √©chantillons appartenant √† un groupe sp√©cifique. Les informations de groupe sont fournies via un tableau qui encode le groupe de chaque √©chantillon.\n",
    "\n",
    "Chaque ensemble d'entra√Ænement est donc constitu√© de tous les √©chantillons, sauf ceux d'un groupe sp√©cifique. Cela correspond √† [**`LeavePGroupsOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html) avec `n_groups=1` et est similaire √† [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) avec `n_splits` √©gal au nombre d'√©tiquettes uniques pass√©es au param√®tre `groups`.\n",
    "\n",
    "Par exemple, dans le cas d'exp√©riences multiples, [**`LeaveOneGroupOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html) peut √™tre utilis√© pour cr√©er une validation crois√©e bas√©e sur diff√©rentes exp√©riences : nous cr√©ons un ensemble d'entra√Ænement en utilisant les √©chantillons de toutes les exp√©riences, √† l'exception d'une seule d'entre elles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "X = [1, 5, 10, 50, 60, 70, 80]\n",
    "y = [0, 1, 1, 2, 2, 2, 2]\n",
    "groups = [1, 1, 2, 2, 3, 3, 3]\n",
    "logo = LeaveOneGroupOut()\n",
    "for train, test in logo.split(X, y, groups=groups):\n",
    "    print(f\"{train} {test}\")\n",
    "# [2 3 4 5 6] [0 1]\n",
    "# [0 1 4 5 6] [2 3]\n",
    "# [0 1 2 3] [4 5 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre application courante est d'utiliser des informations temporelles : par exemple, les groupes pourraient √™tre l'ann√©e de collecte des √©chantillons, permettant ainsi une validation crois√©e bas√©e sur des s√©parations temporelles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='leave-p-groups-out'></a> Laisser P groupes de c√¥t√© (LPGO - _Leave P Groups Out_)\n",
    "\n",
    "[**`LeavePGroupsOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html) est similaire √† [**`LeaveOneGroupOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html), mais il supprime les √©chantillons li√©s √† $P$ groupes pour chaque ensemble d'entra√Ænement/test. Toutes les combinaisons possibles de $P$ groupes sont exclues, ce qui signifie que les ensembles de test se chevauchent lorsque $P \\gt 1$.\n",
    "\n",
    "Exemple de Laisser-2-Groupes de c√¥t√© :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "X = np.arange(6)\n",
    "y = [1, 1, 1, 2, 2, 2]\n",
    "groups = [1, 1, 2, 2, 3, 3]\n",
    "lpgo = LeavePGroupsOut(n_groups=2)\n",
    "for train, test in lpgo.split(X, y, groups=groups):\n",
    "    print(f\"{train} {test}\")\n",
    "# [4 5] [0 1 2 3]\n",
    "# [2 3] [0 1 4 5]\n",
    "# [0 1] [2 3 4 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='group-shuffle-split'></a> Groupe Shuffle Split\n",
    "\n",
    "L'it√©rateur [**`GroupShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) fonctionne comme une combinaison de [**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) et de [**`LeavePGroupsOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html), et g√©n√®re une s√©quence de partitions al√©atoires dans lesquelles un sous-ensemble de groupes est exclu pour chaque division. Chaque division d'entra√Ænement/test est effectu√©e ind√©pendamment, ce qui signifie qu'il n'y a pas de relation garantie entre les ensembles de test successifs.\n",
    "\n",
    "Voici un exemple d'utilisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"]\n",
    "groups = [1, 1, 2, 2, 3, 3, 4, 4]\n",
    "gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)\n",
    "for train, test in gss.split(X, y, groups=groups):\n",
    "    print(f\"{train} {test}\")\n",
    "# [0 1 2 3] [4 5 6 7]\n",
    "# [2 3 6 7] [0 1 4 5]\n",
    "# [2 3 4 5] [0 1 6 7]\n",
    "# [4 5 6 7] [0 1 2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une visualisation du comportement de la validation crois√©e.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_011.png)\n",
    "\n",
    "Cette classe est utile lorsque le comportement de [**`LeavePGroupsOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html) est souhait√©, mais que le nombre de groupes est suffisamment √©lev√© pour que la g√©n√©ration de toutes les partitions possibles avec $P$ groupes exclus soit prohibitivement co√ªteuse. Dans un tel sc√©nario, [**`GroupShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) fournit un √©chantillon al√©atoire (avec remplacement) des ensembles d'entra√Ænement/test g√©n√©r√©s par [**`LeavePGroupsOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='predefined-fold-splits-validation-sets'></a> 3.1.2.4. Divisions pr√©d√©finies\n",
    "\n",
    "Pour certains ensembles de donn√©es, une r√©partition pr√©d√©finie des donn√©es en ensembles d'entra√Ænement et de validation, ou en plusieurs ensembles de validation crois√©e, existe d√©j√†. En utilisant [**`PredefinedSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html), il est possible d'utiliser ces r√©partitions, par exemple lors de la recherche des hyperparam√®tres.\n",
    "\n",
    "Par exemple, lorsque vous utilisez un ensemble de validation, d√©finissez la valeur `test_fold` √† 0 pour tous les √©chantillons faisant partie de l'ensemble de validation, et √† -1 pour tous les autres √©chantillons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='using-cross-validation-iterators-to-split-train-and-test'></a> 3.1.2.5. Utilisation d'it√©rateurs de validation crois√©e pour s√©parer les ensembles d'entra√Ænement et de test\n",
    "\n",
    "Les fonctions de validation crois√©e bas√©es sur les groupes mentionn√©es ci-dessus peuvent √©galement √™tre utiles pour diviser un ensemble de donn√©es en sous-ensembles d'entra√Ænement et de test. Notez que la fonction pratique [**`train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) est un wrapper autour de [**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) et ne permet donc que des divisions stratifi√©es (en utilisant les √©tiquettes de classe) et ne prend pas en compte les groupes.\n",
    "\n",
    "Pour effectuer la division en ensembles d'entra√Ænement et de test, utilisez les indices des sous-ensembles d'entra√Ænement et de test g√©n√©r√©s par le g√©n√©rateur renvoy√© par la m√©thode `split()` du diviseur de validation crois√©e. Par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "X = np.array([0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001])\n",
    "y = np.array([\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"])\n",
    "groups = np.array([1, 1, 2, 2, 3, 3, 4, 4])\n",
    "train_indx, test_indx = next(\n",
    "    GroupShuffleSplit(random_state=7).split(X, y, groups)\n",
    ")\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    X[train_indx], X[test_indx], y[train_indx], y[test_indx]\n",
    "X_train.shape, X_test.shape\n",
    "# ((6,), (2,))\n",
    "np.unique(groups[train_indx]), np.unique(groups[test_indx])\n",
    "# (array([1, 2, 4]), array([3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='cross-validation-of-time-series-data'></a> 3.1.2.6. Validation crois√©e des donn√©es de s√©ries temporelles\n",
    "\n",
    "Les donn√©es de s√©ries temporelles se caract√©risent par la corr√©lation entre les observations qui sont proches dans le temps (_autocorr√©lation_). Cependant, les techniques de validation crois√©e classiques telles que [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) et [**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) supposent que les √©chantillons sont ind√©pendants et identiquement distribu√©s, ce qui conduirait √† une corr√©lation d√©raisonnable entre les instances d'entra√Ænement et de test (donnant de mauvaises estimations de l'erreur de g√©n√©ralisation) sur les donn√©es de s√©ries temporelles. Par cons√©quent, il est tr√®s important d'√©valuer notre mod√®le pour les donn√©es de s√©ries temporelles sur les observations \"futures\" les moins similaires √† celles utilis√©es pour entra√Æner le mod√®le. Pour cela, une solution est propos√©e par [**`TimeSeriesSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='time-series-split'></a> Division des s√©ries temporelles\n",
    "\n",
    "[**`TimeSeriesSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) est une variation de _k-fold_ qui renvoie les $k$ premi√®res partitions comme ensemble d'entra√Ænement et la $k + 1$-√®me partition comme ensemble de test. Notez que, contrairement aux m√©thodes de validation crois√©e standard, les ensembles d'entra√Ænement successifs sont des ensembles englobants de ceux qui les pr√©c√®dent. De plus, tous les √©chantillons exc√©dentaires sont ajout√©s √† la premi√®re partition d'entra√Ænement, qui est toujours utilis√©e pour entra√Æner le mod√®le.\n",
    "\n",
    "Cette classe peut √™tre utilis√©e pour effectuer la validation crois√©e des √©chantillons de donn√©es de s√©ries temporelles observ√©es √† intervalles de temps fixes.\n",
    "\n",
    "Exemple d'une validation crois√©e en 3 parties sur des donn√©es de s√©ries temporelles avec 6 √©chantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)\n",
    "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)\n",
    "for train, test in tscv.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [0 1 2] [3]\n",
    "# [0 1 2 3] [4]\n",
    "# [0 1 2 3 4] [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une visualisation du comportement de la validation crois√©e.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_013.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='a-note-on-shuffling'></a> 3.1.3. Note sur le m√©lange\n",
    "\n",
    "Si l'ordre des donn√©es n'est pas arbitraire (par exemple, les √©chantillons avec la m√™me √©tiquette de classe sont contigus), le m√©langer en premier peut √™tre essentiel pour obtenir un r√©sultat de validation crois√©e significatif. Cependant, l'inverse peut √™tre vrai si les √©chantillons ne sont pas ind√©pendants et identiquement distribu√©s. Par exemple, si les √©chantillons correspondent √† des articles de presse et sont tri√©s par leur date de publication, alors le m√©lange des donn√©es conduira probablement √† un mod√®le qui est surajust√© et √† un score de validation artificiellement √©lev√© : il sera test√© sur des √©chantillons artificiellement similaires (proches dans le temps) aux √©chantillons d'entra√Ænement.\n",
    "\n",
    "Certains diviseurs de validation crois√©e, comme [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), ont une option int√©gr√©e pour m√©langer les indices des donn√©es avant de les diviser. Notez que :\n",
    "\n",
    "- Cela consomme moins de m√©moire que le m√©lange direct des donn√©es.\n",
    "- Par d√©faut, aucun m√©lange n'est effectu√©, y compris pour la validation crois√©e (stratifi√©e) K-fold r√©alis√©e en sp√©cifiant `cv=un_entier` √† [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), la recherche en grille, etc. Gardez √† l'esprit que [**`train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) retourne toujours une division al√©atoire.\n",
    "- Le param√®tre `random_state` est par d√©faut √† `None`, ce qui signifie que le m√©lange sera diff√©rent √† chaque it√©ration de `KFold(..., shuffle=True)`. Cependant, `GridSearchCV` utilisera le m√™me m√©lange pour chaque ensemble de param√®tres valid√© par un seul appel √† sa m√©thode `fit`.\n",
    "- Pour obtenir des r√©sultats identiques pour chaque division, d√©finissez `random_state` sur un entier.\n",
    "\n",
    "Pour plus de d√©tails sur la fa√ßon de contr√¥ler le caract√®re al√©atoire des diviseurs de validation crois√©e et √©viter les probl√®mes courants, voir [**Contr√¥ler le hasard** (10.3)](https://scikit-learn.org/stable/common_pitfalls.html#randomness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='cross-validation-and-model-selection'></a> 3.1.4. Validation crois√©e et s√©lection de mod√®le\n",
    "\n",
    "Les diviseurs de validation crois√©e peuvent √©galement √™tre utilis√©s pour effectuer directement la s√©lection de mod√®le en utilisant la recherche en grille pour les hyperparam√®tres optimaux du mod√®le. C'est le sujet de la prochaine section : [**R√©glage des hyperparam√®tres d'un estimateur** (3.2)](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='permutation-test-score'></a> 3.1.5. Score de test de permutation\n",
    "\n",
    "[**`permutation_test_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html) offre une autre fa√ßon d'√©valuer les performances des classifieurs. Il fournit une valeur p bas√©e sur des permutations, qui repr√©sente √† quel point les performances observ√©es du classifieur pourraient √™tre obtenues par hasard. L'hypoth√®se nulle dans ce test est que le classifieur ne parvient pas √† exploiter une quelconque d√©pendance statistique entre les caract√©ristiques et les √©tiquettes pour effectuer des pr√©dictions correctes sur les donn√©es exclues. [**`permutation_test_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html) g√©n√®re une distribution nulle en calculant `n_permutations` diff√©rentes permutations des donn√©es. Dans chaque permutation, les √©tiquettes sont m√©lang√©es al√©atoirement, supprimant ainsi toute d√©pendance entre les caract√©ristiques et les √©tiquettes. La valeur p est le nombre de permutations pour lesquelles le score de validation crois√©e moyen obtenu par le mod√®le est meilleur que le score de validation crois√©e obtenu par le mod√®le en utilisant les donn√©es d'origine. Pour des r√©sultats fiables, `n_permutations` devrait g√©n√©ralement √™tre sup√©rieur √† 100 et `cv` entre 3 et 10 partitions.\n",
    "\n",
    "Une faible valeur p indique que l'ensemble de donn√©es contient une d√©pendance r√©elle entre les caract√©ristiques et les √©tiquettes et que le classifieur a √©t√© capable de l'utiliser pour obtenir de bons r√©sultats. Une valeur p √©lev√©e peut √™tre due √† l'absence de d√©pendance entre les caract√©ristiques et les √©tiquettes (il n'y a pas de diff√©rence dans les valeurs des caract√©ristiques entre les classes) ou parce que le classifieur n'a pas pu utiliser la d√©pendance dans les donn√©es. Dans ce dernier cas, l'utilisation d'un classifieur plus appropri√© capable d'utiliser la structure des donn√©es conduirait √† une valeur p plus faible.\n",
    "\n",
    "La validation crois√©e fournit des informations sur la capacit√© de g√©n√©ralisation d'un classifieur, en particulier sur la plage des erreurs attendues du classifieur. Cependant, un classifieur entra√Æn√© sur un ensemble de donn√©es de grande dimension sans structure peut encore mieux se comporter que pr√©vu en validation crois√©e, simplement par hasard. Cela peut se produire g√©n√©ralement avec de petits ensembles de donn√©es contenant moins de quelques centaines d'√©chantillons. [**`permutation_test_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html) fournit des informations sur la mesure dans laquelle le classifieur a trouv√© une v√©ritable structure de classe et peut aider √† √©valuer les performances du classifieur.\n",
    "\n",
    "Il est important de noter que ce test a montr√© qu'il produit des valeurs p basses m√™me s'il n'y a qu'une faible structure dans les donn√©es, car il n'y a absolument aucune structure dans les ensembles de donn√©es permut√©s correspondants. Ce test est donc capable de montrer quand le mod√®le surpasse de mani√®re fiable une pr√©diction al√©atoire.\n",
    "\n",
    "Enfin, [**`permutation_test_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html) est calcul√© de mani√®re exhaustive et ajuste en interne `(n_permutations + 1) * n_cv` mod√®les. Il est donc r√©alisable uniquement avec de petits ensembles de donn√©es pour lesquels l'ajustement d'un mod√®le individuel est tr√®s rapide.\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**Test par permutations de la signifiance d'un score de classification**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_permutation_tests_for_classification.ipynb)<br/>([_Test with permutations the significance of a classification score_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_permutation_tests_for_classification.html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
