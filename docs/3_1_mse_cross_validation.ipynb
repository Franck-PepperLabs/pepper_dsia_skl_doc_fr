{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='model-selection-and-evaluation'></a> 3. [**Sélection et évaluation de modèle**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#model-selection-and-evaluation)</br>([*Model selection and evaluation*](https://scikit-learn.org/stable/model_selection.html#model-selection-and-evaluation))\n",
    "\n",
    "# 3.1. [**Validation croisée : évaluer les performances des estimateurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-evaluating-estimator-performance)<br/>([_Cross-validation: evaluating estimator performance_](https://scikit-learn.org/stable/model_selection.html#cross-validation-evaluating-estimator-performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 25 pages, 7 exemples, 7 papiers\n",
    "- 3.1.1. [**Calcul de métriques à validation croisée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#computing-cross-validated-metrics)<br/>([_computing-cross-validated-metrics_](https://scikit-learn.org/stable/model_selection.html#computing-cross-validated-metrics))\n",
    "- 3.1.2. [**Itérateurs de validation croisée**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-iterators)<br/>([_Cross validation iterators_](https://scikit-learn.org/stable/model_selection.html#cross-validation-iterators))\n",
    "- 3.1.3. [**Une note sur le brassage**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#a-note-on-shuffling)<br/>([_A note on shuffling_](https://scikit-learn.org/stable/model_selection.html#a-note-on-shuffling))\n",
    "- 3.1.4. [**Validation croisée et sélection de modèles**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-and-model-selection)<br/>([_cross-validation-and-model-selection_](https://scikit-learn.org/stable/model_selection.html#cross-validation-and-model-selection))\n",
    "- 3.1.5. [**Résultat du test de permutation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#permutation-test-score)<br/>([_Permutation test score_](https://scikit-learn.org/stable/model_selection.html#permutation-test-score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='computing-cross-validated-metrics'></a> 3.1. Validation croisée : évaluer les performances des estimateurs\n",
    "\n",
    "Apprendre les paramètres d'une fonction de prédiction et la tester sur les mêmes données est une erreur méthodologique : un modèle qui se contenterait de répéter les étiquettes des échantillons qu'il vient de voir aurait un score parfait mais ne parviendrait pas à prédire quoi que ce soit d'utile sur de nouvelles données. Cette situation s'appelle le **surajustement**. Pour l'éviter, il est courant lors de la réalisation d'une expérience d'apprentissage automatique (supervisée) de conserver une partie des données disponibles sous forme d'**ensemble de test** `X_test`, `y_test`. Notez que le mot \"expérience\" n'est pas destiné à désigner uniquement un usage académique, car même dans les environnements commerciaux, l'apprentissage automatique commence généralement de manière expérimentale. Voici un organigramme du flux de travail typique de validation croisée dans l'entraînement de modèles. Les meilleurs paramètres peuvent être déterminés par des techniques comme la [**recherche en grille** (3.2.1)](https://scikit-learn.org/stable/modules/grid_search.html#grid-search).\n",
    "\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Dans scikit-learn, une répartition aléatoire en ensembles d'apprentissage et de test peut être rapidement calculée avec la fonction utilitaire [**`train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split). Chargeons l'ensemble de données Iris pour y adapter une machine à vecteurs de support linéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons désormais échantillonner rapidement un ensemble d'entraînement tout en conservant 40 % des données pour tester (évaluer) notre classifieur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "# ((90, 4), (90,))\n",
    "X_test.shape, y_test.shape\n",
    "# ((60, 4), (60,))\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "# 0.96..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'évaluation de différents paramétrages (\"hyperparamètres\") pour les estimateurs, tels que le paramètre `C` qui doit être défini manuellement pour une SVM, il existe toujours un risque de surapprentissage sur l'_ensemble de test_ car les paramètres peuvent être modifiés jusqu'à ce que l'estimateur fonctionne de manière optimale. De cette façon, les connaissances sur l'ensemble de test peuvent \"fuir\" dans le modèle et les métriques d'évaluation ne plus rendre compte des performances de généralisation. Pour résoudre ce problème, une autre partie de l'ensemble de données peut être isolée en tant qu'\"ensemble de validation\": l'entraînement se déroule sur l'ensemble d'entraînement, après quoi l'évaluation est effectuée sur l'ensemble de validation, et quand l'expérience semble être réussie, l'évaluation finale peut être effectuée sur l'ensemble de test.\n",
    "\n",
    "Cependant, en partitionnant les données disponibles en trois ensembles, nous réduisons considérablement le nombre d'échantillons qui peuvent être utilisés pour entraîner le modèle, et les résultats peuvent dépendre d'un choix aléatoire particulier pour la paire d'ensembles (entraînement, validation).\n",
    "\n",
    "Une solution à ce problème est une procédure appelée [⦿ **validation croisée**](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) (CV (_Cross validation_) en abrégé). Un ensemble de test doit toujours être conservé pour l'évaluation finale, mais l'ensemble de validation n'est plus nécessaire lors de la réalisation de la CV. Dans l'approche de base, appelée $k$-fold CV, l'ensemble d'apprentissage est divisé en $k$ ensembles plus petits (d'autres approches sont décrites ci-dessous, mais suivent généralement les mêmes principes). La procédure suivante est suivie pour chacun des $k$ \"plis\" :\n",
    "\n",
    "- Un modèle est entraîné sur $k - 1$ plis en tant que données d'apprentissage ;\n",
    "- le modèle résultant est validé sur le pli restant (il est utilisé comme ensemble de test pour calculer une mesure de performance telle que l'exactitude).\n",
    "\n",
    "La mesure de performance rapportée par la validation croisée $k$-plis est alors la moyenne des valeurs calculées dans la boucle. Cette approche peut être coûteuse en calcul, mais ne gaspille pas trop de données (comme c'est le cas lors du choix d'un ensemble de validation arbitraire), ce qui est un avantage majeur dans des problèmes tels que l'inférence inverse où le nombre d'échantillons est très petit.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='computing-cross-validated-metrics'></a> 3.1.1. Calcul de métriques à validation croisée\n",
    "\n",
    "La manière la plus simple d'utiliser la validation croisée consiste à appeler la fonction utilitaire [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) sur l'estimateur et l'ensemble de données.\n",
    "\n",
    "L'exemple suivant montre comment estimer la précision d'une machine à vecteurs de support à noyau linéaire sur l'ensemble de données iris en divisant les données, en ajustant un modèle et en calculant le score 5 fois consécutives (avec des divisions différentes à chaque fois) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores\n",
    "# array([0.96..., 1. , 0.96..., 0.96..., 1. ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score moyen et l'écart type sont alors donnés par :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "# 0.98 accuracy with a standard deviation of 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, le score calculé à chaque itération de la CV est donné par la méthode `score` de l'estimateur. Il est possible de changer cela en utilisant le paramètre `scoring`` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')\n",
    "scores\n",
    "# array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [**Le paramètre `scoring` : définir les règles d'évaluation du modèle** (3.3.1)](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) pour plus de détails. Dans le cas de l'ensemble de données Iris, les échantillons sont équilibrés entre les classes cibles, d'où le fait que l'exactitude et le score F1 sont presque égaux.\n",
    "\n",
    "Lorsque l'argument `cv` est un entier, [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) utilise par défaut les stratégies [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) ou [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), cette dernière étant utilisée si l'estimateur dérive de [**`ClassifierMixin`**](https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html).\n",
    "\n",
    "Il est également possible d'utiliser d'autres stratégies de validation croisée en passant un itérateur de validation croisée à la place, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = X.shape[0]\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, X, y, cv=cv)\n",
    "# array([0.977..., 0.977..., 1.  ..., 0.955..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre option consiste à utiliser un itérable fournissant des séparations (entraînement, test) sous forme de tableaux d'indices, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97333333])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_cv_2folds(X):\n",
    "    n = X.shape[0]\n",
    "    for i in range(1, 3):\n",
    "        idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
    "        yield idx, idx\n",
    "\n",
    "custom_cv = custom_cv_2folds(X)\n",
    "cross_val_score(clf, X, y, cv=custom_cv)\n",
    "# array([1.        , 0.973...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation de données avec des données conservées**\n",
    "\n",
    "Tout comme il est important de tester un estimateur sur les données d'entraînement conservées, le prétraitement (comme la normalisation, la sélection de caractéristiques, etc.) et les [**Transformations de données** (6)](https://scikit-learn.org/stable/data_transforms.html#data-transforms) similaires doivent également être apprises à partir d'un ensemble d'entraînement puis appliquées aux données conservées pour la prédiction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "clf.score(X_test_transformed, y_test)\n",
    "# 0.9333..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un [**`Pipeline`**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) facilite la composition des estimateurs, offrant ce comportement sous validation croisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.93333333, 0.95555556, 0.93333333, 0.97777778])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, X, y, cv=cv)\n",
    "# array([0.977..., 0.933..., 0.955..., 0.933..., 0.977...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [**Pipelines et estimateurs composites** (6.1)](https://scikit-learn.org/stable/modules/compose.html#combining-estimators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='the-cross-validate-function-and-multiple-metric-evaluation'></a> 3.1.1.1. La fonction `cross_validate` et l'évaluation de métriques multiples\n",
    "\n",
    "La fonction [**`cross_validate`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) diffère de [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) de deux manières :\n",
    "\n",
    "- Elle permet de spécifier plusieurs métriques pour l'évaluation.\n",
    "- Elle renvoie un dictionnaire contenant les temps d'ajustement, les temps d'évaluation (et éventuellement les scores d'entraînement, les estimateurs ajustés, les indices de la partition entraînement-test) en plus du score du test.\n",
    "\n",
    "Pour une évaluation à métrique unique, où le paramètre de score est une chaîne, un `callable` ou `None`, les clés seront - `['test_score', 'fit_time', 'score_time']`\n",
    "\n",
    "Et pour l'évaluation à métriques multiples, la valeur de retour est un dictionnaire avec les clés suivantes - `['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']`\n",
    "\n",
    "La valeur par défaut de `return_train_score` est `False` pour économiser du temps de calcul. Pour évaluer également les scores sur l'ensemble d'entraînement, vous devez le définir sur `True`. Vous pouvez également conserver l'estimateur ajusté pour chaque ensemble d'entraînement en définissant `return_estimator=True`. De même, vous pouvez définir `return_indices=True` pour conserver les indices d'entraînement et de test utilisés pour diviser le jeu de données en ensembles d'entraînement et de test pour chaque partition CV.\n",
    "\n",
    "Les multiples métriques peuvent être spécifiées sous forme de liste, de tuple ou d'ensemble de noms d'évaluateurs prédéfinis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "sorted(scores.keys())\n",
    "# ['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n",
    "scores['test_recall_macro']\n",
    "# array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou sous la forme d'un dictionnaire qui fait correspondre le nom de l'évaluateur à une fonction d'évaluation prédéfinie ou personnalisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.975     , 0.975     , 0.99166667, 0.98333333, 0.98333333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "scoring = {\n",
    "    'prec_macro': 'precision_macro',\n",
    "    'rec_macro': make_scorer(recall_score, average='macro')\n",
    "}\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5, return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "# ['fit_time', 'score_time', 'test_prec_macro', 'test_rec_macro',\n",
    "#  'train_prec_macro', 'train_rec_macro']\n",
    "scores['train_rec_macro']\n",
    "# array([0.97..., 0.97..., 0.99..., 0.98..., 0.98...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un exemple de `cross_validate` utilisant une métrique unique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimator', 'fit_time', 'score_time', 'test_score']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(clf, X, y,\n",
    "                        scoring='precision_macro', cv=5,\n",
    "                        return_estimator=True)\n",
    "sorted(scores.keys())\n",
    "# ['estimator', 'fit_time', 'score_time', 'test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='obtaining-predictions-by-cross-validation'></a> 3.1.1.2. Obtenir des prédictions par validation croisée\n",
    "\n",
    "La fonction [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) a une interface similaire à [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), mais renvoie, pour chaque élément de l'entrée, la prédiction qui a été obtenue pour cet élément lorsqu'il était dans l'ensemble de test. Seules les stratégies de validation croisée qui affectent tous les éléments à un ensemble de test exactement une fois peuvent être utilisées (sinon, une exception est levée).\n",
    "\n",
    "> **Avertissement** : Remarque sur l'utilisation inappropriée de [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)  \n",
    "> Le résultat de [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) peut être différent de ceux obtenus avec [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) car les éléments sont regroupés différemment. La fonction [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) prend une moyenne sur les plis de validation croisée, tandis que [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) renvoie simplement les étiquettes (ou probabilités) de plusieurs modèles distincts non distingués. Ainsi, [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) n'est pas une mesure appropriée de l'erreur de généralisation.\n",
    "\n",
    "**La fonction [`cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict) convient pour :**\n",
    "\n",
    "- La visualisation des prédictions obtenues à partir de différents modèles.\n",
    "- Le mélange de modèles : lorsque les prédictions d'un estimateur supervisé sont utilisées pour entraîner un autre estimateur dans le cadre des méthodes ensemblistes.\n",
    "\n",
    "Les itérateurs de validation croisée disponibles sont présentés dans la section suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemples\n",
    "\n",
    "1. Receiver Operating Characteristic (ROC) avec validation croisée,\n",
    "2. Élimination récursive des caractéristiques avec validation croisée,\n",
    "3. Stratégie de refit personnalisée d'une grille de recherche avec validation croisée,\n",
    "4. Exemple de pipeline pour l'extraction et l'évaluation de caractéristiques de texte,\n",
    "5. Tracer des prédictions validées croisées,\n",
    "6. Validation croisée imbriquée versus non imbriquée."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
