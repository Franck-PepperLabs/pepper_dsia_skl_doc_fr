{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='model-selection-and-evaluation'></a> 3. [**S√©lection et √©valuation de mod√®le**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#model-selection-and-evaluation)</br>([*Model selection and evaluation*](https://scikit-learn.org/stable/model_selection.html#model-selection-and-evaluation))\n",
    "\n",
    "# 3.1. [**Validation crois√©e¬†: √©valuer les performances des estimateurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-evaluating-estimator-performance)<br/>([_Cross-validation: evaluating estimator performance_](https://scikit-learn.org/stable/model_selection.html#cross-validation-evaluating-estimator-performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 25 pages, 7 exemples, 7 papiers\n",
    "- 3.1.1. [**Calcul de m√©triques √† validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#computing-cross-validated-metrics)<br/>([_computing-cross-validated-metrics_](https://scikit-learn.org/stable/model_selection.html#computing-cross-validated-metrics))\n",
    "- 3.1.2. [**It√©rateurs de validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-iterators)<br/>([_Cross validation iterators_](https://scikit-learn.org/stable/model_selection.html#cross-validation-iterators))\n",
    "- 3.1.3. [**Une note sur le brassage**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#a-note-on-shuffling)<br/>([_A note on shuffling_](https://scikit-learn.org/stable/model_selection.html#a-note-on-shuffling))\n",
    "- 3.1.4. [**Validation crois√©e et s√©lection de mod√®les**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#cross-validation-and-model-selection)<br/>([_cross-validation-and-model-selection_](https://scikit-learn.org/stable/model_selection.html#cross-validation-and-model-selection))\n",
    "- 3.1.5. [**R√©sultat du test de permutation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#permutation-test-score)<br/>([_Permutation test score_](https://scikit-learn.org/stable/model_selection.html#permutation-test-score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='computing-cross-validated-metrics'></a> 3.1. Validation crois√©e¬†: √©valuer les performances des estimateurs\n",
    "\n",
    "Apprendre les param√®tres d'une fonction de pr√©diction et la tester sur les m√™mes donn√©es est une erreur m√©thodologique : un mod√®le qui se contenterait de r√©p√©ter les √©tiquettes des √©chantillons qu'il vient de voir aurait un score parfait mais ne parviendrait pas √† pr√©dire quoi que ce soit d'utile sur de nouvelles donn√©es. Cette situation s'appelle le **surajustement**. Pour l'√©viter, il est courant lors de la r√©alisation d'une exp√©rience d'apprentissage automatique (supervis√©e) de conserver une partie des donn√©es disponibles sous forme d'**ensemble de test** `X_test`, `y_test`. Notez que le mot \"exp√©rience\" n'est pas destin√© √† d√©signer uniquement un usage acad√©mique, car m√™me dans les environnements commerciaux, l'apprentissage automatique commence g√©n√©ralement de mani√®re exp√©rimentale. Voici un organigramme du flux de travail typique de validation crois√©e dans l'entra√Ænement de mod√®les. Les meilleurs param√®tres peuvent √™tre d√©termin√©s par des techniques comme la [**recherche en grille** (3.2.1)](https://scikit-learn.org/stable/modules/grid_search.html#grid-search).\n",
    "\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Dans scikit-learn, une r√©partition al√©atoire en ensembles d'apprentissage et de test peut √™tre rapidement calcul√©e avec la fonction utilitaire [**`train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split). Chargeons l'ensemble de donn√©es Iris pour y adapter une machine √† vecteurs de support lin√©aire¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons d√©sormais √©chantillonner rapidement un ensemble d'entra√Ænement tout en conservant 40¬†% des donn√©es pour tester (√©valuer) notre classifieur¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "# ((90, 4), (90,))\n",
    "X_test.shape, y_test.shape\n",
    "# ((60, 4), (60,))\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "# 0.96..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'√©valuation de diff√©rents param√©trages (\"hyperparam√®tres\") pour les estimateurs, tels que le param√®tre `C` qui doit √™tre d√©fini manuellement pour une SVM, il existe toujours un risque de surapprentissage sur l'_ensemble de test_ car les param√®tres peuvent √™tre modifi√©s jusqu'√† ce que l'estimateur fonctionne de mani√®re optimale. De cette fa√ßon, les connaissances sur l'ensemble de test peuvent \"fuir\" dans le mod√®le et les m√©triques d'√©valuation ne plus rendre compte des performances de g√©n√©ralisation. Pour r√©soudre ce probl√®me, une autre partie de l'ensemble de donn√©es peut √™tre isol√©e en tant qu'\"ensemble de validation\": l'entra√Ænement se d√©roule sur l'ensemble d'entra√Ænement, apr√®s quoi l'√©valuation est effectu√©e sur l'ensemble de validation, et quand l'exp√©rience semble √™tre r√©ussie, l'√©valuation finale peut √™tre effectu√©e sur l'ensemble de test.\n",
    "\n",
    "Cependant, en partitionnant les donn√©es disponibles en trois ensembles, nous r√©duisons consid√©rablement le nombre d'√©chantillons qui peuvent √™tre utilis√©s pour entra√Æner le mod√®le, et les r√©sultats peuvent d√©pendre d'un choix al√©atoire particulier pour la paire d'ensembles (entra√Ænement, validation).\n",
    "\n",
    "Une solution √† ce probl√®me est une proc√©dure appel√©e [‚¶ø **validation crois√©e**](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) (CV (_Cross validation_) en abr√©g√©). Un ensemble de test doit toujours √™tre conserv√© pour l'√©valuation finale, mais l'ensemble de validation n'est plus n√©cessaire lors de la r√©alisation de la CV. Dans l'approche de base, appel√©e $k$-fold CV, l'ensemble d'apprentissage est divis√© en $k$ ensembles plus petits (d'autres approches sont d√©crites ci-dessous, mais suivent g√©n√©ralement les m√™mes principes). La proc√©dure suivante est suivie pour chacun des $k$ \"plis\"¬†:\n",
    "\n",
    "- Un mod√®le est entra√Æn√© sur $k - 1$ plis en tant que donn√©es d'apprentissage¬†;\n",
    "- le mod√®le r√©sultant est valid√© sur le pli restant (il est utilis√© comme ensemble de test pour calculer une mesure de performance telle que l'exactitude).\n",
    "\n",
    "La mesure de performance rapport√©e par la validation crois√©e $k$-plis est alors la moyenne des valeurs calcul√©es dans la boucle. Cette approche peut √™tre co√ªteuse en calcul, mais ne gaspille pas trop de donn√©es (comme c'est le cas lors du choix d'un ensemble de validation arbitraire), ce qui est un avantage majeur dans des probl√®mes tels que l'inf√©rence inverse o√π le nombre d'√©chantillons est tr√®s petit.\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='computing-cross-validated-metrics'></a> 3.1.1. Calcul de m√©triques √† validation crois√©e\n",
    "\n",
    "La mani√®re la plus simple d'utiliser la validation crois√©e consiste √† appeler la fonction utilitaire [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) sur l'estimateur et l'ensemble de donn√©es.\n",
    "\n",
    "L'exemple suivant montre comment estimer la pr√©cision d'une machine √† vecteurs de support √† noyau lin√©aire sur l'ensemble de donn√©es iris en divisant les donn√©es, en ajustant un mod√®le et en calculant le score 5 fois cons√©cutives (avec des divisions diff√©rentes √† chaque fois)¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores\n",
    "# array([0.96..., 1. , 0.96..., 0.96..., 1. ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score moyen et l'√©cart type sont alors donn√©s par :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "# 0.98 accuracy with a standard deviation of 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©faut, le score calcul√© √† chaque it√©ration de la CV est donn√© par la m√©thode `score` de l'estimateur. Il est possible de changer cela en utilisant le param√®tre `scoring`` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')\n",
    "scores\n",
    "# array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [**Le param√®tre `scoring` : d√©finir les r√®gles d'√©valuation du mod√®le** (3.3.1)](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) pour plus de d√©tails. Dans le cas de l'ensemble de donn√©es Iris, les √©chantillons sont √©quilibr√©s entre les classes cibles, d'o√π le fait que l'exactitude et le score F1 sont presque √©gaux.\n",
    "\n",
    "Lorsque l'argument `cv` est un entier, [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) utilise par d√©faut les strat√©gies [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) ou [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), cette derni√®re √©tant utilis√©e si l'estimateur d√©rive de [**`ClassifierMixin`**](https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html).\n",
    "\n",
    "Il est √©galement possible d'utiliser d'autres strat√©gies de validation crois√©e en passant un it√©rateur de validation crois√©e √† la place, par exemple¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = X.shape[0]\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, X, y, cv=cv)\n",
    "# array([0.977..., 0.977..., 1.  ..., 0.955..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre option consiste √† utiliser un it√©rable fournissant des s√©parations (entra√Ænement, test) sous forme de tableaux d'indices, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97333333])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_cv_2folds(X):\n",
    "    n = X.shape[0]\n",
    "    for i in range(1, 3):\n",
    "        idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
    "        yield idx, idx\n",
    "\n",
    "custom_cv = custom_cv_2folds(X)\n",
    "cross_val_score(clf, X, y, cv=custom_cv)\n",
    "# array([1.        , 0.973...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation de donn√©es avec des donn√©es conserv√©es**\n",
    "\n",
    "Tout comme il est important de tester un estimateur sur les donn√©es d'entra√Ænement conserv√©es, le pr√©traitement (comme la normalisation, la s√©lection de caract√©ristiques, etc.) et les [**Transformations de donn√©es** (6)](https://scikit-learn.org/stable/data_transforms.html#data-transforms) similaires doivent √©galement √™tre apprises √† partir d'un ensemble d'entra√Ænement puis appliqu√©es aux donn√©es conserv√©es pour la pr√©diction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "clf.score(X_test_transformed, y_test)\n",
    "# 0.9333..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un [**`Pipeline`**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) facilite la composition des estimateurs, offrant ce comportement sous validation crois√©e¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.93333333, 0.95555556, 0.93333333, 0.97777778])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, X, y, cv=cv)\n",
    "# array([0.977..., 0.933..., 0.955..., 0.933..., 0.977...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [**Pipelines et estimateurs composites** (6.1)](https://scikit-learn.org/stable/modules/compose.html#combining-estimators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='the-cross-validate-function-and-multiple-metric-evaluation'></a> 3.1.1.1. La fonction `cross_validate` et l'√©valuation de m√©triques multiples\n",
    "\n",
    "La fonction [**`cross_validate`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) diff√®re de [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) de deux mani√®res¬†:\n",
    "\n",
    "- Elle permet de sp√©cifier plusieurs m√©triques pour l'√©valuation.\n",
    "- Elle renvoie un dictionnaire contenant les temps d'ajustement, les temps d'√©valuation (et √©ventuellement les scores d'entra√Ænement, les estimateurs ajust√©s, les indices de la partition entra√Ænement-test) en plus du score du test.\n",
    "\n",
    "Pour une √©valuation √† m√©trique unique, o√π le param√®tre de score est une cha√Æne, un `callable` ou `None`, les cl√©s seront - `['test_score', 'fit_time', 'score_time']`\n",
    "\n",
    "Et pour l'√©valuation √† m√©triques multiples, la valeur de retour est un dictionnaire avec les cl√©s suivantes - `['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']`\n",
    "\n",
    "La valeur par d√©faut de `return_train_score` est `False` pour √©conomiser du temps de calcul. Pour √©valuer √©galement les scores sur l'ensemble d'entra√Ænement, vous devez le d√©finir sur `True`. Vous pouvez √©galement conserver l'estimateur ajust√© pour chaque ensemble d'entra√Ænement en d√©finissant `return_estimator=True`. De m√™me, vous pouvez d√©finir `return_indices=True` pour conserver les indices d'entra√Ænement et de test utilis√©s pour diviser le jeu de donn√©es en ensembles d'entra√Ænement et de test pour chaque partition CV.\n",
    "\n",
    "Les multiples m√©triques peuvent √™tre sp√©cifi√©es sous forme de liste, de tuple ou d'ensemble de noms d'√©valuateurs pr√©d√©finis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "sorted(scores.keys())\n",
    "# ['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n",
    "scores['test_recall_macro']\n",
    "# array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou sous la forme d'un dictionnaire qui fait correspondre le nom de l'√©valuateur √† une fonction d'√©valuation pr√©d√©finie ou personnalis√©e :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.975     , 0.975     , 0.99166667, 0.98333333, 0.98333333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "scoring = {\n",
    "    'prec_macro': 'precision_macro',\n",
    "    'rec_macro': make_scorer(recall_score, average='macro')\n",
    "}\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5, return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "# ['fit_time', 'score_time', 'test_prec_macro', 'test_rec_macro',\n",
    "#  'train_prec_macro', 'train_rec_macro']\n",
    "scores['train_rec_macro']\n",
    "# array([0.97..., 0.97..., 0.99..., 0.98..., 0.98...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un exemple de `cross_validate` utilisant une m√©trique unique¬†:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimator', 'fit_time', 'score_time', 'test_score']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(clf, X, y,\n",
    "                        scoring='precision_macro', cv=5,\n",
    "                        return_estimator=True)\n",
    "sorted(scores.keys())\n",
    "# ['estimator', 'fit_time', 'score_time', 'test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='obtaining-predictions-by-cross-validation'></a> 3.1.1.2. Obtenir des pr√©dictions par validation crois√©e\n",
    "\n",
    "La fonction [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) a une interface similaire √† [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), mais renvoie, pour chaque √©l√©ment de l'entr√©e, la pr√©diction qui a √©t√© obtenue pour cet √©l√©ment lorsqu'il √©tait dans l'ensemble de test. Seules les strat√©gies de validation crois√©e qui affectent tous les √©l√©ments √† un ensemble de test exactement une fois peuvent √™tre utilis√©es (sinon, une exception est lev√©e).\n",
    "\n",
    "> **Avertissement** : Remarque sur l'utilisation inappropri√©e de [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)  \n",
    "> Le r√©sultat de [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) peut √™tre diff√©rent de ceux obtenus avec [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) car les √©l√©ments sont regroup√©s diff√©remment. La fonction [**`cross_val_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) prend une moyenne sur les plis de validation crois√©e, tandis que [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) renvoie simplement les √©tiquettes (ou probabilit√©s) de plusieurs mod√®les distincts non distingu√©s. Ainsi, [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) n'est pas une mesure appropri√©e de l'erreur de g√©n√©ralisation.\n",
    "\n",
    "**La fonction [`cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict) convient pour :**\n",
    "\n",
    "- La visualisation des pr√©dictions obtenues √† partir de diff√©rents mod√®les.\n",
    "- Le m√©lange de mod√®les : lorsque les pr√©dictions d'un estimateur supervis√© sont utilis√©es pour entra√Æner un autre estimateur dans le cadre des m√©thodes ensemblistes.\n",
    "\n",
    "Les it√©rateurs de validation crois√©e disponibles sont pr√©sent√©s dans la section suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### [**Caract√©ristique de fonctionnement du r√©cepteur (Receiver Operating Characteristic - ROC) avec validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_roc_crossval.ipynb)<br/>([_Receiver Operating Characteristic (ROC) with cross validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html))\n",
    "\n",
    "#### [**√âlimination r√©cursive des caract√©ristiques (RFE) avec validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_13_feature_selection/plot_rfe_with_cross_validation.ipynb)<br/>([_Recursive Feature Elimination (RFE) with cross-validation_](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html))\n",
    "\n",
    "#### [**Strat√©gie personnalis√©e de r√©ajustement d'une recherche en grille avec validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_digits.ipynb)<br/>([_Custom refit strategy of a grid search with cross-validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html))\n",
    "\n",
    "#### [**Exemple de pipeline pour l'extraction et l'√©valuation de caract√©ristiques de texte**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_text_feature_extraction.ipynb)<br/>([_Sample pipeline for text feature extraction and evaluation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_text_feature_extraction.html))\n",
    "\n",
    "#### [**Trac√© de pr√©dictions valid√©es par validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_cv_predict.ipynb)<br/>([_Plotting Cross-Validated Predictions_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_predict.html))\n",
    "\n",
    "#### [**Validation crois√©e imbriqu√©e vs. non-imbriqu√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_nested_cross_validation_iris.ipynb)<br/>([_Nested versus non-nested cross-validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='cross-validation-iterators'></a> 3.1.2. It√©rateurs de validation crois√©e\n",
    "\n",
    "Les sections suivantes r√©pertorient les utilitaires pour g√©n√©rer des indices pouvant √™tre utilis√©s pour diviser un ensemble de donn√©es en diff√©rents sous-ensembles selon diff√©rentes strat√©gies de validation crois√©e.\n",
    "\n",
    "### <a id='cross-validation-iterators-for-i-i-d-data'></a> 3.1.2.1. It√©rateurs de validation crois√©e pour les donn√©es i.i.d.\n",
    "\n",
    "Lorsque l'on suppose que des donn√©es sont ind√©pendantes et identiquement distribu√©es (i.i.d.), on fait l'hypoth√®se que tous les √©chantillons proviennent du m√™me processus de g√©n√©ration et que ce processus de g√©n√©ration ne se souvient pas des √©chantillons g√©n√©r√©s pr√©c√©demment.\n",
    "\n",
    "Les validateurs crois√©s suivants peuvent √™tre utilis√©s dans de tels cas.\n",
    "\n",
    "> **Note** : Bien que les donn√©es i.i.d. soient une hypoth√®se courante en th√©orie de l'apprentissage automatique, elle est rarement v√©rifi√©e en pratique. Si l'on sait que les √©chantillons ont √©t√© g√©n√©r√©s √† l'aide d'un processus d√©pendant du temps, il est pr√©f√©rable d'utiliser un [**sch√©ma de validation crois√©e prenant en compte les s√©ries temporelles** (3.1.2.6)](https://scikit-learn.org/stable/modules/cross_validation.html#timeseries-cv). De m√™me, si l'on sait que le processus de g√©n√©ration pr√©sente une structure de groupe (√©chantillons collect√©s aupr√®s de diff√©rents sujets, exp√©riences, dispositifs de mesure), il est pr√©f√©rable d'utiliser [**la validation crois√©e par groupe** (3.1.2.3)](https://scikit-learn.org/stable/modules/cross_validation.html#group-cv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='k-fold'></a> K-fold\n",
    "\n",
    "[**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) divise tous les √©chantillons en $k$ groupes d'√©chantillons, appel√©s plis (si $k = n$, cela √©quivaut √† la strat√©gie _Leave One Out_), de tailles √©gales (si possible). La fonction de pr√©diction est entra√Æn√©e √† l'aide de $k - 1$ plis, et le pli laiss√© de c√¥t√© est utilis√© pour le test.\n",
    "\n",
    "Exemple de validation crois√©e √† 2 plis sur un ensemble de donn√©es avec 4 √©chantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [2 3] [0 1]\n",
    "# [0 1] [2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une visualisation du comportement de la validation crois√©e. Notez que [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) n'est pas affect√© par les classes ou les groupes.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_006.png)\n",
    "\n",
    "Chaque pli est constitu√© de deux tableaux : le premier est li√© √† l'_ensemble d'entra√Ænement_, et le second √† l'_ensemble de test_. Ainsi, on peut cr√©er les ensembles d'entra√Ænement/test en utilisant l'indexation numpy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='repeated-k-fold'></a> K-fold r√©p√©t√©e\n",
    "\n",
    "[**`RepeatedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html) r√©p√®te [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) $n$ fois. Il peut √™tre utilis√© lorsque l'on souhaite ex√©cuter KFold $n$ fois, en produisant diff√©rentes divisions √† chaque r√©p√©tition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de validation crois√©e √† 2 plis r√©p√©t√©e 2 fois :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n",
      "[0 2] [1 3]\n",
      "[1 3] [0 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "random_state = 12883823\n",
    "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)\n",
    "for train, test in rkf.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [2 3] [0 1]\n",
    "# [0 1] [2 3]\n",
    "# [0 2] [1 3]\n",
    "# [1 3] [0 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De m√™me, [**`RepeatedStratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html) r√©p√®te Stratified K-Fold $n$ fois avec une randomisation diff√©rente √† chaque r√©p√©tition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='leave-one-out-loo'></a> Leave One Out (LOO)\n",
    "\n",
    "[**`LeaveOneOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html) (ou LOO) est une validation crois√©e simple. Chaque ensemble d'apprentissage est cr√©√© en prenant tous les √©chantillons sauf un, l'ensemble de test √©tant l'√©chantillon exclu. Ainsi, pour $n$ √©chantillons, nous avons $n$ ensembles d'apprentissage diff√©rents et $n$ ensembles de test diff√©rents. Cette proc√©dure de validation crois√©e ne gaspille pas beaucoup de donn√©es car un seul √©chantillon est retir√© de l'ensemble d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [0]\n",
      "[0 2 3] [1]\n",
      "[0 1 3] [2]\n",
      "[0 1 2] [3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "X = [1, 2, 3, 4]\n",
    "loo = LeaveOneOut()\n",
    "for train, test in loo.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [1 2 3] [0]\n",
    "# [0 2 3] [1]\n",
    "# [0 1 3] [2]\n",
    "# [0 1 2] [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les utilisateurs potentiels de LOO pour la s√©lection de mod√®les doivent prendre en compte quelques avertissements connus. Par rapport √† la validation crois√©e $k$-fold, on construit $n$ mod√®les √† partir des √©chantillons au lieu de $k$ mod√®les, o√π $n \\gt k$. De plus, chaque mod√®le est entra√Æn√© sur $n - 1$ √©chantillons au lieu de $(k-1) n / k$. Dans les deux cas, en supposant que $k$ n'est pas trop grand et $k \\lt n$, LOO est plus co√ªteux en termes de calcul que la validation crois√©e $k$-fold.\n",
    "\n",
    "En termes de pr√©cision, LOO conduit souvent √† une grande variance en tant qu'estimateur de l'erreur de test. Intuitivement, √©tant donn√© que $n - 1$ des $n$ √©chantillons sont utilis√©s pour construire chaque mod√®le, les mod√®les construits √† partir des plis sont pratiquement identiques les uns aux autres et au mod√®le construit √† partir de l'ensemble d'apprentissage complet.\n",
    "\n",
    "Cependant, si la courbe d'apprentissage est raide pour la taille d'entra√Ænement consid√©r√©e, une validation crois√©e √† 5 ou 10 plis peut surestimer l'erreur de g√©n√©ralisation.\n",
    "\n",
    "En r√®gle g√©n√©rale, la plupart des auteurs et des preuves empiriques sugg√®rent que la validation crois√©e √† 5 ou 10 plis devrait √™tre pr√©f√©r√©e √† LOO.\n",
    "\n",
    "##### R√©f√©rences\n",
    "\n",
    "- http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html\n",
    "- üìö T. Hastie, R. Tibshirani et J. Friedman, [**‚ÄúElements of Statistical Learning Ed. 2‚Äù**](https://hastie.su.domains/Papers/ESLII.pdf), Springer, 2009.\n",
    "- üî¨ L. Breiman, P. Spector [**‚ÄúSubmodel selection and evaluation in regression: The X-random case‚Äù**](https://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf), International Statistical Review 1992.\n",
    "- üî¨ R. Kohavi, [**‚ÄúA Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection‚Äù**](http://ai.stanford.edu/~ronnyk/accEst.pdf), Intl. Jnt. Conf. AI.\n",
    "- üî¨ R. Bharat Rao, G. Fung, R. Rosales, [**‚ÄúOn the Dangers of Cross-Validation. An Experimental Evaluation‚Äù**](https://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf), SIAM 2008.\n",
    "- üìö G. James, D. Witten, T. Hastie, R Tibshirani, [**‚ÄúAn Introduction to Statistical Learning‚Äù**](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf), Springer 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='leave-p-out-lpo'></a> Leave P Out (LPO)\n",
    "\n",
    "[**`LeavePOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html) est tr√®s similaire √† [**`LeaveOneOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html) car il cr√©e tous les ensembles d'entra√Ænement/test possibles en supprimant $p$ √©chantillons de l'ensemble complet. Pour $n$ √©chantillons, cela produit ${n \\choose p}$ paires d'ensembles d'entra√Ænement/test. Contrairement √† [**`LeaveOneOut`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html) et [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), les ensembles de test se chevaucheront pour $p \\gt 1$.\n",
    "\n",
    "Exemple de Leave-2-Out sur un ensemble de donn√©es avec 4 √©chantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[1 3] [0 2]\n",
      "[1 2] [0 3]\n",
      "[0 3] [1 2]\n",
      "[0 2] [1 3]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "X = np.ones(4)\n",
    "lpo = LeavePOut(p=2)\n",
    "for train, test in lpo.split(X):\n",
    "    print(f\"{train} {test}\")\n",
    "# [2 3] [0 1]\n",
    "# [1 3] [0 2]\n",
    "# [1 2] [0 3]\n",
    "# [0 3] [1 2]\n",
    "# [0 2] [1 3]\n",
    "# [0 1] [2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='random-permutations-cross-validation-a-k-a-shuffle-split'></a> Validation crois√©e par permutations al√©atoires, alias Shuffle & Split\n",
    "\n",
    "L'it√©rateur [**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) g√©n√©rera un nombre d√©fini par l'utilisateur de jeux de donn√©es d'entra√Ænement/test ind√©pendants. Les √©chantillons sont d'abord m√©lang√©s, puis divis√©s en une paire d'ensembles d'entra√Ænement et de test.\n",
    "\n",
    "Il est possible de contr√¥ler l'al√©atoire pour assurer la reproductibilit√© des r√©sultats en initialisant explicitement le g√©n√©rateur de nombres pseudo-al√©atoires `random_state`.\n",
    "\n",
    "Voici un exemple d'utilisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 1 6 7 3 0 5] [2 8 4]\n",
      "[2 9 8 0 6 7 4] [3 5 1]\n",
      "[4 5 1 0 6 9 7] [2 3 8]\n",
      "[2 7 5 8 0 3 4] [6 1 9]\n",
      "[4 1 0 6 8 9 3] [5 2 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = np.arange(10)\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(X):\n",
    "    print(f\"{train_index} {test_index}\")\n",
    "# [9 1 6 7 3 0 5] [2 8 4]\n",
    "# [2 9 8 0 6 7 4] [3 5 1]\n",
    "# [4 5 1 0 6 9 7] [2 3 8]\n",
    "# [2 7 5 8 0 3 4] [6 1 9]\n",
    "# [4 1 0 6 8 9 3] [5 2 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une visualisation du comportement de la validation crois√©e. Notez que [**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) n'est pas influenc√© par les classes ou les groupes.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_008.png)\n",
    "\n",
    "[**`ShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html) est donc une bonne alternative √† la validation crois√©e [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) qui permet un contr√¥le plus pr√©cis du nombre d'it√©rations et de la proportion d'√©chantillons de chaque c√¥t√© de la division d'entra√Ænement/test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='cross-validation-iterators-with-stratification-based-on-class-labels'></a> 3.1.2.2. It√©rateurs de validation crois√©e avec stratification bas√©e sur les √©tiquettes de classe\n",
    "\n",
    "Certains probl√®mes de classification peuvent pr√©senter un d√©s√©quilibre important dans la distribution des classes cibles : par exemple, il peut y avoir plusieurs fois plus d'√©chantillons n√©gatifs que d'√©chantillons positifs. Dans de tels cas, il est recommand√© d'utiliser un √©chantillonnage stratifi√© tel qu'impl√©ment√© dans [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) et [**`StratifiedShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) pour garantir que les fr√©quences relatives des classes sont approximativement pr√©serv√©es dans chaque pli d'entra√Ænement et de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='stratified-k-fold'></a> K-fold stratifi√©\n",
    "\n",
    "[**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) est une variation de la validation crois√©e _k-fold_ qui renvoie des plis _stratifi√©s_ : chaque ensemble contient approximativement le m√™me pourcentage d'√©chantillons de chaque classe cible que l'ensemble complet.\n",
    "\n",
    "Voici un exemple de validation crois√©e stratifi√©e √† 3 plis sur un ensemble de donn√©es avec 50 √©chantillons provenant de deux classes d√©s√©quilibr√©es. Nous montrons le nombre d'√©chantillons dans chaque classe et comparons avec [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [30  3]   |   test -  [15  2]\n",
      "train -  [30  3]   |   test -  [15  2]\n",
      "train -  [30  4]   |   test -  [15  1]\n",
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [34]   |   test -  [11  5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n",
    "X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print(f'train -  {np.bincount(y[train])}   |   test -  {np.bincount(y[test])}')\n",
    "# train -  [30  3]   |   test -  [15  2]\n",
    "# train -  [30  3]   |   test -  [15  2]\n",
    "# train -  [30  4]   |   test -  [15  1]\n",
    "kf = KFold(n_splits=3)\n",
    "for train, test in kf.split(X, y):\n",
    "    print(f'train -  {np.bincount(y[train])}   |   test -  {np.bincount(y[test])}')\n",
    "# train -  [28  5]   |   test -  [17]\n",
    "# train -  [28  5]   |   test -  [17]\n",
    "# train -  [34]   |   test -  [11  5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) pr√©serve les ratios de classes (environ 1/10) √† la fois dans l'ensemble d'apprentissage et dans l'ensemble de test.\n",
    "\n",
    "Voici une visualisation du comportement de la validation crois√©e.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_009.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='stratified-shuffle-split'></a> Stratified Shuffle Split\n",
    "\n",
    "[**`StratifiedShuffleSplit`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) est une variation de _ShuffleSplit_ qui renvoie des s√©parations stratifi√©es, c'est-√†-dire qui cr√©e des s√©parations en conservant le m√™me pourcentage pour chaque classe cible que dans l'ensemble complet.\n",
    "\n",
    "Voici une visualisation du comportement de la validation crois√©e.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_012.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='cross-validation-iterators-for-grouped-data'></a> 3.1.2.3. It√©rateurs de validation crois√©e pour les donn√©es regroup√©es\n",
    "\n",
    "L'hypoth√®se i.i.d. est rompue si le processus g√©n√©ratif sous-jacent produit des groupes d'√©chantillons d√©pendants.\n",
    "\n",
    "Un tel regroupement de donn√©es d√©pend du domaine. Par exemple, il peut y avoir des donn√©es m√©dicales collect√©es aupr√®s de plusieurs patients, avec plusieurs √©chantillons pr√©lev√©s sur chaque patient. Et de telles donn√©es sont susceptibles de d√©pendre du groupe individuel. Dans notre exemple, l'identifiant du patient pour chaque √©chantillon sera son identifiant de groupe.\n",
    "\n",
    "Dans ce cas, nous aimerions savoir si un mod√®le entra√Æn√© sur un ensemble particulier de groupes g√©n√©ralise bien aux groupes non vus. Pour mesurer cela, nous devons nous assurer que tous les √©chantillons dans le pli de validation proviennent de groupes qui ne sont pas du tout repr√©sent√©s dans le pli d'apprentissage associ√©.\n",
    "\n",
    "Les diviseurs de validation crois√©e suivants peuvent √™tre utilis√©s pour cela. L'identifiant de regroupement des √©chantillons est sp√©cifi√© via le param√®tre `groups`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='group-k-fold'></a> K-fold par groupe\n",
    "\n",
    "[**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) est une variation de la validation crois√©e _k-fold_ qui garantit que le m√™me groupe n'est pas repr√©sent√© √† la fois dans les ensembles de test et d'apprentissage. Par exemple, si les donn√©es sont obtenues √† partir de sujets diff√©rents avec plusieurs √©chantillons par sujet et si le mod√®le est suffisamment flexible pour apprendre √† partir de caract√©ristiques tr√®s sp√©cifiques √† chaque personne, il pourrait ne pas g√©n√©raliser √† de nouveaux sujets. [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) permet de d√©tecter ce type de situations de surajustement.\n",
    "\n",
    "Imaginez que vous ayez trois sujets, chacun avec un num√©ro associ√© de 1 √† 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5] [6 7 8 9]\n",
      "[0 1 2 6 7 8 9] [3 4 5]\n",
      "[3 4 5 6 7 8 9] [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"d\", \"d\", \"d\"]\n",
    "groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
    "\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "for train, test in gkf.split(X, y, groups=groups):\n",
    "    print(f\"{train} {test}\")\n",
    "# [0 1 2 3 4 5] [6 7 8 9]\n",
    "# [0 1 2 6 7 8 9] [3 4 5]\n",
    "# [3 4 5 6 7 8 9] [0 1 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque sujet se trouve dans un pli de test diff√©rent, et le m√™me sujet n'est jamais √† la fois dans le test et dans l'apprentissage. Notez que les plis n'ont pas exactement la m√™me taille en raison du d√©s√©quilibre dans les donn√©es. Si les proportions de classe doivent √™tre √©quilibr√©es dans les plis, [**`StratifiedGroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html) est une meilleure option.\n",
    "\n",
    "Voici une visualisation du comportement de la validation crois√©e.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_007.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similaire √† [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), les ensembles de test de [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) formeront une partition compl√®te de l'ensemble des donn√©es. Contrairement √† [**`KFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) n'est pas du tout al√©atoire, tandis que KFold est al√©atoire lorsque `shuffle=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='stratifiedgroupkfold'></a> StratifiedGroupKFold\n",
    "\n",
    "[**`StratifiedGroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html) est un sch√©ma de validation crois√©e qui combine √† la fois [**`StratifiedKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) et [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html). L'id√©e est de tenter de pr√©server la distribution des classes dans chaque s√©paration tout en maintenant chaque groupe dans une seule s√©paration. Cela peut √™tre utile lorsque vous disposez d'un ensemble de donn√©es d√©s√©quilibr√©, de sorte que l'utilisation uniquement de [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) pourrait produire des s√©parations biais√©es.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  3  4  5  6  7 10 11 15 16 17] [ 1  8  9 12 13 14]\n",
      "[ 0  1  4  5  6  7  8  9 11 12 13 14] [ 2  3 10 15 16 17]\n",
      "[ 1  2  3  8  9 10 12 13 14 15 16 17] [ 0  4  5  6  7 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "X = list(range(18))\n",
    "y = [1] * 6 + [0] * 12\n",
    "groups = [1, 2, 3, 3, 4, 4, 1, 1, 2, 2, 3, 4, 5, 5, 5, 6, 6, 6]\n",
    "sgkf = StratifiedGroupKFold(n_splits=3)\n",
    "for train, test in sgkf.split(X, y, groups=groups):\n",
    "    print(f\"{train} {test}\")\n",
    "# [ 0  2  3  4  5  6  7 10 11 15 16 17] [ 1  8  9 12 13 14]\n",
    "# [ 0  1  4  5  6  7  8  9 11 12 13 14] [ 2  3 10 15 16 17]\n",
    "# [ 1  2  3  8  9 10 12 13 14 15 16 17] [ 0  4  5  6  7 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes d'impl√©mentation :\n",
    "\n",
    "- Avec l'impl√©mentation actuelle, un m√©lange complet n'est pas possible dans la plupart des sc√©narios. Lorsque `shuffle=True`, les √©tapes suivantes se produisent :\n",
    "    1. Tous les groupes sont m√©lang√©s.\n",
    "    2. Les groupes sont tri√©s par √©cart type des classes en utilisant un tri stable.\n",
    "    3. Les groupes tri√©s sont parcourus et assign√©s aux plis.\n",
    "- Cela signifie que seuls les groupes ayant le m√™me √©cart type de distribution de classes seront m√©lang√©s, ce qui peut √™tre utile lorsque chaque groupe n'a qu'une seule classe.\n",
    "- L'algorithme attribue de mani√®re gloutonne chaque groupe √† un des `n_splits` ensembles de test, en choisissant l'ensemble de test qui minimise la variance de la distribution des classes entre les ensembles de test. L'assignation des groupes se fait des groupes avec la plus grande variance √† la plus faible variance en termes de fr√©quence des classes, c'est-√†-dire que les grands groupes ayant des valeurs concentr√©es sur une ou quelques classes sont assign√©s en premier.\n",
    "- Cette division est sous-optimale dans le sens o√π elle peut produire des s√©parations d√©s√©quilibr√©es m√™me si une stratification parfaite est possible. Si vous avez une r√©partition relativement proche des classes dans chaque groupe, il vaut mieux utiliser [**`GroupKFold`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html).\n",
    "\n",
    "Voici une visualisation du comportement de la validation crois√©e pour des groupes in√©gaux :\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_005.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
