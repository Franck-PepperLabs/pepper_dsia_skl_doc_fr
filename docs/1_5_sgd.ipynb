{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='supervised-learning'></a> 1. [**Apprentissage supervisé**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_supervised_learning.ipynb#supervised-learning)</br>([*Supervised learning*](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning))\n",
    "\n",
    "# <a id='stochastic-gradient-descent'></a> 1.5. [**Descente de gradient stochastique (SGD)**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb)<br/>([_Stochastic Gradient Descent_](https://scikit-learn.org/stable/modules/sgd.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 11 pages, 6 exemples, 7 papiers\n",
    "- 1.5.1. [**Classification**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#classification)<br/>([_Classification_](https://scikit-learn.org/stable/modules/sgd.html#classification))\n",
    "- 1.5.2. [**Régression**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#regression)<br/>([_Regression_](https://scikit-learn.org/stable/modules/sgd.html#regression))\n",
    "- 1.5.3. [**SVM à une classe en ligne**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#online-one-class-svm)<br/>([_Online One-Class SVM_](https://scikit-learn.org/stable/modules/sgd.html#online-one-class-svm))\n",
    "- 1.5.4. [**Descente de gradient stochastique pour données creuses**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#stochastic-gradient-descent-for-sparse-data)<br/>([_Stochastic Gradient Descent for sparse data_](https://scikit-learn.org/stable/modules/sgd.html#stochastic-gradient-descent-for-sparse-data))\n",
    "- 1.5.5. [**Complexité**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#complexity)<br/>([_Complexity_](https://scikit-learn.org/stable/modules/sgd.html#complexity))\n",
    "- 1.5.6. [**Critère d'arrêt**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#stopping-criterion)<br/>([_Stopping criterion_](https://scikit-learn.org/stable/modules/sgd.html#stopping-criterion))\n",
    "- 1.5.7. [**Conseils d'utilisation pratique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#tips-on-practical-use)<br/>([_Tips on Practical Use_](https://scikit-learn.org/stable/modules/sgd.html#tips-on-practical-use))\n",
    "- 1.5.8. [**Formulation mathématique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#mathematical-formulation)<br/>([_Mathematical formulation_](https://scikit-learn.org/stable/modules/sgd.html#mathematical-formulation))\n",
    "- 1.5.9. [**Détails d'implémentation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_5_sgd.ipynb#implementation-details)<br/>([_Implementation details_](https://scikit-learn.org/stable/modules/sgd.html#implementation-details))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='stochastic-gradient-descent'></a> 1.5. **Descente de gradient stochastique (SGD)**<br/>([_Stochastic Gradient Descent_](https://scikit-learn.org/stable/modules/sgd.html))\n",
    "\n",
    "La [**descente de gradient stochastique (SGD)**](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) est une approche simple mais très efficace pour ajuster des classifieurs linéaires et des régresseurs sous des fonctions de perte convexes telles que les [**Machines à vecteurs de support**](https://en.wikipedia.org/wiki/Support_vector_machine) (linéaires) et la [**Régression logistique**](https://en.wikipedia.org/wiki/Logistic_regression). Bien que la SGD existe depuis longtemps dans la communauté de l'apprentissage automatique, elle a récemment reçu une attention considérable dans le contexte de l'apprentissage à grande échelle.\n",
    "\n",
    "La SGD a été appliquée avec succès à des problèmes d'apprentissage automatique de grande taille et à données creuses, souvent rencontrés dans la classification de texte et le traitement du langage naturel. Étant donné que les données sont creuses, les classifieurs de ce module s'adaptent facilement à des problèmes comportant plus de 10^5 exemples d'entraînement et plus de 10^5 caractéristiques.\n",
    "\n",
    "Strictement parlant, la SGD est simplement une technique d'optimisation et ne correspond pas à une famille spécifique de modèles d'apprentissage automatique. Il s'agit simplement d'une manière de former un modèle. Souvent, une instance de [**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) ou [**`SGDRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor) aura un estimateur équivalent dans l'API scikit-learn, utilisant éventuellement une technique d'optimisation différente. Par exemple, l'utilisation de `SGDClassifier(loss='log_loss')` donne lieu à une régression logistique, c'est-à-dire un modèle équivalent à [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) qui est ajusté via SGD au lieu d'être ajusté par l'un des autres solveurs de [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression). De même, `SGDRegressor(loss='squared_error', penalty='l2')` et [**`Ridge`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) résolvent le même problème d'optimisation, par des moyens différents.\n",
    "\n",
    "Les avantages de la descente de gradient stochastique sont :\n",
    "- Efficacité.\n",
    "- Facilité d'implémentation (de nombreuses opportunités pour l'optimisation du code).\n",
    "\n",
    "Les inconvénients de la descente de gradient stochastique comprennent :\n",
    "- La nécessité de définir plusieurs hyperparamètres tels que le paramètre de régularisation et le nombre d'itérations.\n",
    "- La sensibilité de la SGD à la mise à l'échelle des caractéristiques.\n",
    "\n",
    "> **Avertissement :** Assurez-vous de permuter (mélanger) vos données d'entraînement avant d'ajuster le modèle ou utilisez `shuffle=True` pour mélanger après chaque itération (utilisé par défaut). De plus, de préférence, les caractéristiques doivent être standardisées à l'aide de, par exemple, `make_pipeline(StandardScaler(), SGDClassifier())` (voir [**Pipelines** (6.1)](https://scikit-learn.org/stable/modules/compose.html#combining-estimators))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='classification'></a> 1.5.1. **Classification**<br/>([_Classification_](https://scikit-learn.org/stable/modules/sgd.html#classification))\n",
    "\n",
    "La classe [**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) met en œuvre une simple routine d'apprentissage par descente de gradient stochastique qui prend en charge différentes fonctions de perte et pénalités pour la classification. Ci-dessous se trouve la frontière de décision d'un [**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) entraîné avec la perte de charnière, équivalente à une SVM linéaire.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_sgd_separating_hyperplane_001.png\"\n",
    "    alt=\"SGD : Hyperplan de séparation à marge maximale\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Comme d'autres classifieurs, SGD doit être ajusté avec deux tableaux : un tableau `X` de forme `(n_samples, n_features)` contenant les échantillons d'entraînement, et un tableau `y` de forme `(n_samples,)` contenant les valeurs cibles (étiquettes de classe) pour les échantillons d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(max_iter=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(max_iter=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(max_iter=5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "clf.fit(X, y)\n",
    "# SGDClassifier(max_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois ajusté, le modèle peut être utilisé pour prédire de nouvelles valeurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2., 2.]])\n",
    "# array([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD ajuste un modèle linéaire aux données d'entraînement. L'attribut `coef_` contient les paramètres du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.91080278, 9.91080278]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_\n",
    "# array([[9.9..., 9.9...]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'attribut `intercept_` contient l'interception (également appelée _décalage_ ou _biais_) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.99002993])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_\n",
    "# array([-9.9...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que le modèle utilise ou non une interception, c'est-à-dire un hyperplan biaisé, est contrôlé par le paramètre `fit_intercept`.\n",
    "\n",
    "La distance signée à l'hyperplan (calculée comme le produit scalaire entre les coefficients et l'échantillon d'entrée, plus l'interception) est donnée par [**`SGDClassifier.decision_function`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.decision_function) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.65318117])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function([[2., 2.]])\n",
    "# array([29.6...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction de perte concrète peut être définie via le paramètre `loss`. [**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) prend en charge les fonctions de perte suivantes :\n",
    "\n",
    "- `loss=\"hinge\"` : (marge douce) Machine à vecteurs de support linéaire,\n",
    "- `loss=\"modified_huber\"` : perte de charnière lissée,\n",
    "- `loss=\"log_loss\"` : régression logistique,\n",
    "- et toutes les pertes de régression ci-dessous. Dans ce cas, la cible est encodée en tant que -1 ou 1, et le problème est traité comme un problème de régression. La classe prédite correspond alors au signe de la cible prédite.\n",
    "\n",
    "Veuillez vous référer à la [**section mathématique ci-dessous** (1.5.8)](#sgd-mathematical-formulation) pour les formules. Les deux premières fonctions de perte sont \"paresseuses\" ; elles ne mettent à jour les paramètres du modèle que si un exemple viole la contrainte de marge, ce qui rend l'apprentissage très efficace et peut entraîner des modèles plus parcimonieux (c'est-à-dire avec plus de coefficients nuls), même lorsque la pénalité $\\ell_2$ est utilisée.\n",
    "\n",
    "L'utilisation de `loss=\"log_loss\"` ou de `loss=\"modified_huber\"` active la méthode `predict_proba`, qui renvoie un vecteur d'estimations de probabilité $P(y|x)$ par échantillon $x$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00459185, 0.99540815]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss=\"log_loss\", max_iter=5).fit(X, y)\n",
    "clf.predict_proba([[1., 1.]]) \n",
    "# array([[0.00..., 0.99...]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La pénalité concrète peut être définie via le paramètre `penalty`. La SGD prend en charge les pénalités suivantes :\n",
    "- `penalty=\"l2\"` : Pénalité de la norme $\\ell_2$ sur `coef_`.\n",
    "- `penalty=\"l1\"` : Pénalité de la norme $\\ell_1$ sur `coef_`.\n",
    "- `penalty=\"elasticnet\"` : Combinaison convexe de $\\ell_2$ et $\\ell_1$ ; `(1 - l1_ratio) * L2 + l1_ratio * L1`.\n",
    "\n",
    "Le paramètre par défaut est `penalty=\"l2\"`. La pénalité $\\ell_1$ conduit à des solutions parcimonieuses, poussant la plupart des coefficients vers zéro. L'Elastic Net [11] résout certaines lacunes de la pénalité $\\ell_1$ en présence d'attributs fortement corrélés. Le paramètre `l1_ratio` contrôle la combinaison convexe des pénalités $\\ell_1$ et $\\ell_2$.\n",
    "\n",
    "[**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) prend en charge la classification multiclasse en combinant plusieurs classifieurs binaires selon un schéma \"un contre tous\" (OVA). Pour chacune des $K$ classes, un classifieur binaire est entraîné à distinguer cette classe de toutes les autres $K-1$ classes. Au moment du test, nous calculons le score de confiance (c'est-à-dire les distances signées par rapport au plan) pour chaque classifieur et choisissons la classe avec la plus grande confiance. La figure ci-dessous illustre l'approche OVA sur l'ensemble de données iris. Les lignes en pointillés représentent les trois classifieurs OVA ; les couleurs de fond montrent la surface de décision induite par les trois classifieurs.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_sgd_iris_001.png\"\n",
    "    alt=\"Classification SGD multiclasse sur l'ensemble de données iris\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Dans le cas de la classification multiclasse, `coef_` est un tableau bidimensionnel de forme `(n_classes, n_features)` et `intercept_` est un tableau unidimensionnel de forme `(n_classes,)`. La $i$-ème ligne de `coef_` contient le vecteur de poids du classifieur OVA pour la $i$-ème classe ; les classes sont indexées dans l'ordre croissant (voir l'attribut `classes_`). À noter que, en principe, puisqu'elles permettent de créer un modèle de probabilité, `loss=\"log_loss\"` et `loss=\"modified_huber\"` sont plus adaptées à la classification un contre tous.\n",
    "\n",
    "[**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) prend en charge à la fois les classes pondérées et les instances pondérées via les paramètres de réglage `class_weight` et `sample_weight`. Consultez les exemples ci-dessous et la docstring de [**`SGDClassifier.fit`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.fit) pour plus d'informations.\n",
    "\n",
    "[**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) prend en charge la descente de gradient stochastique moyennée (ASGD) [10]. La moyenne peut être activée en définissant `average=True`. ASGD effectue les mêmes mises à jour que la SGD classique (voir [**Formulation mathématique** (1.5.8)](#mathematical-formulation)), mais au lieu d'utiliser la dernière valeur des coefficients comme attribut `coef_` (c'est-à-dire les valeurs de la dernière mise à jour), `coef_` est plutôt défini comme la valeur **moyenne** des coefficients sur l'ensemble des mises à jour. Il en va de même pour l'attribut `intercept_`. Lors de l'utilisation d'ASGD, le taux d'apprentissage peut être plus élevé et même constant, ce qui peut accélérer le temps d'entraînement sur certains ensembles de données.\n",
    "\n",
    "Pour la classification avec une perte logistique, une autre variante de la SGD avec une stratégie de moyenne est disponible avec l'algorithme Stochastic Average Gradient (SAG), disponible en tant que solveur dans [**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### [**SGD : Hyperplan de séparation à marge maximale**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_5_sgd/plot_sgd_separating_hyperplane.ipynb)<br/>([_SGD: Maximum margin separating hyperplane_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_separating_hyperplane.html))\n",
    "\n",
    "#### [**Tracé de la classification multiclasse SGD sur le jeu de données Iris**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_5_sgd/plot_sgd_iris.ipynb)<br/>([_Plot multi-class SGD on the iris dataset_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_iris.html))\n",
    "\n",
    "#### [**SGD : Échantillons pondérés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_5_sgd/plot_sgd_weighted_samples.ipynb)<br/>([_SGD: Weighted samples_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_weighted_samples.html))\n",
    "\n",
    "#### [**Comparaison de divers solveurs en ligne**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_5_sgd/plot_sgd_comparison.ipynb)<br/>([_Comparing various online solvers_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_comparison.html))\n",
    "\n",
    "#### [**SVM : hyperplan séparateur pour les classes déséquilibrées**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_4_svm/plot_separating_hyperplane_unbalanced.ipynb)<br/>([*SVM: Separating hyperplane for unbalanced classes*](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html))\n",
    "\n",
    "(voir la note dans l'exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='regression'></a> 1.5.2. **Régression**<br/>([_Regression_](https://scikit-learn.org/stable/modules/sgd.html#regression))\n",
    "\n",
    "La classe [**`SGDRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor) implémente une procédure d'apprentissage simple de descente de gradient stochastique qui prend en charge différentes fonctions de perte et régularisations pour ajuster des modèles de régression linéaire. [**`SGDRegressor`**](https://scikit-learn.org/stable/modules/sgd.html#regression) est bien adapté à des problèmes de régression avec un grand nombre d'échantillons d'entraînement (> 10 000), pour d'autres problèmes, nous recommandons d'utiliser [**`Ridge`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge), [**`Lasso`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) ou [**`ElasticNet`**](https://scikit-learn.org/stable/modules/sgd.html#regression).\n",
    "\n",
    "La fonction de perte concrète peut être définie via le paramètre `loss`. [**`SGDRegressor`**](https://scikit-learn.org/stable/modules/sgd.html#regression) prend en charge les fonctions de perte suivantes :\n",
    "- `loss=\"squared_error\"` : Moindres carrés ordinaires,\n",
    "- `loss=\"huber\"` : Perte de Huber pour la régression robuste,\n",
    "- `loss=\"epsilon_insensitive\"` : Régression vectorielle de support linéaire.\n",
    "\n",
    "Veuillez vous référer à la [**section mathématique ci-dessous** (1.5.8)](sgd-mathematical-formulation) pour les formules. Les fonctions de perte de Huber et epsilon-insensible peuvent être utilisées pour la régression robuste. La largeur de la région insensible doit être spécifiée via le paramètre `epsilon`. Ce paramètre dépend de l'échelle des variables cibles.\n",
    "\n",
    "Le paramètre `penalty` détermine la régularisation à utiliser (voir la description ci-dessus dans la section classification).\n",
    "\n",
    "[**`SGDRegressor`**](https://scikit-learn.org/stable/modules/sgd.html#regression) prend également en charge la descente de gradient stochastique moyennée [10] (ici encore, voir la description ci-dessus dans la section classification).\n",
    "\n",
    "Pour la régression avec une perte quadratique et une régularisation $\\ell_2$, une autre variante de la descente de gradient stochastique avec une stratégie de moyenne est disponible avec l'algorithme de gradient stochastique moyen (SAG), disponible en tant que solveur dans [**`Ridge`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='online-one-class-svm'></a> 1.5.3. **SVM à une classe en ligne**<br/>([_Online One-Class SVM_](https://scikit-learn.org/stable/modules/sgd.html#online-one-class-svm))\n",
    "\n",
    "La classe [**`sklearn.linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html#sklearn.linear_model.SGDOneClassSVM) implémente une version linéaire en ligne de la One-Class SVM à l'aide de la descente de gradient stochastique. Combinée avec des techniques d'approximation de noyau, [**`sklearn.linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/sgd.html#online-one-class-svm) peut être utilisée pour approximer la solution d'une One-Class SVM à noyau, mise en œuvre dans [**`sklearn.svm.OneClassSVM`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM), avec une complexité linéaire dans le nombre d'échantillons. Notez que la complexité d'une One-Class SVM à noyau est au mieux quadratique dans le nombre d'échantillons. [**`sklearn.linear_model.SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/sgd.html#online-one-class-svm) convient donc bien aux ensembles de données avec un grand nombre d'échantillons d'entraînement (> 10 000), pour lesquels la variante SGD peut être plusieurs ordres de grandeur plus rapide.\n",
    "\n",
    "Comme [**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) et [**`SGDRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor), [**`SGDOneClassSVM`**](https://scikit-learn.org/stable/modules/sgd.html#online-one-class-svm) prend en charge la descente de gradient stochastique moyennée. L'option de moyennage peut être activée en définissant `average=True`.\n",
    "\n",
    "### Détails mathématiques\n",
    "\n",
    "Son implémentation est basée sur l'implémentation de la descente de gradient stochastique. En effet, le problème d'optimisation original de la One-Class SVM est donné par\n",
    "\n",
    "$$\n",
    "\\begin{split}\\begin{aligned}\n",
    "\\min_{w, \\rho, \\xi} & \\quad \\frac{1}{2}\\Vert w \\Vert^2 - \\rho + \\frac{1}{\\nu n} \\sum_{i=1}^n \\xi_i \\\\\n",
    "\\text{s.t.} & \\quad \\langle w, x_i \\rangle \\geq \\rho - \\xi_i \\quad 1 \\leq i \\leq n \\\\\n",
    "& \\quad \\xi_i \\geq 0 \\quad 1 \\leq i \\leq n\n",
    "\\end{aligned}\\end{split}\n",
    "$$\n",
    "\n",
    "où $\\nu \\in (0, 1]$ est le paramètre spécifié par l'utilisateur contrôlant la proportion d'outliers et la proportion de vecteurs de support. En se débarrassant des variables de relâchement $\\xi_i$, ce problème est équivalent à\n",
    "\n",
    "$$\n",
    "\\min_{w, \\rho} \\frac{1}{2}\\Vert w \\Vert^2 - \\rho + \\frac{1}{\\nu n} \\sum_{i=1}^n \\max(0, \\rho - \\langle w, x_i \\rangle) \\, .\n",
    "$$\n",
    "\n",
    "En multipliant par la constante $\\nu$ et en introduisant l'interception $b = 1 - \\rho$, nous obtenons le problème d'optimisation équivalent suivant\n",
    "\n",
    "$$\n",
    "\\min_{w, b} \\frac{\\nu}{2}\\Vert w \\Vert^2 + b\\nu + \\frac{1}{n} \\sum_{i=1}^n \\max(0, 1 - (\\langle w, x_i \\rangle + b)) \\, .\n",
    "$$\n",
    "\n",
    "Cela ressemble aux problèmes d'optimisation étudiés dans la section [**Formulation mathématique** (1.5.8)](#sgd-mathematical-formulation) avec $y_i = 1, 1 \\leq i \\leq n$ et $\\alpha = \\nu/2$, étant la fonction de perte charnière et $R$ étant la norme $\\ell_2$. Nous devons simplement ajouter le terme $b\\nu$ dans la boucle d'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='stochastic-gradient-descent-for-sparse-data'></a> 1.5.4. **Descente de gradient stochastique pour données creuses**<br/>([_Stochastic Gradient Descent for sparse data_](https://scikit-learn.org/stable/modules/sgd.html#stochastic-gradient-descent-for-sparse-data))\n",
    "\n",
    "**Note:** L'implémentation pour données creuses produit des résultats légèrement différents de l'implémentation dense, en raison d'un taux d'apprentissage réduit pour l'interception. Consultez [**Détails de l'implémentation** (1.5.9)](#implementation-details).\n",
    "\n",
    "Il existe une prise en charge intégrée pour les données creuses fournies dans n'importe quelle matrice dans un format pris en charge par [**`scipy.sparse`**](https://docs.scipy.org/doc/scipy/reference/sparse.html). Cependant, pour une efficacité maximale, utilisez le format CSR (Compressed Sparse Row) tel que défini dans [**`scipy.sparse.csr_matrix`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html).\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**Classification de documents textuels à l'aide de caractéristiques creuses**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/text/plot_document_classification_20newsgroups.ipynb)<br/>([_Classification of text documents using sparse features_](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='complexity'></a> 1.5.5. **Complexité**<br/>([_Complexity_](https://scikit-learn.org/stable/modules/sgd.html#complexity))\n",
    "\n",
    "Le principal avantage de la SGD réside dans son efficacité, qui est essentiellement linéaire par rapport au nombre d'exemples d'entraînement. Si `X` est une matrice de taille `(n, p)`, l'entraînement a un coût de $\\mathcal{O}(kn\\bar{p})$, où $k$ est le nombre d'itérations (epochs) et $\\bar p$ est le nombre moyen d'attributs non nuls par échantillon.\n",
    "\n",
    "Cependant, des résultats théoriques récents montrent que le temps nécessaire pour obtenir une précision d'optimisation souhaitée n'augmente pas à mesure que la taille de l'ensemble d'entraînement augmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='stopping-criterion'></a> 1.5.6. **Critère d'arrêt**<br/>([_Stopping criterion_](https://scikit-learn.org/stable/modules/sgd.html#stopping-criterion))\n",
    "\n",
    "Les classes [**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) et [**`SGDRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor) proposent deux critères pour arrêter l'algorithme lorsqu'un certain niveau de convergence est atteint :\n",
    "\n",
    "- Avec `early_stopping=True`, les données d'entrée sont divisées en un ensemble d'entraînement et un ensemble de validation. Le modèle est ensuite ajusté sur l'ensemble d'entraînement, et le critère d'arrêt est basé sur la prédiction de `score` (en utilisant la méthode de score) calculée sur l'ensemble de validation. La taille de l'ensemble de validation peut être modifiée avec le paramètre `validation_fraction`.\n",
    "- Avec `early_stopping=False`, le modèle est ajusté sur l'ensemble des données d'entrée, et le critère d'arrêt est basé sur la fonction objectif calculée sur les données d'entraînement.\n",
    "\n",
    "Dans les deux cas, le critère est évalué une fois par époque, et l'algorithme s'arrête lorsque le critère n'améliore pas `n_iter_no_change` fois d'affilée. L'amélioration est évaluée avec une tolérance absolue `tol`, et l'algorithme s'arrête de toute façon après un nombre maximal d'itérations `max_iter`.\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**Arrêt précoce de la descente de gradient stochastique**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_5_sgd/plot_sgd_early_stopping.ipynb)<br/>([_Early stopping of Stochastic Gradient Descent_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_early_stopping.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='tips-on-practical-use'></a> 1.5.7. **Conseils d'utilisation pratique**<br/>([_Tips on Practical Use_](https://scikit-learn.org/stable/modules/sgd.html#tips-on-practical-use))\n",
    "\n",
    "### Mise à l'échelle des caractéristiques\n",
    "\n",
    "La descente de gradient stochastique est sensible à la mise à l'échelle des caractéristiques, il est donc fortement recommandé de mettre à l'échelle vos données. Par exemple, mettez à l'échelle chaque attribut sur le vecteur d'entrée `X` dans l'intervalle $[0, 1]$ ou $[-1, +1]$, ou standardisez-le pour avoir une moyenne de $0$ et une variance de $1$. Notez que la **même** mise à l'échelle doit être appliquée au vecteur de test pour obtenir des résultats significatifs. Cela peut être facilement fait en utilisant [**`StandardScaler`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) :\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Ne trichez pas - ajustez uniquement sur les données d'entraînement\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)  # appliquer la même transformation aux données de test\n",
    "\n",
    "# Ou mieux encore : utilisez un pipeline !\n",
    "from sklearn.pipeline import make_pipeline\n",
    "est = make_pipeline(StandardScaler(), SGDClassifier())\n",
    "est.fit(X_train)\n",
    "est.predict(X_test)\n",
    "```\n",
    "\n",
    "Si vos attributs ont une échelle intrinsèque (par exemple, les fréquences de mots ou les caractéristiques indicatrices), la mise à l'échelle n'est pas nécessaire.\n",
    "\n",
    "### Régularisation\n",
    "\n",
    "Trouver un terme de régularisation raisonnable $\\alpha$ est mieux fait en utilisant une recherche automatique des hyperparamètres, par exemple [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) ou [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV), généralement dans la plage `10.0**-np.arange(1,7)`.\n",
    "\n",
    "### Nombre d'itérations\n",
    "\n",
    "Empiriquement, nous avons constaté que la SGD converge après avoir observé environ 10^6 exemples d'entraînement. Ainsi, une première estimation raisonnable pour le nombre d'itérations est `max_iter = np.ceil(10**6 / n)`, où `n` est la taille de l'ensemble d'entraînement.\n",
    "\n",
    "### Mise à l'échelle des caractéristiques extraites par PCA\n",
    "\n",
    "Si vous appliquez la SGD à des caractéristiques extraites à l'aide de l'ACP, nous avons constaté qu'il est souvent judicieux de mettre à l'échelle les valeurs des caractéristiques par une constante $c$ de telle sorte que la norme L2 moyenne des données d'entraînement soit égale à un.\n",
    "\n",
    "### Meilleure performance de la SGD moyennée\n",
    "\n",
    "Nous avons constaté que la SGD moyennée fonctionne mieux avec un plus grand nombre de caractéristiques et une valeur de $\\eta_0$ plus élevée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='mathematical-formulation'></a> 1.5.8. **Formulation mathématique**<br/>([_Mathematical formulation_](https://scikit-learn.org/stable/modules/sgd.html#mathematical-formulation))\n",
    "\n",
    "Nous décrivons ici les détails mathématiques de la procédure SGD. Vous pouvez trouver un bon aperçu des taux de convergence dans [12].\n",
    "\n",
    "Étant donné un ensemble d'exemples d'entraînement $(x_1, y_1), \\ldots, (x_n, y_n)$ où $x_i \\in \\mathbf{R}^m$ et $y_i \\in \\mathbf{R}$ ($y_i \\in \\{-1, 1\\}$ pour la classification), notre objectif est d'apprendre une fonction de score linéaire $f(x) = w^T x + b$ avec les paramètres de modèle $w \\in \\mathbf{R}^m$ et l'interception $b \\in \\mathbf{R}$. Pour effectuer des prédictions pour la classification binaire, nous regardons simplement le signe de $f(x)$. Pour trouver les paramètres du modèle, nous minimisons l'erreur d'entraînement régularisée donnée par\n",
    "\n",
    "$$\n",
    "E(w,b) = \\frac{1}{n}\\sum_{i=1}^{n} L(y_i, f(x_i)) + \\alpha R(w)\n",
    "$$\n",
    "\n",
    "où $L$ est une fonction de perte qui mesure l'adéquation du modèle et $R$ est un terme de régularisation (alias _pénalité_) qui pénalise la complexité du modèle ; $\\alpha > 0$ est un hyperparamètre non négatif qui contrôle la force de régularisation.\n",
    "\n",
    "> **Détails des fonctions de perte :** Différents choix pour $L$ entraînent différents classifieurs ou régresseurs :\n",
    "> - Charnière (marge souple) : équivalent à la Classification par Machine à Vecteurs de Support. $L(y_i, f(x_i)) = \\max(0, 1 - y_i f(x_i))$.\n",
    "> - Perceptron : $L(y_i, f(x_i)) = \\max(0, - y_i f(x_i))$.\n",
    "> - Huber modifié : $L(y_i, f(x_i)) = \\max(0, 1 - y_i f(x_i))^2$ si $y_i f(x_i) > 1$, et $L(y_i, f(x_i)) = -4 y_i f(x_i)$ sinon.\n",
    "> - Perte logarithmique : équivalent à la Régression Logistique. $L(y_i, f(x_i)) = \\log(1 + \\exp (-y_i f(x_i)))$.\n",
    "> - Erreur quadratique : Régression linéaire (Ridge ou Lasso en fonction de $R$). $L(y_i, f(x_i)) = \\frac{1}{2}(y_i - f(x_i))^2$.\n",
    "> - Huber : moins sensible aux valeurs aberrantes que les moindres carrés. C'est équivalent aux moindres carrés lorsque $|y_i - f(x_i)| \\leq \\varepsilon$, et $L(y_i, f(x_i)) = \\varepsilon |y_i - f(x_i)| - \\frac{1}{2} \\varepsilon^2$ sinon.\n",
    "> - Epsilon-Insensitive (marge souple) : équivalent à la Régression par Machine à Vecteurs de Support. $L(y_i, f(x_i)) = \\max(0, |y_i - f(x_i)| - \\varepsilon)$.\n",
    "\n",
    "Toutes les fonctions de perte ci-dessus peuvent être considérées comme une borne supérieure sur l'erreur de classification (perte zéro-un), comme le montre la figure ci-dessous.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_sgd_loss_functions_001.png\"\n",
    "    alt=\"Fonctions de perte convexes SGD\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Les choix populaires pour le terme de régularisation $R$ (le paramètre `penalty`) comprennent :\n",
    "- Norme $\\ell_2$ : $R(w) := \\frac{1}{2} \\sum_{j=1}^{m} w_j^2 = ||w||_2^2$,\n",
    "- Norme $\\ell_1$ : $R(w) := \\sum_{j=1}^{m} |w_j|$, ce qui conduit à des solutions clairsemées.\n",
    "- Elastic Net : $R(w) := \\frac{\\rho}{2} \\sum_{j=1}^{n} w_j^2 + (1-\\rho) \\sum_{j=1}^{m} |w_j|$, une combinaison convexe de $\\ell_2$ et $\\ell_1$, où $\\rho$ est donné par `1 - l1_ratio`.\n",
    "\n",
    "La figure ci-dessous (voir l'exemple [**Pénalité SGD**](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_penalties.html)) montre les contours des différents termes de régularisation dans un espace de paramètres à deux dimensions $(m = 2)$ lorsque $R(w) = 1$.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_sgd_penalties_001.png\"\n",
    "    alt=\"Pénalités SGD\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**Pénalités SGD**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_5_sgd/plot_sgd_penalties.ipynb)<br/>([_SGD: Penalties_](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_penalties.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.8.1 **SGD**<br/>([_SGD_](https://scikit-learn.org/stable/modules/sgd.html#id5))\n",
    "\n",
    "La descente de gradient stochastique est une méthode d'optimisation pour les problèmes d'optimisation non contraints. Contrairement à la descente de gradient (par lots), la SGD approxime le vrai gradient de $E(w, b)$ en considérant un seul exemple d'entraînement à la fois.\n",
    "\n",
    "La classe [**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) met en œuvre une routine d'apprentissage de type SGD de premier ordre. L'algorithme itère sur les exemples d'entraînement et, pour chaque exemple, met à jour les paramètres du modèle en fonction de la règle de mise à jour donnée par\n",
    "\n",
    "$$\n",
    "w \\leftarrow w - \\eta \\left[\\alpha \\frac{\\partial R(w)}{\\partial w}\n",
    "+ \\frac{\\partial L(w^T x_i + b, y_i)}{\\partial w}\\right]\n",
    "$$\n",
    "\n",
    "où $\\eta$ est le taux d'apprentissage qui contrôle la taille du pas dans l'espace des paramètres. L'interception $b$ est mise à jour de manière similaire, mais sans régularisation (et avec une décroissance supplémentaire pour les matrices creuses, comme détaillé dans [**Détails de l'implémentation** (1.5.9)](#implementation-details)).\n",
    "\n",
    "Le taux d'apprentissage $\\eta$ peut être soit constant, soit en décroissance progressive. Pour la classification, l'ordonnancement de taux d'apprentissage par défaut (`learning_rate='optimal'`) est donné par\n",
    "\n",
    "$$\n",
    "\\eta^{(t)} = \\frac {1}{\\alpha  (t_0 + t)}\n",
    "$$\n",
    "\n",
    "où $t$ est l'étape de temps (il y a un total de `n_samples * n_iter` étapes de temps), $t_0$ est déterminé sur la base d'une heuristique proposée par Léon Bottou de telle sorte que les mises à jour initiales attendues soient comparables à la taille attendue des poids (en supposant que la norme des échantillons d'entraînement est d'environ 1). La définition exacte peut être trouvée dans `_init_t` dans `BaseSGD`.\n",
    "\n",
    "Pour la régression, l'ordonnancement de taux d'apprentissage par défaut est l'inversion de l'échelle (`learning_rate='invscaling'`), donnée par\n",
    "\n",
    "$$\n",
    "\\eta^{(t)} = \\frac{\\eta_0}{t^{e_t}}\n",
    "$$\n",
    "\n",
    "où $\\eta_0$ et $e_t$ sont des hyperparamètres choisis par l'utilisateur via `eta0` et `power_t`, respectivement.\n",
    "\n",
    "Pour un taux d'apprentissage constant, utilisez `learning_rate='constant'` et utilisez `eta0` pour spécifier le taux d'apprentissage.\n",
    "\n",
    "Pour un taux d'apprentissage décroissant de manière adaptative, utilisez `learning_rate='adaptive'` et utilisez `eta0` pour spécifier le taux d'apprentissage initial. Lorsque le critère d'arrêt est atteint, le taux d'apprentissage est divisé par 5, et l'algorithme ne s'arrête pas. L'algorithme s'arrête lorsque le taux d'apprentissage passe en dessous de 1e-6.\n",
    "\n",
    "Les paramètres du modèle peuvent être accessibles via les attributs `coef_` et `intercept_` : `coef_` contient les poids $w$ et `intercept_` contient $b$.\n",
    "\n",
    "Lors de l'utilisation de la SGD moyennée (avec le paramètre `average`), `coef_` est défini comme la moyenne des poids sur toutes les mises à jour : `coef_`\n",
    "$= \\frac{1}{T} \\sum_{t=0}^{T-1} w^{(t)}$, où $T$ est le nombre total de mises à jour, trouvé dans l'attribut `t_`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='implementation-details'></a> 1.5.9. **Détails d'implémentation**<br/>([_Implementation details_](https://scikit-learn.org/stable/modules/sgd.html#implementation-details))\n",
    "\n",
    "L'implémentation de la SGD est influencée par la « Stochastic Gradient SVM » de [7]. Tout comme SvmSGD, le vecteur de poids est représenté comme le produit d'un scalaire et d'un vecteur, ce qui permet une mise à jour efficace des poids dans le cas de la régularisation $\\ell_2$. Dans le cas d'une entrée creuse `X`, l'interception est mise à jour avec un taux d'apprentissage plus faible (multiplié par 0,01) pour tenir compte du fait qu'elle est mise à jour plus fréquemment. Les exemples d'entraînement sont sélectionnés séquentiellement et le taux d'apprentissage est réduit après chaque exemple observé. Nous avons adopté l'ordonnancement de taux d'apprentissage de [8]. Pour la classification multiclasse, on utilise une approche « un contre tous ». Nous utilisons l'algorithme de gradient tronqué proposé dans [9] pour la régularisation $\\ell_1$ (et l'Elastic Net). Le code est écrit en Cython.\n",
    "\n",
    "### Références\n",
    "\n",
    "🌐 [7] [**“Stochastic Gradient Descent”**](https://leon.bottou.org/projects/sgd) L. Bottou - Website, 2010.\n",
    "\n",
    "🔬 [8] [**“Pegasos: Primal Estimated sub-GrAdient SOlver for SVM”**](https://home.ttic.edu/~nati/Publications/PegasosMPB.pdf) S. Shalev-Shwartz, Y. Singer, N. Srebro - In Proceedings of ICML 2007.\n",
    "\n",
    "🔬 [9] [**“Stochastic Gradient Descent Training for L1-regularized Log-linear Models with Cumulative Penalty”**](https://aclanthology.org/P09-1054.pdf) Y. Tsuruoka, J. Tsujii, S. Ananiadou - In Proceedings of the AFNLP/ACL 2009.\n",
    "\n",
    "🔬 [10] (1,2) [**“Towards Optimal One Pass Large Scale Learning with Averaged Stochastic Gradient Descent”**](https://www.semanticscholar.org/reader/a7e2d53c47bdef073add879557270d915d80a098) Xu, Wei (2011)\n",
    "\n",
    "🔬 [11] [**“Regularization and variable selection via the elastic net”**](http://web.stanford.edu/%7Ehastie/Papers/elasticnet.pdf) H. Zou, T. Hastie - Journal of the Royal Statistical Society Series B, 67 (2), 301-320.\n",
    "\n",
    "🔬 [12] [**“Solving large scale linear prediction problems using stochastic gradient descent algorithms”**](https://dl.acm.org/doi/10.1145/1015330.1015332) T. Zhang - In Proceedings of ICML 2004."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
