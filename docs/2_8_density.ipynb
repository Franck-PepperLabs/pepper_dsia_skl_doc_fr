{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='unsupervised-learning'></a> 2. [**Apprentissage non supervisé**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_unsupervised_learning.ipynb#model-selection-and-evaluation)</br>([*Unsupervised learning*](https://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning))\n",
    "\n",
    "# 2.8. [**Estimation de la densité**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_8_density.ipynb#density-estimation)<br/>([_Density Estimation_](https://scikit-learn.org/stable/density.html#density-estimation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 7 pages, 3 exemples, 0 papiers\n",
    "- 2.8.1. [**Estimation de la densité : histogrammes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_8_density.ipynb#density-estimation-histograms)<br/>([_Density Estimation: Histograms_](https://scikit-learn.org/stable/density.html#density-estimation-histograms))\n",
    "- 2.8.2. [**Estimation de la densité du noyau**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/2_8_density.ipynb#kernel-density-estimation)<br/>([_Kernel Density Estimation_](https://scikit-learn.org/stable/modules/density.html#kernel-density-estimation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='density-estimation'></a> 2.8. Estimation de densité\n",
    "\n",
    "L'estimation de densité se situe entre l'apprentissage non supervisé, l'ingénierie des caractéristiques et la modélisation des données. Certaines des techniques d'estimation de densité les plus populaires et les plus utiles sont les modèles de mélange tels que les mélanges gaussiens ([**`GaussianMixture`**](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)), ainsi que les approches basées sur les voisins telles que l'estimation de densité par noyau ([**`KernelDensity`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html)). Les mélanges gaussiens sont discutés plus en détail dans le contexte du [**regroupement** (2.3)](https://scikit-learn.org/stable/modules/clustering.html#clustering), car cette technique est également utile en tant que schéma de regroupement non supervisé.\n",
    "\n",
    "L'estimation de densité est un concept très simple, et la plupart des gens sont déjà familiers avec une technique d'estimation de densité courante : l'histogramme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='density-estimation-histograms'></a> 2.8.1. Estimation de densité : Histogrammes\n",
    "\n",
    "Un histogramme est une visualisation simple des données où des intervalles sont définis, et le nombre de points de données dans chaque intervalle est comptabilisé. Un exemple d'histogramme peut être vu dans le panneau supérieur gauche de la figure suivante :\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_kde_1d_001.png\"\n",
    "    alt=\"Estimation de densité par noyau - Histogrammes\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Un problème majeur avec les histogrammes, cependant, est que le choix des intervalles peut avoir un effet disproportionné sur la visualisation résultante. Considérez le panneau supérieur droit de la figure ci-dessus. Il montre un histogramme sur les mêmes données, avec les intervalles décalés vers la droite. Les résultats des deux visualisations semblent complètement différents et pourraient conduire à différentes interprétations des données.\n",
    "\n",
    "De manière intuitive, on peut aussi considérer un histogramme comme une pile de blocs, un bloc par point. En empilant les blocs dans l'espace de grille approprié, nous obtenons l'histogramme. Mais que se passe-t-il si, au lieu d'empiler les blocs sur une grille régulière, nous centrons chaque bloc sur le point qu'il représente, et que nous additionnons la hauteur totale à chaque emplacement ? Cette idée conduit à la visualisation du bas à gauche. Ce n'est peut-être pas aussi net qu'un histogramme, mais le fait que les données déterminent les emplacements des blocs signifie que c'est une représentation beaucoup plus fidèle des données sous-jacentes.\n",
    "\n",
    "Cette visualisation est un exemple d'_estimation de densité par noyau_, dans ce cas avec un noyau en forme de chapeau (c'est-à-dire un bloc carré à chaque point). Nous pouvons obtenir une distribution plus lisse en utilisant un noyau plus doux. Le graphique en bas à droite montre une estimation de densité par noyau gaussien, dans laquelle chaque point contribue à une courbe gaussienne totale. Le résultat est une estimation de densité lisse dérivée des données, qui fonctionne comme un puissant modèle non paramétrique de la distribution des points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='kernel-density-estimation'></a> 2.8.2. Estimation de densité par noyau\n",
    "\n",
    "L'estimation de densité par noyaux (Kernel Density Estimation) dans scikit-learn est implémentée dans l'estimateur [**`KernelDensity`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html), qui utilise les structures d'arbre KD ou Ball Tree pour des requêtes efficaces (voir [**Nearest Neighbors** (1.6)](https://scikit-learn.org/stable/modules/neighbors.html#neighbors) pour une discussion sur ces méthodes). Bien que l'exemple ci-dessus utilise un ensemble de données en 1D pour simplifier, l'estimation de densité par noyaux peut être réalisée dans n'importe quel nombre de dimensions, mais dans la pratique, la malédiction de la dimensionnalité peut entraîner une dégradation de ses performances dans les dimensions élevées.\n",
    "\n",
    "Dans la figure suivante, 100 points sont tirés d'une distribution bimodale, et les estimations de densité par noyaux sont montrées pour trois choix de noyaux :\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_kde_1d_003.png\"\n",
    "    alt=\"Distribution KDE en 1D\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Il est évident que la forme du noyau affecte la régularité de la distribution résultante. L'estimateur de densité par noyaux de scikit-learn peut être utilisé de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41075698, -0.41075698, -0.41076071, -0.41075698, -0.41075698,\n",
       "       -0.41076071])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(X)\n",
    "kde.score_samples(X)\n",
    "# array([-0.41075698, -0.41075698, -0.41076071, -0.41075698, -0.41075698,\n",
    "#        -0.41076071])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous avons utilisé `kernel='gaussian'`, comme vu précédemment. Mathématiquement, un noyau est une fonction positive $K(x;h)$ contrôlée par le paramètre de largeur de bande $h$. Avec cette forme de noyau, l'estimation de densité en un point $y$ dans un groupe de points $x_i; i=1\\cdots N$ est donnée par :\n",
    "\n",
    "$$\\rho_K(y) = \\sum_{i=1}^{N} K(y - x_i; h)$$\n",
    "\n",
    "La `bandwidth` agit ici comme un paramètre de lissage, contrôlant le compromis entre le biais et la variance du résultat. Une large valeur de `bandwidth` conduit à une distribution de densité très lisse (c'est-à-dire à un biais élevé). Une petite valeur de `bandwidth` conduit à une distribution de densité moins lisse (c'est-à-dire à une variance élevée).\n",
    "\n",
    "Le paramètre `bandwidth` contrôle ce lissage. Vous pouvez soit fixer manuellement ce paramètre, soit utiliser les méthodes d'estimation de Scott et Silvermann.\n",
    "\n",
    "[**`KernelDensity`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html) implémente plusieurs formes de noyaux courants, qui sont illustrées dans la figure suivante :\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_kde_1d_002.png\"\n",
    "    alt=\"Noyaux d'estimation de densité par noyaux\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Les formes de ces noyaux sont les suivantes :\n",
    "\n",
    "- Noyau gaussien (`kernel='gaussian'`): $K(x; h) \\propto \\exp(- \\frac{x^2}{2h^2} )$\n",
    "- Noyau tophat (`kernel='tophat'`): $K(x; h) \\propto 1 \\text{ si } x < h$\n",
    "- Noyau Epanechnikov (`kernel='epanechnikov'`): $K(x; h) \\propto 1 - \\frac{x^2}{h^2}$\n",
    "- Noyau exponentiel (`kernel='exponential'`): $K(x; h) \\propto \\exp(-x/h)$\n",
    "- Noyau linéaire (`kernel='linear'`): $K(x; h) \\propto 1 - x/h \\text{ si } x < h$\n",
    "- Noyau cosinus (`kernel='cosine'`): $K(x; h) \\propto \\cos(\\frac{\\pi x}{2h}) \\text{ si } x < h$\n",
    "\n",
    "L'estimateur de densité par noyaux peut être utilisé avec n'importe quelle distance valide (voir [**`DistanceMetric`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html) pour une liste des métriques disponibles), mais les résultats sont correctement normalisés uniquement pour la métrique euclidienne. Une métrique particulièrement utile est la [**distance Haversine**](https://en.wikipedia.org/wiki/Haversine_formula) qui mesure la distance angulaire entre des points sur une sphère. Voici un exemple d'utilisation d'une estimation de densité par noyaux pour la visualisation de données géospatiales, dans ce cas la distribution des observations de deux espèces différentes sur le continent sud-américain :\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_species_kde_001.png\"\n",
    "    alt=\"Estimation de densité par noyaux pour les distributions d'espèces\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Une autre application utile de l'estimation de densité par noyaux est d'apprendre un modèle génératif non paramétrique d'un ensemble de données afin de générer efficacement de nouveaux échantillons à partir de ce modèle génératif. Voici un exemple d'utilisation de ce procédé pour créer un nouvel ensemble de chiffres écrits à la main, en utilisant un noyau gaussien appris sur une projection PCA des données :\n",
    "\n",
    "<div style=\"background-color: white; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_digits_kde_sampling_001.png\"\n",
    "    alt=\"Estimation de densité par noyaux pour les chiffres écrits à la main\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Les \"nouvelles\" données consistent en des combinaisons linéaires des données d'entrée, avec des poids tirés de manière probabiliste selon le modèle de l'estimation de densité par noyaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### [**Estimation simple de densité par noyaux en 1D**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_6_neighbors/plot_kde_1d.ipynb)<br/>([_Simple 1D Kernel Density Estimation_](https://scikit-learn.org/stable/auto_examples/neighbors/plot_kde_1d.html))\n",
    "\n",
    "Calcul d'estimations simples de densité par noyaux en une dimension.\n",
    "\n",
    "#### [**Estimation de densité par noyaux**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_6_neighbors/plot_digits_kde_sampling.ipynb)<br/>([_Kernel Density Estimation_](https://scikit-learn.org/stable/auto_examples/neighbors/plot_digits_kde_sampling.html))\n",
    "\n",
    "Exemple d'utilisation de l'estimation de densité par noyaux pour apprendre un modèle génératif des données de chiffres écrits à la main, et générer de nouveaux échantillons à partir de ce modèle.\n",
    "\n",
    "#### [**Estimation de densité par noyaux des distributions d'espèces**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_6_neighbors/plot_species_kde.ipynb)<br/>([_Kernel Density Estimate of Species Distributions_](https://scikit-learn.org/stable/auto_examples/neighbors/plot_species_kde.html))\n",
    "\n",
    "Exemple d'estimation de densité par noyaux utilisant la distance Haversine pour visualiser des données géospatiales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
