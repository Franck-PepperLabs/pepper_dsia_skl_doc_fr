{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='supervised-learning'></a> 1. [**Apprentissage supervisé**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_supervised_learning.ipynb#supervised-learning)</br>([*Supervised learning*](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning))\n",
    "\n",
    "# <a id='multiclass-and-multioutput-algorithms'></a> 1.12. [**Algorithmes multi-classes et multi-sorties**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb)<br/>([_Multiclass and multioutput algorithms_](https://scikit-learn.org/stable/modules/multiclass.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 11 pages, 1 exemples, 5 papiers\n",
    "- 1.12.1. [**Classification multi-classes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#multiclass-classification)<br/>([_Multiclass classification_](https://scikit-learn.org/stable/modules/multiclass.html#multiclass-classification))\n",
    "    - 1.12.1.1. [**Classification multi-classes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#target-format)<br/>([_Target format_](https://scikit-learn.org/stable/modules/multiclass.html#target-format))\n",
    "    - 1.12.1.2. [**`OneVsRestClassifier`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#onevsrestclassifier)<br/>([_`OneVsRestClassifier`_](https://scikit-learn.org/stable/modules/multiclass.html#onevsrestclassifier))\n",
    "    - 1.12.1.3. [**`OneVsOneClassifier`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#onevsoneclassifier)<br/>([_`OneVsOneClassifier`_](https://scikit-learn.org/stable/modules/multiclass.html#onevsoneclassifier))\n",
    "    - 1.12.1.4. [**`OutputCodeClassifier`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#outputcodeclassifier)<br/>([_`OutputCodeClassifier`_](https://scikit-learn.org/stable/modules/multiclass.html#outputcodeclassifier))\n",
    "- 1.12.2. [**Classification multi-étiquettes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#multilabel-classification)<br/>([_Multilabel classification_](https://scikit-learn.org/stable/modules/multiclass.html#multilabel-classification))\n",
    "    - 1.12.2.1. [**Format de la cible**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#target-format)<br/>([_Target format_](https://scikit-learn.org/stable/modules/multiclass.html#target-format))\n",
    "    - 1.12.2.2. [**`MultiOutputClassifier`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#multioutputclassifier)<br/>([_`MultiOutputClassifier`_](https://scikit-learn.org/stable/modules/multiclass.html#multioutputclassifier))\n",
    "    - 1.12.2.3. [**`ClassifierChain`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#classifierchain)<br/>([_`ClassifierChain`_](https://scikit-learn.org/stable/modules/multiclass.html#classifierchain))\n",
    "- 1.12.3. [**Classification multi-classes et multi-sorties**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#multiclass-multioutput-classification)<br/>([_Multiclass-multioutput classification_](https://scikit-learn.org/stable/modules/multiclass.html#multiclass-multioutput-classification))\n",
    "    - 1.12.3.1. [**Format de la cible**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#id8)<br/>([_Target format_](https://scikit-learn.org/stable/modules/multiclass.html#id8))\n",
    "- 1.12.4. [**Régression multi-sorties**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#multioutput-regression)<br/>([_Multioutput regression_](https://scikit-learn.org/stable/modules/multiclass.html#multioutput-regression))\n",
    "    - 1.12.4.1. [**Format de la cible**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#id10)<br/>([_Target format_](https://scikit-learn.org/stable/modules/multiclass.html#id10))\n",
    "    - 1.12.4.2. [**`MultiOutputRegressor`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#multioutputregressor)<br/>([_`MultiOutputRegressor`_](https://scikit-learn.org/stable/modules/multiclass.html#multioutputregressor))\n",
    "    - 1.12.4.3. [**`RegressorChain`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/1_12_multiclass.ipynb#regressorchain)<br/>([_`RegressorChain`_](https://scikit-learn.org/stable/modules/multiclass.html#regressorchain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='multiclass-and-multioutput-algorithms'></a> 1.12. **Algorithmes multi-classes et multi-sorties**<br/>([_Multiclass and multioutput algorithms_](https://scikit-learn.org/stable/modules/multiclass.html))\n",
    "\n",
    "Cette section du guide de l'utilisateur couvre les fonctionnalités liées aux problèmes d'apprentissage multiples, notamment la classification et la régression [**multi-classes**](https://scikit-learn.org/stable/glossary.html#term-multiclass), [**multi-étiquettes**](https://scikit-learn.org/stable/glossary.html#term-multilabel) et [**multi-sorties**](https://scikit-learn.org/stable/glossary.html#term-multioutput).\n",
    "\n",
    "Les modules de cette section mettent en œuvre des [**méta-estimateurs**](https://scikit-learn.org/stable/glossary.html#term-meta-estimators) qui nécessitent qu'un estimateur de base soit fourni dans leur constructeur. Les méta-estimateurs étendent la fonctionnalité de l'estimateur de base pour prendre en charge les problèmes d'apprentissage multiples. Cela est accompli en transformant le problème d'apprentissage multiple en un ensemble de problèmes plus simples, puis en ajustant un estimateur pour chaque problème.\n",
    "\n",
    "Cette section couvre deux modules : [**`sklearn.multiclass`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.multiclass) et [**`sklearn.multioutput`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.multioutput). Le tableau ci-dessous présente les types de problèmes pour lesquels chaque module est responsable, ainsi que les méta-estimateurs correspondants fournis par chaque module.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/multi_org_chart.png\"\n",
    "    alt=\"Modules `sklearn.multiclass` et `sklearn.multioutput`\"\n",
    "    style=\"max-width: 75%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "Le tableau ci-dessous fournit une référence rapide sur les différences entre les types de problèmes. Des explications plus détaillées sont disponibles dans les sections suivantes de ce guide.\n",
    "\n",
    "||Nombre de cibles|Cardinalité de la cible|Type de cible ([**`type_of_target`**](https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target)) valide|\n",
    "|-|-|-|-|\n",
    "|Classification multi-classes|1|>2|`'multiclass'`|\n",
    "|Classification multi-étiquettes|>1|2 (0 ou 1)|`'multilabel-indicator'`|\n",
    "|Classification multi-classes et multi-sorties|>1|>2|`'multiclass-multioutput'`|\n",
    "|Régression multi-sorties|>1|Continue|`'continuous-multioutput'`|\n",
    "\n",
    "Ci-dessous se trouve un résumé des estimateurs de scikit-learn qui prennent en charge l'apprentissage multiple intégré, regroupés par stratégie. Vous n'avez pas besoin des méta-estimateurs fournis par cette section si vous utilisez l'un de ces estimateurs. Cependant, les méta-estimateurs peuvent fournir des stratégies supplémentaires au-delà de ce qui est intégré :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Naturellement multiclasse :**\n",
    "    - [**`naive_bayes.BernoulliNB`**](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB)\n",
    "    - [**`tree.DecisionTreeClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "    - [**`tree.ExtraTreeClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier)\n",
    "    - [**`ensemble.ExtraTreesClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier)\n",
    "    - [**`naive_bayes.GaussianNB`**](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n",
    "    - [**`neighbors.KNeighborsClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "    - [**`semi_supervised.LabelPropagation`**](https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelPropagation.html#sklearn.semi_supervised.LabelPropagation)\n",
    "    - [**`semi_supervised.LabelSpreading`**](https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelSpreading.html#sklearn.semi_supervised.LabelSpreading)\n",
    "    - [**`discriminant_analysis.LinearDiscriminantAnalysis`**](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis)\n",
    "    - [**`svm.LinearSVC`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) (en réglant `multi_class=\"crammer_singer\"`)\n",
    "    - [**`linear_model.LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) (en réglant `multi_class=\"multinomial\"`)\n",
    "    - [**`linear_model.LogisticRegressionCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV) (en réglant `multi_class=\"multinomial\"`)\n",
    "    - [**`neural_network.MLPClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "    - [**`neighbors.NearestCentroid`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html#sklearn.neighbors.NearestCentroid)\n",
    "    - [**`discriminant_analysis.QuadraticDiscriminantAnalysis`**](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)\n",
    "    - [**`neighbors.RadiusNeighborsClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html#sklearn.neighbors.RadiusNeighborsClassifier)\n",
    "    - [**`ensemble.RandomForestClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "    - [**`linear_model.RidgeClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier)\n",
    "    - [**`linear_model.RidgeClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html#sklearn.linear_model.RidgeClassifierCV)\n",
    "- **Multiclasse Un-contre-Un (OVO) :**\n",
    "    - [**`svm.NuSVC`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC)\n",
    "    - [**`svm.SVC`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "    - [**`gaussian_process.GaussianProcessClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier) (en réglant `multi_class=\"one_vs_one\"`)\n",
    "- **Multiclass Un-contre-Tous (OVR) :**\n",
    "    - [**`ensemble.GradientBoostingClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier)\n",
    "    - [**`gaussian_process.GaussianProcessClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier) (en réglant `multi_class=\"one_vs_rest\"`)\n",
    "    - [**`svm.LinearSVC`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) (en réglant `multi_class=\"ovr\"`)\n",
    "    - [**`linear_model.LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) (en réglant `multi_class=\"ovr\"`)\n",
    "    - [**`linear_model.LogisticRegressionCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV) (en réglant `multi_class=\"ovr\"`)\n",
    "    - [**`linear_model.SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n",
    "    - [**`linear_model.Perceptron`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron)\n",
    "    - [**`linear_model.PassiveAggressiveClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html#sklearn.linear_model.PassiveAggressiveClassifier)\n",
    "- **Prise en charge de la classification multi-étiquettes :**\n",
    "    - [**`tree.DecisionTreeClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "    - [**`tree.ExtraTreeClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier)\n",
    "    - [**`ensemble.ExtraTreesClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier)\n",
    "    - [**`neighbors.KNeighborsClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "    - [**`neural_network.MLPClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "    - [**`neighbors.RadiusNeighborsClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html#sklearn.neighbors.RadiusNeighborsClassifier)\n",
    "    - [**`ensemble.RandomForestClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "    - [**`linear_model.RidgeClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier)\n",
    "    - [**`linear_model.RidgeClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html#sklearn.linear_model.RidgeClassifierCV)\n",
    "- **Prise en charge de la classification multi-classes et multi-sorties :**\n",
    "    - [**`tree.DecisionTreeClassifier`**](https://scikit-learn.org/stable/modules.generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "    - [**`tree.ExtraTreeClassifier`**](https://scikit-learn.org/stable/modules.generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier)\n",
    "    - [**`ensemble.ExtraTreesClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier)\n",
    "    - [**`neighbors.KNeighborsClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "    - [**`neighbors.RadiusNeighborsClassifier`**](https://scikit-learn.org/stable/modules.generated/sklearn.neighbors.RadiusNeighborsClassifier.html#sklearn.neighbors.RadiusNeighborsClassifier)\n",
    "    - [**`ensemble.RandomForestClassifier`**](https://scikit-learn.org/stable/modules.generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='multiclass-classification'></a> 1.12.1. **Classification multi-classes**<br/>([_Multiclass classification_](https://scikit-learn.org/stable/modules/multiclass.html#multiclass-classification))\n",
    "\n",
    "> **Attention :** Tous les classifieurs de scikit-learn effectuent la classification multi-classes par défaut. Vous n'avez pas besoin d'utiliser le module [**`sklearn.multiclass`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.multiclass) à moins que vous ne souhaitiez expérimenter avec différentes stratégies de classification multi-classes.\n",
    "\n",
    "La **classification multi-classes** est une tâche de classification avec plus de deux classes. Chaque échantillon ne peut être étiqueté que comme une seule classe.\n",
    "\n",
    "Par exemple, la classification à l'aide de caractéristiques extraites à partir d'un ensemble d'images de fruits, où chaque image peut être soit une orange, une pomme ou une poire. Chaque image est un échantillon et est étiquetée comme l'une des 3 classes possibles. La classification multi-classes suppose que chaque échantillon est attribué à une seule étiquette - un échantillon ne peut pas, par exemple, être à la fois une poire et une pomme.\n",
    "\n",
    "Bien que tous les classifieurs de scikit-learn soient capables de la classification multi-classes, les méta-estimateurs offerts par [**`sklearn.multiclass`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.multiclass) permettent de modifier la manière dont ils gèrent plus de deux classes, car cela peut avoir un effet sur les performances du classifieur (que ce soit en termes d'erreur de généralisation ou de ressources informatiques requises)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='target-format'></a> 1.12.1.1. **Classification multi-classes**<br/>([_Target format_](https://scikit-learn.org/stable/modules/multiclass.html#target-format))\n",
    "\n",
    "Les représentations [**multi-classes**](https://scikit-learn.org/stable/glossary.html#term-multiclass) pour [**`type_of_target`**](https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target) valides (`y`) sont les suivantes :\n",
    "\n",
    "- Vecteur 1D ou vecteur colonne contenant plus de deux valeurs discrètes. Un exemple de vecteur `y` pour 4 échantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple' 'pear' 'apple' 'orange']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.array(['apple', 'pear', 'apple', 'orange'])\n",
    "print(y)\n",
    "# ['apple' 'pear' 'apple' 'orange']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matrice [**binaire**](https://scikit-learn.org/stable/glossary.html#term-binary) dense ou creuse de forme `(n_samples, n_classes)` avec un seul échantillon par ligne, où chaque colonne représente une classe. Un exemple de matrice [**binaire**](https://scikit-learn.org/stable/glossary.html#term-binary), à la fois dense et creuse, `y` pour 4 échantillons, où les colonnes, dans l'ordre, sont pomme, orange et poire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "  (0, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 0)\t1\n",
      "  (3, 1)\t1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "y = np.array(['apple', 'pear', 'apple', 'orange'])\n",
    "y_dense = LabelBinarizer().fit_transform(y)\n",
    "print(y_dense)\n",
    "#   [[1 0 0]\n",
    "#    [0 0 1]\n",
    "#    [1 0 0]\n",
    "#    [0 1 0]]\n",
    "from scipy import sparse\n",
    "y_sparse = sparse.csr_matrix(y_dense)\n",
    "print(y_sparse)\n",
    "#     (0, 0)        1\n",
    "#     (1, 2)        1\n",
    "#     (2, 0)        1\n",
    "#     (3, 1)        1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour plus d'informations sur [**`LabelBinarizer`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer), consultez la section [**Transformation de la cible de prédiction (y)** (6.9)](https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='onevsrestclassifier'></a> 1.12.1.2. **`OneVsRestClassifier`**<br/>([_`OneVsRestClassifier`_](https://scikit-learn.org/stable/modules/multiclass.html#onevsrestclassifier))\n",
    "\n",
    "La stratégie **un-contre-tous**, également connue sous le nom de **un-contre-tous**, est implémentée dans la classe [**`OneVsRestClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier). Cette stratégie consiste à ajuster un classifieur pour chaque classe. Pour chaque classifieur, la classe est ajustée par rapport à toutes les autres classes. En plus de son efficacité computationnelle (seuls `n_classes` classifieurs sont nécessaires), un avantage de cette approche est son interprétabilité. Étant donné que chaque classe est représentée par un unique classifieur, il est possible d'acquérir des connaissances sur la classe en inspectant son classifieur correspondant. Il s'agit de la stratégie la plus couramment utilisée et constitue un choix par défaut judicieux.\n",
    "\n",
    "Voici un exemple d'apprentissage multi-classes à l'aide de la stratégie un-contre-tous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "OneVsRestClassifier(LinearSVC(dual=\"auto\", random_state=0)).fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`OneVsRestClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier) prend également en charge la classification multi-étiquettes. Pour utiliser cette fonctionnalité, fournissez au classifieur une matrice d'indicateurs, dans laquelle la cellule `[i, j]` indique la présence de l'étiquette `j` dans l'échantillon `i`.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_multilabel_001.png\"\n",
    "    alt=\"Classification multi-étiquettes\"\n",
    "    style=\"max-width: 50%; height: auto;\"/>\n",
    "</div>\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "##### [**Classification multi-étiquettes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/1_11_ensembles/plot_multilabel.ipynb)<br/>([_Multilabel classification_](https://scikit-learn.org/stable/auto_examples/ensemble/plot_multilabel.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='onevsoneclassifier'></a> 1.12.1.3. **`OneVsOneClassifier`**<br/>([_`OneVsOneClassifier`_](https://scikit-learn.org/stable/modules/multiclass.html#onevsoneclassifier))\n",
    "\n",
    "[**`OneVsOneClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier) construit un classifieur pour chaque paire de classes. Au moment de la prédiction, la classe qui reçoit le plus de votes est sélectionnée. En cas d'égalité (entre deux classes ayant un nombre égal de votes), elle sélectionne la classe avec le niveau de confiance de classification global le plus élevé en additionnant les niveaux de confiance de classification par paire calculés par les classifieurs binaires sous-jacents.\n",
    "\n",
    "Étant donné qu'il faut ajuster `n_classes * (n_classes - 1) / 2` classifieurs, cette méthode est généralement plus lente que celle du un contre tous (one-vs-the-rest), en raison de sa complexité $\\mathcal{O}(n_{\\text{classes}}^2)$. Cependant, cette méthode peut être avantageuse pour des algorithmes tels que les algorithmes à noyau qui ne sont pas extensibles avec `n_samples`. Cela est dû au fait que chaque problème d'apprentissage individuel n'implique qu'un petit sous-ensemble des données, tandis qu'avec un contre tous, l'ensemble complet des données est utilisé `n_classes` fois. La fonction de décision est le résultat d'une transformation monotone de la classification un contre un.\n",
    "\n",
    "Ci-dessous se trouve un exemple d'apprentissage multi-classes en utilisant OvO :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "OneVsOneClassifier(LinearSVC(dual=\"auto\", random_state=0)).fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Références\n",
    "\n",
    "📚 [**“Pattern recognition and machine learning”**](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf), Christopher M. Bishop, page 183, (First Edition)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='outputcodeclassifier'></a> 1.12.1.4. **`OutputCodeClassifier`**<br/>([_`OutputCodeClassifier`_](https://scikit-learn.org/stable/modules/multiclass.html#outputcodeclassifier))\n",
    "\n",
    "Les stratégies basées sur les codes de sortie de correction d'erreur sont assez différentes de celles du un contre tous et du un contre un. Avec ces stratégies, chaque classe est représentée dans un espace euclidien, où chaque dimension ne peut être que 0 ou 1. Autrement dit, chaque classe est représentée par un code binaire (un tableau de 0 et de 1). La matrice qui garde la trace de l'emplacement/du code de chaque classe est appelée le livre de codes. La taille du code est la dimensionnalité de l'espace mentionné ci-dessus. Intuitivement, chaque classe devrait être représentée par un code aussi unique que possible, et un bon livre de codes devrait être conçu pour optimiser la précision de la classification. Dans cette implémentation, nous utilisons simplement un livre de codes généré de manière aléatoire, comme préconisé dans [3], bien que des méthodes plus élaborées puissent être ajoutées à l'avenir.\n",
    "\n",
    "Au moment de l'apprentissage, un classifieur binaire est ajusté pour chaque bit dans le livre de codes. Au moment de la prédiction, les classifieurs sont utilisés pour projeter de nouveaux points dans l'espace des classes, et la classe la plus proche des points est choisie.\n",
    "\n",
    "Dans [**`OutputCodeClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OutputCodeClassifier.html#sklearn.multiclass.OutputCodeClassifier), l'attribut `code_size` permet à l'utilisateur de contrôler le nombre de classifieurs qui seront utilisés. Il s'agit d'un pourcentage du nombre total de classes.\n",
    "\n",
    "Un nombre compris entre 0 et 1 nécessitera moins de classifieurs que le un contre tous. En théorie, `log2(n_classes) / n_classes` est suffisant pour représenter chaque classe de manière non ambiguë. Cependant, en pratique, cela peut ne pas conduire à une bonne précision car `log2(n_classes)` est beaucoup plus petit que `n_classes`.\n",
    "\n",
    "Un nombre supérieur à 1 nécessitera plus de classifieurs que le un contre tous. Dans ce cas, certains classifieurs corrigeront en théorie les erreurs commises par d'autres classifieurs, d'où le nom de « correction d'erreur ». En pratique, cependant, cela peut ne pas se produire car les erreurs des classifieurs seront généralement corrélées. Les codes de sortie de correction d'erreur ont un effet similaire au bagging.\n",
    "\n",
    "Ci-dessous se trouve un exemple d'apprentissage multi-classes en utilisant les codes de sortie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "clf = OutputCodeClassifier(\n",
    "    LinearSVC(dual=\"auto\", random_state=0),\n",
    "    code_size=2, random_state=0\n",
    ")\n",
    "clf.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Références\n",
    "\n",
    "🔬 [**“Solving multiclass learning problems via error-correcting output codes”**](https://arxiv.org/pdf/cs/9501101.pdf), Dietterich T., Bakiri G., Journal of Artificial Intelligence Research 2, 1995.\n",
    "\n",
    "🔬 [3] [**“The error coding method and PICTs”**](http://www-rcf.usc.edu/~gareth/research/picts.pdf), James G., Hastie T., Journal of Computational and Graphical statistics 7, 1998.\n",
    "\n",
    "📚 [**“Elements of Statistical Learning Ed. 2”**](https://hastie.su.domains/Papers/ESLII.pdf), Hastie T., Tibshirani R., Friedman J., page 606 (second-edition) 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='multilabel-classification'></a> 1.12.2. **Classification multi-étiquettes**<br/>([_Multilabel classification_](https://scikit-learn.org/stable/modules/multiclass.html#multilabel-classification))\n",
    "\n",
    "**La classification multi-étiquettes** (étroitement liée à la **classification multi-sorties**) est une tâche de classification étiquetant chaque échantillon avec `m` étiquettes parmi `n_classes` classes possibles, où `m` peut être de 0 à `n_classes` inclus. On peut considérer qu'il s'agit de prédire des propriétés d'un échantillon qui ne sont pas mutuellement exclusives. Formellement, une sortie binaire est attribuée à chaque classe, pour chaque échantillon. Les classes positives sont indiquées par 1 et les classes négatives par 0 ou -1. Il est donc comparable à l'exécution de tâches de classification binaire pour `n_classes`, par exemple avec [**`MultiOutputClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html#sklearn.multioutput.MultiOutputClassifier). Cette approche traite chaque étiquette de manière indépendante, tandis que les classifieurs multi-étiquettes peuvent traiter les classes multiples simultanément, en tenant compte des comportements corrélés entre elles.\n",
    "\n",
    "Par exemple, la prédiction des sujets pertinents pour un document texte ou une vidéo. Le document ou la vidéo peut concerner l'un des thèmes suivants : \"religion\", \"politique\", \"finance\" ou \"éducation\", plusieurs des classes de sujets ou l'ensemble des classes de sujets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='target-format'></a> 1.12.2.1. **Format de la cible**<br/>([_Target format_](https://scikit-learn.org/stable/modules/multiclass.html#target-format))\n",
    "\n",
    "Une représentation [**multi-étiquettes**](https://scikit-learn.org/stable/glossary.html#term-multilabel) valide `y` est une matrice [**binaire**](https://scikit-learn.org/stable/glossary.html#term-binary) dense ou creuse de forme `(n_samples, n_classes)`. Chaque colonne représente une classe. Les `1` dans chaque ligne indiquent les classes positives auxquelles un échantillon a été étiqueté. Voici un exemple d'une matrice dense `y` pour 3 échantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1]\n",
      " [0 0 1 1]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[1, 0, 0, 1], [0, 0, 1, 1], [0, 0, 0, 0]])\n",
    "print(y)\n",
    "# [[1 0 0 1]\n",
    "#  [0 0 1 1]\n",
    "#  [0 0 0 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des matrices binaires denses peuvent également être créées à l'aide de [**`MultiLabelBinarizer`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer). Pour plus d'informations, reportez-vous à la section [**Transformation de la cible de prédiction (y)** (6.9)](https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets).\n",
    "\n",
    "Un exemple du même `y` sous forme de matrice creuse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n"
     ]
    }
   ],
   "source": [
    "y_sparse = sparse.csr_matrix(y)\n",
    "print(y_sparse)\n",
    "#   (0, 0)      1\n",
    "#   (0, 3)      1\n",
    "#   (1, 2)      1\n",
    "#   (1, 3)      1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='multioutputclassifier'></a> 1.12.2.2. **`MultiOutputClassifier`**<br/>([_`MultiOutputClassifier`_](https://scikit-learn.org/stable/modules/multiclass.html#multioutputclassifier))\n",
    "\n",
    "Le support de la classification multi-étiquettes peut être ajouté à n'importe quel classifieur à l'aide de [**`MultiOutputClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html#sklearn.multioutput.MultiOutputClassifier). Cette stratégie consiste à ajuster un classifieur par cible. Cela permet des classifications avec plusieurs variables cibles. Le but de cette classe est d'étendre les estimateurs pour être capables d'estimer une série de fonctions cibles `(f1, f2, f3, …, fn)` qui sont entraînées sur une unique matrice prédictrice `X` pour prédire une série de réponses `(y1, y2, y3, …, yn)`.\n",
    "\n",
    "Vous pouvez trouver un exemple d'utilisation de [**`MultiOutputClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html#sklearn.multioutput.MultiOutputClassifier) dans la section sur la [**classification multi-sorties** (1.12.3)](#classification-multi-sorties) car il s'agit d'une généralisation de la classification multi-étiquettes aux sorties multi-classes au lieu de sorties binaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='classifierchain'></a> 1.12.2.3. **`ClassifierChain`**<br/>([_`ClassifierChain`_](https://scikit-learn.org/stable/modules/multiclass.html#classifierchain))\n",
    "\n",
    "Les chaînes de classifieurs (voir [**`ClassifierChain`**](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html#sklearn.multioutput.ClassifierChain)) sont une manière de combiner plusieurs classifieurs binaires en un modèle multi-étiquettes unique capable d'exploiter les corrélations entre les cibles.\n",
    "\n",
    "Pour un problème de classification multi-étiquettes avec $N$ classes, $N$ classifieurs binaires se voient attribuer un entier entre $0$ et $N-1$. Ces entiers définissent l'ordre des modèles dans la chaîne. Ensuite, chaque classifieur est ajusté sur les données d'entraînement disponibles ainsi que sur les vraies étiquettes des classes auxquelles les modèles se sont vu attribuer un nombre plus bas.\n",
    "\n",
    "Lors de la prédiction, les vraies étiquettes ne seront pas disponibles. Au lieu de cela, les prédictions de chaque modèle sont transmises aux modèles suivants dans la chaîne pour être utilisées comme caractéristiques.\n",
    "\n",
    "Il est clair que l'ordre de la chaîne est important. Le premier modèle de la chaîne n'a aucune information sur les autres étiquettes, tandis que le dernier modèle de la chaîne dispose de caractéristiques indiquant la présence de toutes les autres étiquettes. En général, on ne connaît pas l'ordre optimal des modèles dans la chaîne, c'est pourquoi on ajuste généralement de nombreuses chaînes ordonnées de manière aléatoire et on moyenne leurs prédictions.\n",
    "\n",
    "#### Références\n",
    "\n",
    "🔬 Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank, [**“Classifier Chains for Multi-label Classification”**](https://link.springer.com/content/pdf/10.1007/978-3-642-04174-7_17.pdf), 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='multiclass-multioutput-classification'></a> 1.12.3. **Classification multi-classes et multi-sorties**<br/>([_Multiclass-multioutput classification_](https://scikit-learn.org/stable/modules/multiclass.html#multiclass-multioutput-classification))\n",
    "\n",
    "La **classification multi-classes et multi-sorties** (également appelée **classification multi-tâches**) est une tâche de classification qui attribue à chaque échantillon un ensemble de propriétés non binaires. Le nombre de propriétés et le nombre de classes par propriété sont tous deux supérieurs à 2. Un seul estimateur gère ainsi plusieurs tâches de classification conjointes. Il s'agit à la fois d'une généralisation de la tâche de classification multi-étiquettes, qui ne considère que des attributs binaires, ainsi que d'une généralisation de la tâche de classification multi-classes, où seule une propriété est considérée.\n",
    "\n",
    "Par exemple, la classification des propriétés \"type de fruit\" et \"couleur\" pour un ensemble d'images de fruits. La propriété \"type de fruit\" a les classes possibles : \"pomme\", \"poire\" et \"orange\". La propriété \"couleur\" a les classes possibles : \"vert\", \"rouge\", \"jaune\" et \"orange\". Chaque échantillon est une image d'un fruit, une étiquette est attribuée pour les deux propriétés et chaque étiquette est l'une des classes possibles de la propriété correspondante.\n",
    "\n",
    "Notez que tous les classifieurs gérant des tâches de classification multi-classes et multi-sorties (également appelées classification multi-tâches) prennent en charge la tâche de classification multi-étiquettes en tant que cas particulier. La classification multi-tâches est similaire à la classification multi-sorties avec différentes formulations de modèles. Pour plus d'informations, consultez la documentation de l'estimateur correspondant.\n",
    "\n",
    "Voici un exemple de classification multi-classes et multi-sorties :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 0],\n",
       "       [1, 2, 1],\n",
       "       [2, 1, 0],\n",
       "       [0, 0, 2],\n",
       "       [0, 2, 1],\n",
       "       [0, 0, 2],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 2],\n",
       "       [2, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "X, y1 = make_classification(\n",
    "    n_samples=10, n_features=100,\n",
    "    n_informative=30, n_classes=3,\n",
    "    random_state=1\n",
    ")\n",
    "y2 = shuffle(y1, random_state=1)\n",
    "y3 = shuffle(y1, random_state=2)\n",
    "Y = np.vstack((y1, y2, y3)).T\n",
    "n_samples, n_features = X.shape # 10,100\n",
    "n_outputs = Y.shape[1] # 3\n",
    "n_classes = 3\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "multi_target_forest = MultiOutputClassifier(forest, n_jobs=2)\n",
    "multi_target_forest.fit(X, Y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Attention :** À l'heure actuelle, aucune métrique dans sklearn.metrics ne prend en charge la tâche de classification multi-classes et multi-sorties.\n",
    "\n",
    "### <a id='id8'></a> 1.12.3.1. **Format de la cible**<br/>([_Format de la cible_](https://scikit-learn.org/stable/modules/multiclass.html#id8))\n",
    "\n",
    "Une représentation valide de [**multi-sorties**](https://scikit-learn.org/stable/glossary.html#term-multioutput) `y` est une matrice dense de forme `(n_samples, n_classes)` contenant des étiquettes de classe. Une concaténation colonne par colonne de variables [**multi-classes**](https://scikit-learn.org/stable/glossary.html#term-multiclass) 1D. Voici un exemple de `y` pour 3 échantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple' 'green']\n",
      " ['orange' 'orange']\n",
      " ['pear' 'green']]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([['apple', 'green'], ['orange', 'orange'], ['pear', 'green']])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='multioutput-regression'></a> 1.12.4. **Régression multi-sorties**<br/>([_Multioutput regression_](https://scikit-learn.org/stable/modules/multiclass.html#multioutput-regression))\n",
    "\n",
    "**Multioutput regression** predicts multiple numerical properties for each sample. Each property is a numerical variable and the number of properties to be predicted for each sample is greater than or equal to 2. Some estimators that support multioutput regression are faster than just running `n_output` estimators.\n",
    "\n",
    "For example, prediction of both wind speed and wind direction, in degrees, using data obtained at a certain location. Each sample would be data obtained at one location and both wind speed and direction would be output for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='id10'></a> 1.12.4.1. **Format de la cible**<br/>([_Format de la cible_](https://scikit-learn.org/stable/modules/multiclass.html#id10))\n",
    "\n",
    "Une représentation [**multi-sorties**](https://scikit-learn.org/stable/glossary.html#term-multioutput) valide `y` est une matrice dense de forme `(n_samples, n_output)` de nombres décimaux, une concaténation colonne par colonne de variables [**continues**](https://scikit-learn.org/stable/glossary.html#term-continuous). Voici un exemple de `y` pour 3 échantillons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 31.4  94. ]\n",
      " [ 40.5 109. ]\n",
      " [ 25.   30. ]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[31.4, 94], [40.5, 109], [25.0, 30]])\n",
    "print(y)\n",
    "# [[ 31.4  94. ]\n",
    "#  [ 40.5 109. ]\n",
    "#  [ 25.   30. ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='multioutputregressor'></a> 1.12.4.2. **`MultiOutputRegressor`**<br/>([_`MultiOutputRegressor`_](https://scikit-learn.org/stable/modules/multiclass.html#multioutputregressor))\n",
    "\n",
    "Le support de la régression multi-sorties peut être ajouté à n'importe quel régresseur avec [**`MultiOutputRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor). Cette stratégie consiste à ajuster un régresseur par cible. Comme chaque cible est représentée par exactement un régresseur, il est possible d'acquérir des connaissances sur la cible en inspectant son régresseur correspondant. Comme [**`MultiOutputRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor) ajuste un régresseur par cible, il ne peut pas tirer parti des corrélations entre les cibles.\n",
    "\n",
    "Voici un exemple de régression multi-sorties :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-154.75474165, -147.03498585,  -50.03812219],\n",
       "       [   7.12165031,    5.12914884,  -81.46081961],\n",
       "       [-187.8948621 , -100.44373091,   13.88978285],\n",
       "       [-141.62745778,   95.02891072, -191.48204257],\n",
       "       [  97.03260883,  165.34867495,  139.52003279],\n",
       "       [ 123.92529176,   21.25719016,   -7.84253   ],\n",
       "       [-122.25193977,  -85.16443186, -107.12274212],\n",
       "       [ -30.170388  ,  -94.80956739,   12.16979946],\n",
       "       [ 140.72667194,  176.50941682,  -17.50447799],\n",
       "       [ 149.37967282,  -81.15699552,   -5.72850319]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "X, y = make_regression(n_samples=10, n_targets=3, random_state=1)\n",
    "MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='regressorchain'></a> 1.12.4.3. **`RegressorChain`**<br/>([_`RegressorChain`_](https://scikit-learn.org/stable/modules/multiclass.html#regressorchain))\n",
    "\n",
    "Les chaînes de régresseurs (voir [**`RegressorChain`**](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.RegressorChain.html#sklearn.multioutput.RegressorChain)) sont analogues aux chaînes de classifieurs ([**`ClassifierChain`**](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html#sklearn.multioutput.ClassifierChain)) et permettent de combiner un certain nombre de régressions en un modèle multi-cibles unique capable d'exploiter les corrélations entre les cibles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
