{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='model-selection-and-evaluation'></a> 3. [**S√©lection et √©valuation de mod√®le**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#model-selection-and-evaluation)</br>([*Model selection and evaluation*](https://scikit-learn.org/stable/model_selection.html#model-selection-and-evaluation))\n",
    "\n",
    "# 3.2. [**R√©glage des hyper-param√®tres d'un estimateur**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#tuning-the-hyper-parameters-of-an-estimator)<br/>([_Tuning the hyper-parameters of an estimator_](https://scikit-learn.org/stable/model_selection.html#tuning-the-hyper-parameters-of-an-estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 18 pages, 9 exemples, 3 papiers\n",
    "- 3.2.1. [**Recherche exhaustive en grille**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#exhaustive-grid-search)<br/>([_Exhaustive Grid Search_](https://scikit-learn.org/stable/model_selection.html#exhaustive-grid-search))\n",
    "- 3.2.2. [**Optimisation al√©atoire des param√®tres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#randomized-parameter-optimization)<br/>([_Randomized Parameter Optimization_](https://scikit-learn.org/stable/model_selection.html#randomized-parameter-optimization))\n",
    "- 3.2.3. [**Recherche de param√®tres optimaux par halving successifs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#searching-for-optimal-parameters-with-successive-halving)<br/>([_Searching for optimal parameters with successive halving_](https://scikit-learn.org/stable/model_selection.html#searching-for-optimal-parameters-with-successive-halving))\n",
    "- 3.2.4. [**Conseils pour la recherche de param√®tres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#tips-for-parameter-search)<br/>([_Tips for parameter search_](https://scikit-learn.org/stable/model_selection.html#tips-for-parameter-search))\n",
    "- 3.2.5. [**Alternatives √† la recherche de param√®tres par force brute**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#alternatives-to-brute-force-parameter-search)<br/>([_Alternatives to brute force parameter search_](https://scikit-learn.org/stable/model_selection.html#alternatives-to-brute-force-parameter-search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les hyperparam√®tres sont des param√®tres qui ne sont pas directement appris au sein des estimateurs. Dans scikit-learn, ils sont transmis en tant qu'arguments au constructeur des classes d'estimateur. Des exemples typiques incluent `C`, `kernel` et `gamma` pour le classifieur √† vecteurs de support, `alpha` pour Lasso, etc.\n",
    "\n",
    "Il est possible et recommand√© d'explorer l'espace des hyperparam√®tres pour obtenir le meilleur score de [**validation crois√©e** (3.1)](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).\n",
    "\n",
    "Tout param√®tre fourni lors de la construction d'un estimateur peut √™tre optimis√© de cette mani√®re. Pour trouver les noms et les valeurs actuelles de tous les param√®tres pour un estimateur donn√©, utilisez :\n",
    "\n",
    "```python\n",
    "estimator.get_params()\n",
    "```\n",
    "\n",
    "Une recherche comprend :\n",
    "- un estimateur (r√©gresseur ou classifieur tel que `sklearn.svm.SVC()`);\n",
    "- un espace de param√®tres ;\n",
    "- une m√©thode pour rechercher ou √©chantillonner des candidats ;\n",
    "- un sch√©ma de validation crois√©e ; et\n",
    "- une [**fonction de score** (3.2.4.1)](https://scikit-learn.org/stable/modules/grid_search.html#gridsearch-scoring).\n",
    "\n",
    "Deux approches g√©n√©riques de recherche de param√®tres sont fournies dans scikit-learn : pour des valeurs donn√©es, [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) consid√®re exhaustivement toutes les combinaisons de param√®tres, tandis que [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) peut √©chantillonner un nombre donn√© de candidats dans un espace de param√®tres avec une distribution sp√©cifi√©e. Ces deux outils ont des contreparties successives, [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) et [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html), qui peuvent √™tre beaucoup plus rapides pour trouver une bonne combinaison de param√®tres.\n",
    "\n",
    "Apr√®s avoir d√©crit ces outils, nous d√©taillons les [**meilleures pratiques** (3.2.4)](https://scikit-learn.org/stable/modules/grid_search.html#grid-search-tips) applicables √† ces approches. Certains mod√®les permettent des strat√©gies de recherche de param√®tres sp√©cialis√©es et efficaces, d√©crites dans [**Alternatives to brute force parameter search** (3.2.5)](https://scikit-learn.org/stable/modules/grid_search.html#alternative-cv).\n",
    "\n",
    "Notez qu'il est courant qu'un petit sous-ensemble de ces param√®tres puisse avoir un impact important sur les performances pr√©dictives ou calculatoires du mod√®le, tandis que d'autres peuvent √™tre laiss√©s √† leurs valeurs par d√©faut. Il est recommand√© de lire la documentation de la classe d'estimateur pour mieux comprendre leur comportement attendu, √©ventuellement en lisant la r√©f√©rence contenue dans la documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='exhaustive-grid-search'></a> 3.2.1. Recherche exhaustive en grille\n",
    "\n",
    "La recherche en grille fournie par [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) g√©n√®re de mani√®re exhaustive des candidats √† partir d'une grille de valeurs de param√®tres sp√©cifi√©e avec le param√®tre `param_grid`. Par exemple, la grille suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'instance [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) impl√©mente l'API habituelle de l'estimateur : lorsqu'elle est \"ajust√©e\" sur un ensemble de donn√©es, toutes les combinaisons possibles de valeurs de param√®tres sont √©valu√©es et la meilleure combinaison est conserv√©e.\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**Strat√©gie personnalis√©e de r√©ajustement d'une recherche en grille avec validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_digits.ipynb)<br/>([_Custom refit strategy of a grid search with cross-validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html))\n",
    "\n",
    "Un exemple de calcul de recherche en grille sur l'ensemble de donn√©es \"digits\".\n",
    "\n",
    "#### [**Exemple de pipeline pour l'extraction et l'√©valuation de caract√©ristiques de texte**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_text_feature_extraction.ipynb)<br/>([_Sample pipeline for text feature extraction and evaluation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_text_feature_extraction.html))\n",
    "Un exemple d'utilisation de la recherche en grille couplant des param√®tres d'un extracteur de caract√©ristiques de documents texte (comptage des n-grammes et transformation TF-IDF) avec un classifieur (ici un SVM lin√©aire entra√Æn√© avec SGD avec soit une r√©gularisation de type elastic net, soit une r√©gularisation de type L2) √† l'aide d'une instance `pipeline.Pipeline`.\n",
    "\n",
    "#### [**Validation crois√©e imbriqu√©e vs. non-imbriqu√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_nested_cross_validation_iris.ipynb)<br/>([_Nested versus non-nested cross-validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html))\n",
    "\n",
    "Un exemple de recherche en grille dans une boucle de validation crois√©e sur l'ensemble de donn√©es \"Iris\". Il s'agit de la meilleure pratique pour √©valuer les performances d'un mod√®le avec la recherche en grille.\n",
    "\n",
    "#### [**D√©monstration de l'√©valuation multi-m√©trique sur `cross_val_score` et `GridSearchCV`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_multi_metric_evaluation.ipynb)<br/>([_Demonstration of multi-metric evaluation on `cross_val_score` and `GridSearchCV`_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html))\n",
    "\n",
    "Un exemple d'utilisation de [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) pour √©valuer simultan√©ment plusieurs m√©triques.\n",
    "\n",
    "#### [**√âquilibrer la complexit√© du mod√®le et le score valid√© par validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_refit_callable.ipynb)<br/>([_Balance model complexity and cross-validated score_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_refit_callable.html))\n",
    "\n",
    "Un exemple d'utilisation de l'interface `refit=callable` dans [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). L'exemple montre comment cette interface ajoute une certaine flexibilit√© pour identifier le meilleur estimateur. Cette interface peut √©galement √™tre utilis√©e dans l'√©valuation de plusieurs m√©triques.\n",
    "\n",
    "#### [**Comparaison statistique des mod√®les √† l'aide de la recherche en grille**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_stats.ipynb)<br/>([_Statistical comparison of models using grid search_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_stats.html))\n",
    "\n",
    "Un exemple de comparaison statistique des r√©sultats de [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='randomized-parameter-optimization'></a> 3.2.2. Optimisation de param√®tres al√©atoire\n",
    "\n",
    "Bien que l'utilisation d'une grille de param√®tres soit actuellement la m√©thode la plus largement utilis√©e pour l'optimisation des param√®tres, d'autres m√©thodes de recherche pr√©sentent des propri√©t√©s plus favorables. [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) met en ≈ìuvre une recherche al√©atoire des param√®tres, o√π chaque param√®tre est √©chantillonn√© √† partir d'une distribution de valeurs de param√®tres possibles. Cela pr√©sente deux avantages principaux par rapport √† une recherche exhaustive :\n",
    "\n",
    "- Un budget peut √™tre choisi ind√©pendamment du nombre de param√®tres et des valeurs possibles.\n",
    "- L'ajout de param√®tres qui n'influencent pas les performances n'affecte pas l'efficacit√©.\n",
    "\n",
    "La sp√©cification de la mani√®re dont les param√®tres doivent √™tre √©chantillonn√©s est effectu√©e √† l'aide d'un dictionnaire, tr√®s similaire √† la sp√©cification des param√®tres pour [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). De plus, un budget de calcul, repr√©sent√© par le nombre de candidats √©chantillonn√©s ou d'it√©rations d'√©chantillonnage, est sp√©cifi√© √† l'aide du param√®tre `n_iter`. Pour chaque param√®tre, il est possible de sp√©cifier soit une distribution de valeurs possibles, soit une liste de choix discrets (qui seront √©chantillonn√©s uniform√©ment) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "{\n",
    "    'C': scipy.stats.expon(scale=100),\n",
    "    'gamma': scipy.stats.expon(scale=.1),\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight':['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet exemple utilise le module `scipy.stats`, qui contient de nombreuses distributions utiles pour l'√©chantillonnage des param√®tres, telles que `expon`, `gamma`, `uniform`, `loguniform` ou `randint`.\n",
    "\n",
    "En principe, n'importe quelle fonction peut √™tre utilis√©e, pourvu qu'elle fournisse une m√©thode `rvs` (√©chantillonnage de variable al√©atoire) pour √©chantillonner une valeur. Un appel √† la fonction `rvs` doit fournir des √©chantillons al√©atoires ind√©pendants √† partir des valeurs de param√®tres possibles lors des appels cons√©cutifs.\n",
    "\n",
    "> **Attention:** Les distributions dans `scipy.stats` avant la version scipy 0.16 ne permettent pas de sp√©cifier un √©tat al√©atoire. √Ä la place, elles utilisent l'√©tat al√©atoire global de numpy, qui peut √™tre initialis√© via `np.random.seed` ou d√©fini √† l'aide de `np.random.set_state`. Cependant, √† partir de scikit-learn 0.18, le module [**`sklearn.model_selection`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) d√©finira l'√©tat al√©atoire fourni par l'utilisateur si scipy >= 0.16 est √©galement disponible.\n",
    "\n",
    "Pour les param√®tres continus, tels que `C` ci-dessus, il est important de sp√©cifier une distribution continue pour tirer pleinement parti de la randomisation. De cette fa√ßon, l'augmentation de `n_iter` conduira toujours √† une recherche plus fine.\n",
    "\n",
    "Une variable al√©atoire continue uniforme logarithmique est la version continue d'un param√®tre r√©parti logarithmiquement. Par exemple, pour sp√©cifier l'√©quivalent de `C` ci-dessus, on peut utiliser `loguniform(1, 100)` au lieu de `[1, 10, 100]`.\n",
    "\n",
    "En suivant l'exemple ci-dessus de recherche en grille, nous pouvons sp√©cifier une variable al√©atoire continue r√©partie de mani√®re logarithmique entre `1e0` et `1e3` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import loguniform\n",
    "{\n",
    "    'C': loguniform(1e0, 1e3),\n",
    "    'gamma': loguniform(1e-4, 1e-3),\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight':['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### [**Comparaison de la recherche al√©atoire et de la recherche en grille pour l'estimation d'hyperparam√®tres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_randomized_search.ipynb)<br/>([_Comparing randomized search and grid search for hyperparameter estimation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html))\n",
    "\n",
    "Compare l'utilisation et l'efficacit√© de la recherche al√©atoire et de la recherche en grille."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©f√©rences\n",
    "\n",
    "üî¨ Bergstra, J. and Bengio, Y., [**‚ÄúRandom search for hyper-parameter optimization‚Äù**](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf), The Journal of Machine Learning Research (2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='searching-for-optimal-parameters-with-successive-halving'></a> 3.2.3. Searching for optimal parameters with successive halving\n",
    "\n",
    "Scikit-learn also provides the [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) and [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) estimators that can be used to search a parameter space using successive halving [1] [2]. Successive halving (SH) is like a tournament among candidate parameter combinations. SH is an iterative selection process where all candidates (the parameter combinations) are evaluated with a small amount of resources at the first iteration. Only some of these candidates are selected for the next iteration, which will be allocated more resources. For parameter tuning, the resource is typically the number of training samples, but it can also be an arbitrary numeric parameter such as `n_estimators` in a random forest.\n",
    "\n",
    "As illustrated in the figure below, only a subset of candidates ‚Äòsurvive‚Äô until the last iteration. These are the candidates that have consistently ranked among the top-scoring candidates across all iterations. Each iteration is allocated an increasing amount of resources per candidate, here the number of samples.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_successive_halving_iterations_001.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "We here briefly describe the main parameters, but each parameter and their interactions are described in more details in the sections below. The `factor` (> 1) parameter controls the rate at which the resources grow, and the rate at which the number of candidates decreases. In each iteration, the number of resources per candidate is multiplied by `factor` and the number of candidates is divided by the same factor. Along with `resource` and `min_resources`, factor is the most important parameter to control the search in our implementation, though a value of 3 usually works well. `factor` effectively controls the number of iterations in [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) and the number of candidates (by default) and iterations in [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html). `aggressive_elimination=True` can also be used if the number of available resources is small. More control is available through tuning the `min_resources` parameter.\n",
    "\n",
    "These estimators are still experimental: their predictions and their API might change without any deprecation cycle. To use them, you need to explicitly import `enable_halving_search_cv`:\n",
    "\n",
    "```python\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "```\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Comparison between grid search and successive halving\n",
    "#### Successive Halving Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='searching-for-optimal-parameters-with-successive-halving'></a> 3.2.3. Recherche des param√®tres optimaux avec le \"Successive Halving\"\n",
    "\n",
    "Scikit-learn propose √©galement les estimateurs [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) et [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) qui peuvent √™tre utilis√©s pour rechercher dans un espace de param√®tres en utilisant le \"Successive Halving\" [1] [2]. Le \"Successive Halving\" (SH) est comme un tournoi entre les combinaisons de param√®tres candidates. Le SH est un processus de s√©lection it√©ratif o√π toutes les combinaisons candidates (les combinaisons de param√®tres) sont √©valu√©es avec une petite quantit√© de ressources lors de la premi√®re it√©ration. Seules certaines de ces combinaisons candidates sont s√©lectionn√©es pour la prochaine it√©ration, qui b√©n√©ficiera de plus de ressources. Pour l'optimisation des param√®tres, la ressource est g√©n√©ralement le nombre d'√©chantillons d'entra√Ænement, mais elle peut √©galement √™tre un param√®tre num√©rique arbitraire tel que `n_estimators` dans une for√™t al√©atoire.\n",
    "\n",
    "Comme illustr√© dans la figure ci-dessous, seuls certains candidats \"survivent\" jusqu'√† la derni√®re it√©ration. Ce sont les candidats qui se sont constamment class√©s parmi les meilleurs candidats en termes de score lors de toutes les it√©rations. √Ä chaque it√©ration, une quantit√© croissante de ressources par candidat est allou√©e, ici le nombre d'√©chantillons.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_successive_halving_iterations_001.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Nous d√©crivons bri√®vement ici les principaux param√®tres, mais chaque param√®tre et leurs interactions sont d√©crits plus en d√©tail dans les sections suivantes. Le param√®tre `factor` (> 1) contr√¥le le taux de croissance des ressources et le taux de diminution du nombre de candidats. √Ä chaque it√©ration, le nombre de ressources par candidat est multipli√© par `factor` et le nombre de candidats est divis√© par le m√™me facteur. Avec `resource` et `min_resources`, le param√®tre `factor` est le param√®tre le plus important pour contr√¥ler la recherche dans notre impl√©mentation, bien qu'une valeur de 3 fonctionne g√©n√©ralement bien. `factor` contr√¥le efficacement le nombre d'it√©rations dans [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) et le nombre de candidats (par d√©faut) et d'it√©rations dans [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html). `aggressive_elimination=True` peut √©galement √™tre utilis√© si le nombre de ressources disponibles est faible. Un contr√¥le plus pr√©cis est possible en ajustant le param√®tre `min_resources`.\n",
    "\n",
    "Ces estimateurs sont encore **exp√©rimentaux** : leurs pr√©dictions et leur API peuvent changer sans aucun cycle de d√©pr√©ciation. Pour les utiliser, vous devez importer explicitement `enable_halving_search_cv` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### [**Comparaison entre la recherche en grille et le \"Successive Halving\"**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_successive_halving_heatmap.ipynb)<br/>([_Comparison between grid search and successive halving_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_successive_halving_heatmap.html))\n",
    "\n",
    "#### [**It√©rations du \"Successive Halving\"**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_successive_halving_iterations.ipynb)<br/>([_Successive Halving Iterations_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_successive_halving_iterations.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='choosing-min-resources-and-the-number-of-candidates'></a> 3.2.3.1. Choix de `min_resources` et du nombre de candidats\n",
    "\n",
    "Outre le param√®tre `factor`, les deux principaux param√®tres qui influencent le comportement d'une recherche \"successive halving\" sont le param√®tre `min_resources` et le nombre de candidats (ou combinaisons de param√®tres) √©valu√©s. `min_resources` correspond √† la quantit√© de ressources allou√©es √† chaque candidat lors de la premi√®re it√©ration. Le nombre de candidats est sp√©cifi√© directement dans [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) et est d√©termin√© √† partir du param√®tre `param_grid` de [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html).\n",
    "\n",
    "Consid√©rons un cas o√π la ressource est le nombre d'√©chantillons et o√π nous avons 1000 √©chantillons. En th√©orie, avec `min_resources=10` et `factor=2`, nous pouvons effectuer **au maximum** 7 it√©rations avec le nombre d'√©chantillons suivant : `[10, 20, 40, 80, 160, 320, 640]`.\n",
    "\n",
    "Cependant, en fonction du nombre de candidats, nous pourrions ex√©cuter moins de 7 it√©rations : si nous commen√ßons avec un nombre **r√©duit** de candidats, la derni√®re it√©ration pourrait utiliser moins de 640 √©chantillons, ce qui signifie que toutes les ressources disponibles (√©chantillons) ne sont pas utilis√©es. Par exemple, si nous commen√ßons avec 5 candidats, nous n'avons besoin que de 2 it√©rations : 5 candidats pour la premi√®re it√©ration, puis `5 // 2 = 2` candidats √† la deuxi√®me it√©ration, apr√®s quoi nous saurons quel candidat est le meilleur (donc nous n'avons pas besoin d'une troisi√®me it√©ration). Nous n'utiliserions que 20 √©chantillons au maximum, ce qui serait une perte car nous avons 1000 √©chantillons √† disposition. D'autre part, si nous commen√ßons avec un nombre **√©lev√©** de candidats, nous pourrions nous retrouver avec beaucoup de candidats lors de la derni√®re it√©ration, ce qui peut ne pas toujours √™tre id√©al : cela signifie que de nombreux candidats fonctionneront avec toutes les ressources, r√©duisant ainsi essentiellement la proc√©dure √† une recherche standard.\n",
    "\n",
    "Dans le cas de [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html), le nombre de candidats est d√©fini par d√©faut de mani√®re √† ce que la derni√®re it√©ration utilise autant de ressources disponibles que possible. Pour [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html), le nombre de candidats est d√©termin√© par le param√®tre `param_grid`. Le fait de modifier la valeur de `min_resources` aura un impact sur le nombre d'it√©rations possibles et, par cons√©quent, aura √©galement un effet sur le nombre id√©al de candidats.\n",
    "\n",
    "Un autre facteur √† prendre en compte lors du choix de `min_resources` est de savoir s'il est facile ou non de distinguer entre les bons et les mauvais candidats avec une petite quantit√© de ressources. Par exemple, si vous avez besoin de beaucoup d'√©chantillons pour distinguer entre de bons et de mauvais param√®tres, il est recommand√© d'utiliser une valeur √©lev√©e pour `min_resources`. En revanche, si la distinction est claire m√™me avec une petite quantit√© d'√©chantillons, une petite valeur de `min_resources` peut √™tre pr√©f√©rable car cela acc√©l√©rerait le calcul.\n",
    "\n",
    "Remarquez dans l'exemple ci-dessus que la derni√®re it√©ration n'utilise pas la quantit√© maximale de ressources disponibles : 1000 √©chantillons sont disponibles, mais seuls 640 sont utilis√©s au maximum. Par d√©faut, √† la fois [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) et [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) essaient d'utiliser autant de ressources que possible lors de la derni√®re it√©ration, avec la contrainte que cette quantit√© de ressources doit √™tre un multiple √† la fois de `min_resources` et `factor` (cette contrainte sera expliqu√©e dans la prochaine section). [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) atteint cet objectif en √©chantillonnant la bonne quantit√© de candidats, tandis que [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) y parvient en fixant correctement `min_resources`. Pour plus de d√©tails, veuillez consulter [**√âpuisement des ressources disponibles** (3.2.3.4)](https://scikit-learn.org/stable/modules/grid_search.html#exhausting-the-resources)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='amount-of-resource-and-number-of-candidates-at-each-iteration'></a> 3.2.3.2. Quantit√© de ressources et nombre de candidats √† chaque it√©ration\n",
    "\n",
    "√Ä chaque it√©ration `i`, chaque candidat se voit allouer une quantit√© de ressources donn√©e que nous notons `n_resources_i`. Cette quantit√© est contr√¥l√©e par les param√®tres `factor` et `min_resources` de la mani√®re suivante (`factor` est strictement sup√©rieur √† 1) :\n",
    "\n",
    "    n_resources_i = factor**i * min_resources\n",
    "\n",
    "ou de mani√®re √©quivalente :\n",
    "\n",
    "    n_resources_{i+1} = n_resources_i * factor\n",
    "\n",
    "o√π `min_resources == n_resources_0` repr√©sente la quantit√© de ressources utilis√©e lors de la premi√®re it√©ration. `factor` d√©finit √©galement les proportions de candidats qui seront s√©lectionn√©s pour l'it√©ration suivante :\n",
    "\n",
    "    n_candidates_i = n_candidates // (factor ** i)\n",
    "\n",
    "ou de mani√®re √©quivalente :\n",
    "\n",
    "    n_candidates_0 = n_candidates\n",
    "    n_candidates_{i+1} = n_candidates_i // factor\n",
    "\n",
    "Ainsi, lors de la premi√®re it√©ration, nous utilisons `min_resources` ressources `n_candidates` fois. Lors de la deuxi√®me it√©ration, nous utilisons `min_resources * factor` ressources `n_candidates // factor` fois. Le processus se r√©p√®te jusqu'√† ce que la quantit√© maximale de ressources par candidat soit atteinte ou jusqu'√† ce que nous ayons identifi√© le meilleur candidat. Le meilleur candidat est identifi√© lors de l'it√©ration qui √©value `factor` candidats ou moins (voir ci-dessous pour une explication).\n",
    "\n",
    "Voici un exemple avec `min_resources=3` et `factor=2`, en commen√ßant avec 70 candidats :\n",
    "\n",
    "| `n_resources_i` | `n_candidates_i` |\n",
    "|-|-|\n",
    "| 3 (=min_resources) | 70 (=n_candidates) |\n",
    "| 3 * 2 = 6 | 70 // 2 = 35 |\n",
    "| 6 * 2 = 12 | 35 // 2 = 17 |\n",
    "| 12 * 2 = 24 | 17 // 2 = 8 |\n",
    "| 24 * 2 = 48 | 8 // 2 = 4 |\n",
    "| 48 * 2 = 96 | 4 // 2 = 2 |\n",
    "\n",
    "Nous pouvons remarquer que :\n",
    "\n",
    "- le processus s'arr√™te √† la premi√®re it√©ration qui √©value `factor=2` candidats : le meilleur candidat est le meilleur parmi ces 2 candidats. Il n'est pas n√©cessaire d'ex√©cuter une it√©ration suppl√©mentaire, car elle n'√©valuerait qu'un seul candidat (√† savoir le meilleur, que nous avons d√©j√† identifi√©). Pour cette raison, en g√©n√©ral, nous voulons que la derni√®re it√©ration √©value au plus `factor` candidats. Si la derni√®re it√©ration √©value plus de `factor` candidats, alors cette derni√®re it√©ration se r√©duit √† une recherche classique (comme dans [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) ou [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)).\n",
    "- chaque `n_resources_i` est un multiple de `factor` et `min_resources` (ce qui est confirm√© par sa d√©finition ci-dessus).\n",
    "\n",
    "La quantit√© de ressources utilis√©e √† chaque it√©ration peut √™tre trouv√©e dans l'attribut `n_resources_`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='choosing-a-resource'></a> 3.2.3.3. Choix d'une ressource\n",
    "\n",
    "Par d√©faut, la ressource est d√©finie en termes de nombre d'√©chantillons. C'est-√†-dire que chaque it√©ration utilisera un nombre croissant d'√©chantillons pour l'entra√Ænement. Cependant, vous pouvez sp√©cifier manuellement un param√®tre √† utiliser comme ressource avec le param√®tre `resource`. Voici un exemple o√π la ressource est d√©finie en termes du nombre d'estimateurs d'une for√™t al√©atoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 10],\n",
    "              'min_samples_split': [2, 5, 10]}\n",
    "base_estimator = RandomForestClassifier(random_state=0)\n",
    "X, y = make_classification(n_samples=1000, random_state=0)\n",
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "                         factor=2, resource='n_estimators',\n",
    "                         max_resources=30).fit(X, y)\n",
    "sh.best_estimator_\n",
    "# RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez noter qu'il n'est pas possible de fixer un budget sur un param√®tre qui fait partie de la grille de param√®tres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='exhausting-the-available-resources'></a> 3.2.3.4. √âpuisement des ressources disponibles\n",
    "\n",
    "Comme mentionn√© ci-dessus, le nombre de ressources utilis√©es √† chaque it√©ration d√©pend du param√®tre `min_resources`. Si vous disposez de nombreuses ressources disponibles mais commencez avec un faible nombre de ressources, certaines d'entre elles peuvent √™tre gaspill√©es (c'est-√†-dire non utilis√©es) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "import pandas as pd\n",
    "param_grid= {'kernel': ('linear', 'rbf'),\n",
    "             'C': [1, 10, 100]}\n",
    "base_estimator = SVC(gamma='scale')\n",
    "X, y = make_classification(n_samples=1000)\n",
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "                         factor=2, min_resources=20).fit(X, y)\n",
    "sh.n_resources_\n",
    "# [20, 40, 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le processus de recherche n'utilisera au maximum que 80 ressources, alors que notre quantit√© maximale de ressources disponibles est `n_samples=1000`. Ici, nous avons `min_resources = r_0 = 20`.\n",
    "\n",
    "Pour [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html), par d√©faut, le param√®tre `min_resources` est d√©fini sur ‚Äòexhaust‚Äô. Cela signifie que `min_resources` est automatiquement d√©fini de mani√®re √† ce que la derni√®re it√©ration puisse utiliser autant de ressources que possible, dans la limite de `max_resources` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "                         factor=2, min_resources='exhaust').fit(X, y)\n",
    "sh.n_resources_\n",
    "# [250, 500, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`min_resources` a √©t√© automatiquement d√©fini ici sur 250, ce qui permet √† la derni√®re it√©ration d'utiliser toutes les ressources. La valeur exacte utilis√©e d√©pend du nombre de candidats param√®tres, de `max_resources` et de `factor`.\n",
    "\n",
    "Pour [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html), l'√©puisement des ressources peut √™tre r√©alis√© de deux mani√®res :\n",
    "- en d√©finissant `min_resources='exhaust'`, tout comme pour [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) ;\n",
    "- en d√©finissant `n_candidates='exhaust'`.\n",
    "\n",
    "Ces deux options sont mutuellement exclusives : l'utilisation de `min_resources='exhaust'` n√©cessite de conna√Ætre le nombre de candidats, et sym√©triquement `n_candidates='exhaust'` n√©cessite de conna√Ætre `min_resources`.\n",
    "\n",
    "En g√©n√©ral, l'√©puisement total des ressources conduit √† un meilleur candidat final et prend un peu plus de temps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='aggressive-elimination-of-candidates'></a> 3.2.3.5. √âlimination agressive des candidats\n",
    "\n",
    "Id√©alement, nous souhaitons que la derni√®re it√©ration √©value `factor` candidats (voir [**Quantit√© de ressources et nombre de candidats √† chaque it√©ration** (3.2.3.2)](https://scikit-learn.org/stable/modules/grid_search.html#amount-of-resource-and-number-of-candidates)). Il nous suffit ensuite de choisir le meilleur. Lorsque le nombre de ressources disponibles est faible par rapport au nombre de candidats, la derni√®re it√©ration peut √™tre amen√©e √† √©valuer plus de `factor` candidats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "import pandas as pd\n",
    "param_grid = {'kernel': ('linear', 'rbf'),\n",
    "              'C': [1, 10, 100]}\n",
    "base_estimator = SVC(gamma='scale')\n",
    "X, y = make_classification(n_samples=1000)\n",
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "                         factor=2, max_resources=40,\n",
    "                         aggressive_elimination=False).fit(X, y)\n",
    "sh.n_resources_\n",
    "# [20, 40]\n",
    "sh.n_candidates_\n",
    "# [6, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous ne pouvons pas utiliser plus de `max_resources=40` ressources, le processus doit s'arr√™ter √† la deuxi√®me it√©ration, qui √©value plus de `factor=2` candidats.\n",
    "\n",
    "En utilisant le param√®tre `aggressive_elimination`, vous pouvez forcer le processus de recherche √† se terminer avec moins de `factor` candidats lors de la derni√®re it√©ration. Pour ce faire, le processus √©liminera autant de candidats que n√©cessaire en utilisant `min_resources` ressources :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "                         factor=2,\n",
    "                         max_resources=40,\n",
    "                         aggressive_elimination=True,\n",
    "                         ).fit(X, y)\n",
    "sh.n_resources_\n",
    "# [20, 20,  40]\n",
    "sh.n_candidates_\n",
    "# [6, 3, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquez que nous nous retrouvons avec 2 candidats lors de la derni√®re it√©ration car nous avons √©limin√© suffisamment de candidats lors des premi√®res it√©rations en utilisant `n_resources = min_resources = 20`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='analyzing-results-with-the-cv-results-attribute'></a> 3.2.3.6. Analyse des r√©sultats avec l'attribut `cv_results_`\n",
    "\n",
    "L'attribut `cv_results_` contient des informations utiles pour analyser les r√©sultats d'une recherche. Il peut √™tre converti en un dataframe pandas avec `df = pd.DataFrame(est.cv_results_)`. L'attribut `cv_results_` de [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) et [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) est similaire √† celui de [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) et [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html), avec des informations suppl√©mentaires li√©es au processus de recherche successive halving.\n",
    "\n",
    "Voici un exemple avec certaines des colonnes d'un dataframe (tronqu√©) :\n",
    "\n",
    "|    | `iter` | `n_resources` | `mean_test_score` | `params`                                                                                   |\n",
    "|----|------|-------------|-----------------|------------------------------------------------------------------------------------------|\n",
    "| 0  | 0    | 125         | 0.983667        | {‚Äòcriterion‚Äô: ‚Äòlog_loss‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 9, ‚Äòmin_samples_split‚Äô: 5}  |\n",
    "| 1  | 0    | 125         | 0.983667        | {‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 8, ‚Äòmin_samples_split‚Äô: 7}      |\n",
    "| 2  | 0    | 125         | 0.983667        | {‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 10, ‚Äòmin_samples_split‚Äô: 10}    |\n",
    "| 3  | 0    | 125         | 0.983667        | {‚Äòcriterion‚Äô: ‚Äòlog_loss‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 6, ‚Äòmin_samples_split‚Äô: 6}  |\n",
    "| ‚Ä¶  | ‚Ä¶    | ‚Ä¶           | ‚Ä¶               | ‚Ä¶                                                                                        |\n",
    "| 15 | 2    | 500         | 0.951958        | {‚Äòcriterion‚Äô: ‚Äòlog_loss‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 9, ‚Äòmin_samples_split‚Äô: 10} |\n",
    "| 16 | 2    | 500         | 0.947958        | {‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 10, ‚Äòmin_samples_split‚Äô: 10}    |\n",
    "| 17 | 2    | 500         | 0.951958        | {‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 10, ‚Äòmin_samples_split‚Äô: 4}     |\n",
    "| 18 | 3    | 1000        | 0.961009        | {‚Äòcriterion‚Äô: ‚Äòlog_loss‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 9, ‚Äòmin_samples_split‚Äô: 10} |\n",
    "| 19 | 3    | 1000        | 0.955989        | {‚Äòcriterion‚Äô: ‚Äògini‚Äô, ‚Äòmax_depth‚Äô: None, ‚Äòmax_features‚Äô: 10, ‚Äòmin_samples_split‚Äô: 4}     |\n",
    "\n",
    "Chaque ligne correspond √† une combinaison de param√®tres donn√©e (un candidat) et √† une it√©ration donn√©e. L'it√©ration est donn√©e par la colonne `iter`. La colonne `n_resources` vous indique combien de ressources ont √©t√© utilis√©es.\n",
    "\n",
    "Dans l'exemple ci-dessus, la meilleure combinaison de param√®tres est `{'criterion': 'log_loss', 'max_depth': None, 'max_features': 9, 'min_samples_split': 10}` car elle a atteint la derni√®re it√©ration (3) avec le score le plus √©lev√© : 0.96."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©f√©rences\n",
    "\n",
    "üî¨ [1] K. Jamieson, A. Talwalkar, [**‚ÄúNon-stochastic Best Arm Identification and Hyperparameter Optimization‚Äù**](http://proceedings.mlr.press/v51/jamieson16.pdf), in proc. of Machine Learning Research, 2016.\n",
    "\n",
    "üî¨ [2] L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, A. Talwalkar, [**‚ÄúHyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization‚Äù**](https://arxiv.org/pdf/1603.06560.pdf), in Machine Learning Research 18, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='tips-for-parameter-search'></a> 3.2.4. Tips for parameter search\n",
    "\n",
    "### <a id='specifying-an-objective-metric'></a> 3.2.4.1. Specifying an objective metric\n",
    "\n",
    "By default, parameter search uses the `score` function of the estimator to evaluate a parameter setting. These are the [**`sklearn.metrics.accuracy_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) for classification and [**`sklearn.metrics.r2_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) for regression. For some applications, other scoring functions are better suited (for example in unbalanced classification, the accuracy score is often uninformative). An alternative `scoring` function can be specified via the scoring parameter of most parameter search tools. See [**The scoring parameter: defining model evaluation rules** (3.3.1)](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) for more details.\n",
    "\n",
    "### <a id='specifying-multiple-metrics-for-evaluation'></a> 3.2.4.2. Specifying multiple metrics for evaluation\n",
    "\n",
    "[**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) allow specifying multiple metrics for the `scoring` parameter.\n",
    "\n",
    "Multimetric scoring can either be specified as a list of strings of predefined scores names or a dict mapping the scorer name to the scorer function and/or the predefined scorer name(s). See [**Using multiple metric evaluation** (3.3.1.4)](https://scikit-learn.org/stable/modules/model_evaluation.html#multimetric-scoring) for more details.\n",
    "\n",
    "When specifying multiple metrics, the `refit` parameter must be set to the metric (string) for which the `best_params_` will be found and used to build the `best_estimator_` on the whole dataset. If the search should not be refit, set `refit=False`. Leaving refit to the default value `None` will result in an error when using multiple metrics.\n",
    "\n",
    "See [**Demonstration of multi-metric evaluation on `cross_val_score` and `GridSearchCV`**](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py) for an example usage.\n",
    "\n",
    "[**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) and [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) do not support multimetric scoring.\n",
    "\n",
    "### <a id='composite-estimators-and-parameter-spaces'></a> 3.2.4.3. Composite estimators and parameter spaces\n",
    "\n",
    "[**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) allow searching over parameters of composite or nested estimators such as [**`Pipeline`**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), [**`ColumnTransformer`**](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html), [**`VotingClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html) or [**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html) using a dedicated `<estimator>__<parameter>` syntax:\n",
    "\n",
    "---\n",
    "\n",
    "Here, `<estimator>` is the parameter name of the nested `estimator`, in this case estimator. If the meta-estimator is constructed as a collection of estimators as in `pipeline.Pipeline`, then `<estimator>` refers to the name of the estimator, see [**Nested parameters** (6.1.1.1.3)](https://scikit-learn.org/stable/modules/compose.html#pipeline-nested-parameters). In practice, there can be several levels of nesting:\n",
    "\n",
    "---\n",
    "\n",
    "Please refer to [**Pipeline: chaining estimators** (6.1.1)](https://scikit-learn.org/stable/modules/compose.html#pipeline) for performing parameter searches over pipelines.\n",
    "\n",
    "### <a id='model-selection-development-and-evaluation'></a> 3.2.4.4. Model selection: development and evaluation\n",
    "\n",
    "Model selection by evaluating various parameter settings can be seen as a way to use the labeled data to ‚Äútrain‚Äù the parameters of the grid.\n",
    "\n",
    "When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a **development set** (to be fed to the [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) instance) and an **evaluation set** to compute performance metrics.\n",
    "\n",
    "This can be done by using the [**`train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) utility function.\n",
    "\n",
    "### <a id='parallelism'></a> 3.2.4.5. Parallelism\n",
    "\n",
    "The parameter search tools evaluate each parameter combination on each data fold independently. Computations can be run in parallel by using the keyword `n_jobs=-1`. See function signature for more details, and also the Glossary entry for [`n_jobs`](https://scikit-learn.org/stable/glossary.html#term-n_jobs).\n",
    "\n",
    "### <a id='robustness-to-failure'></a> 3.2.4.6. Robustness to failure\n",
    "\n",
    "Some parameter settings may result in a failure to `fit` one or more folds of the data. By default, this will cause the entire search to fail, even if some parameter settings could be fully evaluated. Setting `error_score=0` (or `=np.nan`) will make the procedure robust to such failure, issuing a warning and setting the score for that fold to 0 (or `nan`), but completing the search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='tips-for-parameter-search'></a> 3.2.4. Conseils pour la recherche de param√®tres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='specifying-an-objective-metric'></a> 3.2.4.1. Sp√©cification d'une m√©trique objective\n",
    "\n",
    "Par d√©faut, la recherche de param√®tres utilise la fonction `score` de l'estimateur pour √©valuer un param√®tre donn√©. Il s'agit des fonctions [**`sklearn.metrics.accuracy_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) pour la classification et [**`sklearn.metrics.r2_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) pour la r√©gression. Pour certaines applications, d'autres fonctions de score sont mieux adapt√©es (par exemple, dans la classification d√©s√©quilibr√©e, le score d'exactitude n'est souvent pas informatif). Une fonction `scoring` alternative peut √™tre sp√©cifi√©e via le param√®tre `scoring` de la plupart des outils de recherche de param√®tres. Consultez [**Le param√®tre de score : d√©finition des r√®gles d'√©valuation du mod√®le** (3.3.1)](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) pour plus de d√©tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='specifying-multiple-metrics-for-evaluation'></a> 3.2.4.2. Sp√©cification de plusieurs m√©triques pour l'√©valuation\n",
    "\n",
    "[**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) et [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) permettent de sp√©cifier plusieurs m√©triques pour le param√®tre `scoring`.\n",
    "\n",
    "L'√©valuation multi-m√©trique peut √™tre sp√©cifi√©e soit sous forme d'une liste de cha√Ænes de noms de scores pr√©d√©finis, soit sous forme d'un dictionnaire associant le nom du score √† la fonction de score et/ou aux noms de scores pr√©d√©finis. Consultez [**Utilisation de l'√©valuation multi-m√©trique** (3.3.1.4)](https://scikit-learn.org/stable/modules/model_evaluation.html#multimetric-scoring) pour plus de d√©tails.\n",
    "\n",
    "Lors de la sp√©cification de plusieurs m√©triques, le param√®tre `refit` doit √™tre d√©fini sur la m√©trique (cha√Æne de caract√®res) pour laquelle les `best_params_` seront trouv√©s et utilis√©s pour construire le `best_estimator_` sur l'ensemble du jeu de donn√©es. Si la recherche ne doit pas √™tre refaite, d√©finissez `refit=False`. Laisser la valeur par d√©faut `None` pour le param√®tre `refit` entra√Ænera une erreur lors de l'utilisation de plusieurs m√©triques.\n",
    "\n",
    "Veuillez consulter [**D√©monstration de l'√©valuation multi-m√©trique sur `cross_val_score` et `GridSearchCV`**](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py) pour un exemple d'utilisation.\n",
    "\n",
    "[**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) et [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) ne prennent pas en charge l'√©valuation multi-m√©trique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='composite-estimators-and-parameter-spaces'></a> 3.2.4.3. Estimateurs composites et espaces de param√®tres\n",
    "\n",
    "[**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) et [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) permettent la recherche de param√®tres d'estimateurs composites ou imbriqu√©s tels que [**`Pipeline`**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), [**`ColumnTransformer`**](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html), [**`VotingClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html) ou [**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html) en utilisant une syntaxe d√©di√©e `<estimateur>__<param√®tre>` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=CalibratedClassifierCV(estimator=RandomForestClassifier(n_estimators=10)),\n",
       "             param_grid={&#x27;estimator__max_depth&#x27;: [2, 4, 6, 8]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=CalibratedClassifierCV(estimator=RandomForestClassifier(n_estimators=10)),\n",
       "             param_grid={&#x27;estimator__max_depth&#x27;: [2, 4, 6, 8]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: CalibratedClassifierCV</label><div class=\"sk-toggleable__content\"><pre>CalibratedClassifierCV(estimator=RandomForestClassifier(n_estimators=10))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=CalibratedClassifierCV(estimator=RandomForestClassifier(n_estimators=10)),\n",
       "             param_grid={'estimator__max_depth': [2, 4, 6, 8]})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons()\n",
    "calibrated_forest = CalibratedClassifierCV(\n",
    "    estimator=RandomForestClassifier(n_estimators=10))\n",
    "param_grid = {'estimator__max_depth': [2, 4, 6, 8]}\n",
    "search = GridSearchCV(calibrated_forest, param_grid, cv=5)\n",
    "search.fit(X, y)\n",
    "# GridSearchCV(cv=5,\n",
    "#              estimator=CalibratedClassifierCV(...),\n",
    "#              param_grid={'estimator__max_depth': [2, 4, 6, 8]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, `<estimateur>` est le nom du param√®tre de l'estimateur imbriqu√©, dans ce cas, l'estimateur. Si le m√©ta-estimateur est construit comme une collection d'estimateurs comme dans `pipeline.Pipeline`, alors `<estimateur>` se r√©f√®re au nom de l'estimateur, voir [**Param√®tres imbriqu√©s** (6.1.1.1.3)](https://scikit-learn.org/stable/modules/compose.html#pipeline-nested-parameters). En pratique, il peut y avoir plusieurs niveaux d'imbrication :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "pipe = Pipeline([\n",
    "    ('select', SelectKBest()),\n",
    "    ('model', calibrated_forest)])\n",
    "param_grid = {\n",
    "    'select__k': [1, 2],\n",
    "    'model__estimator__max_depth': [2, 4, 6, 8]}\n",
    "search = GridSearchCV(pipe, param_grid, cv=5).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez vous r√©f√©rer √† [**Pipeline : encha√Ænement d'estimateurs** (6.1.1)](https://scikit-learn.org/stable/modules/compose.html#pipeline) pour effectuer des recherches de param√®tres sur les pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='model-selection-development-and-evaluation'></a> 3.2.4.4. S√©lection de mod√®le : d√©veloppement et √©valuation\n",
    "\n",
    "La s√©lection de mod√®le en √©valuant diverses valeurs de param√®tres peut √™tre consid√©r√©e comme une fa√ßon d'utiliser les donn√©es √©tiquet√©es pour \"entra√Æner\" les param√®tres de la grille.\n",
    "\n",
    "Lors de l'√©valuation du mod√®le r√©sultant, il est important de le faire sur des √©chantillons de donn√©es non vus lors du processus de recherche de la grille : il est recommand√© de diviser les donn√©es en un **ensemble de d√©veloppement** (√† alimenter √† l'instance [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)) et un **ensemble d'√©valuation** pour calculer les m√©triques de performance.\n",
    "\n",
    "Cela peut √™tre fait en utilisant la fonction utilitaire [**`train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='parallelism'></a> 3.2.4.5. Parall√©lisme\n",
    "\n",
    "Les outils de recherche de param√®tres √©valuent chaque combinaison de param√®tres sur chaque pli de donn√©es ind√©pendamment. Les calculs peuvent √™tre ex√©cut√©s en parall√®le en utilisant le mot-cl√© `n_jobs=-1`. Consultez la signature de la fonction pour plus de d√©tails, ainsi que l'entr√©e du glossaire pour [`n_jobs`](https://scikit-learn.org/stable/glossary.html#term-n_jobs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='robustness-to-failure'></a> 3.2.4.6. Robustesse face aux √©checs\n",
    "\n",
    "Certaines valeurs de param√®tres peuvent entra√Æner une d√©faillance de `fit` pour un ou plusieurs plis des donn√©es. Par d√©faut, cela entra√Ænera l'√©chec de toute la recherche, m√™me si certaines valeurs de param√®tres pourraient √™tre enti√®rement √©valu√©es. En d√©finissant `error_score=0` (ou `=np.nan`), la proc√©dure deviendra robuste √† de tels √©checs, √©mettra un avertissement et d√©finira le score pour ce pli √† 0 (ou `nan`), mais terminera la recherche sur les autres plis avec succ√®s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='alternatives-to-brute-force-parameter-search'></a> 3.2.5. Alternatives √† la recherche de param√®tres par force brute\n",
    "\n",
    "### <a id='model-specific-cross-validation'></a> 3.2.5.1. Validation crois√©e sp√©cifique au mod√®le\n",
    "\n",
    "Certains mod√®les peuvent ajuster les donn√©es pour une gamme de valeurs d'un param√®tre presque aussi efficacement que pour une seule valeur de ce param√®tre. Cette caract√©ristique peut √™tre exploit√©e pour effectuer une validation crois√©e plus efficace utilis√©e pour la s√©lection du mod√®le de ce param√®tre.\n",
    "\n",
    "Le param√®tre le plus courant pouvant b√©n√©ficier de cette strat√©gie est le param√®tre codant la force de la r√©gularisation. Dans ce cas, on dit que nous calculons le **chemin de r√©gularisation** de l'estimateur.\n",
    "\n",
    "Voici la liste de ces mod√®les :\n",
    "\n",
    "| Mod√®le                                             | Description                                                             |\n",
    "|----------------------------------------------------|-------------------------------------------------------------------------|\n",
    "| [**`linear_model.ElasticNetCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html)(*[, l1_ratio, ...])     | Mod√®le Elastic Net avec ajustement it√©ratif le long d'un chemin de r√©gularisation.  |\n",
    "| [**`linear_model.LarsCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LarsCV.html)(*[, fit_intercept, ...])      | Mod√®le de r√©gression du meilleur angle de croisement valid√©e.            |\n",
    "| [**`linear_model.LassoCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)(*[, eps, n_alphas, ...])     | Mod√®le lin√©aire Lasso avec ajustement it√©ratif le long d'un chemin de r√©gularisation. |\n",
    "| [**`linear_model.LassoLarsCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html)(*[, fit_intercept, ...]) | Lasso valid√© par croisement, en utilisant l'algorithme LARS.                       |\n",
    "| [**`linear_model.LogisticRegressionCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)(*[, Cs, ...])   | Classifieur de r√©gression logistique valid√© par croisement (√©galement appel√© logit, MaxEnt).                 |\n",
    "| [**`linear_model.MultiTaskElasticNetCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNetCV.html)(*[, ...])      | Multi-t√¢ches L1/L2 ElasticNet avec validation crois√©e int√©gr√©e.            |\n",
    "| [**`linear_model.MultiTaskLassoCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskLassoCV.html)(*[, eps, ...])      | Mod√®le Lasso multi-t√¢ches entra√Æn√© avec la norme mixte L1/L2 comme r√©gularisateur, et valid√© par croisement.   |\n",
    "| [**`linear_model.OrthogonalMatchingPursuitCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.OrthogonalMatchingPursuitCV.html)(*)       | Mod√®le de poursuite orthogonale valid√©e par croisement (OMP).               |\n",
    "| [**`linear_model.RidgeCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)([alphas, ...])               | R√©gression Ridge avec validation crois√©e int√©gr√©e.                       |\n",
    "| [**`linear_model.RidgeClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html)([alphas, ...])     | Classifieur Ridge avec validation crois√©e int√©gr√©e.                        |\n",
    "\n",
    "\n",
    "### <a id='information-criterion'></a> 3.2.5.2. Crit√®re d'information\n",
    "\n",
    "Certains mod√®les peuvent offrir une formule ferm√©e d'estimation optimale du param√®tre de r√©gularisation en utilisant un seul chemin de r√©gularisation (au lieu de plusieurs avec la validation crois√©e).\n",
    "\n",
    "Voici la liste des mod√®les b√©n√©ficiant du crit√®re d'information d'Akaike (AIC) ou du crit√®re d'information bay√©sien (BIC) pour la s√©lection automatis√©e du mod√®le :\n",
    "\n",
    "| Mod√®le                                             | Description                                                            |\n",
    "|----------------------------------------------------|------------------------------------------------------------------------|\n",
    "| [**`linear_model.LassoLarsIC`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsIC.html)([*criterion*, ...])       | Mod√®le Lasso ajust√© avec Lars en utilisant BIC ou AIC pour la s√©lection du mod√®le.        |\n",
    "\n",
    "### <a id='out-of-bag-estimates'></a> 3.2.5.3. Estimations out-of-bag\n",
    "\n",
    "Lors de l'utilisation de m√©thodes d'ensemble bas√©es sur le bagging, c'est-√†-dire g√©n√©rant de nouveaux ensembles d'entra√Ænement en utilisant l'√©chantillonnage avec remplacement, une partie de l'ensemble d'entra√Ænement reste inutilis√©e. Pour chaque classifieur de l'ensemble, une partie diff√©rente de l'ensemble d'entra√Ænement est laiss√©e de c√¥t√©.\n",
    "\n",
    "Cette partie laiss√©e de c√¥t√© peut √™tre utilis√©e pour estimer l'erreur de g√©n√©ralisation sans avoir √† utiliser un ensemble de validation distinct. Cette estimation est obtenue \"gratuitement\" car aucune donn√©e suppl√©mentaire n'est n√©cessaire et peut √™tre utilis√©e pour la s√©lection du mod√®le.\n",
    "\n",
    "Cette fonctionnalit√© est actuellement impl√©ment√©e dans les classes suivantes :\n",
    "\n",
    "| Mod√®le                                             | Description                                                            |\n",
    "|----------------------------------------------------|------------------------------------------------------------------------|\n",
    "| [**`ensemble.RandomForestClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)([...]) | Un classifieur random forest.                                           |\n",
    "| [**`ensemble.RandomForestRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)([...]) | Un r√©gresseur random forest.                                           |\n",
    "| [**`ensemble.ExtraTreesClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)([...]) | Un classifieur extra-trees.                                            |\n",
    "| [**`ensemble.ExtraTreesRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html)([n_estimators, ...]) | Un r√©gresseur extra-trees.                                           |\n",
    "| [**`ensemble.GradientBoostingClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)(*[, ...]) | Gradient Boosting pour la classification.                                 |\n",
    "| [**`ensemble.GradientBoostingRegressor`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)(*[, ...]) | Gradient Boosting pour la r√©gression.                                     |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
