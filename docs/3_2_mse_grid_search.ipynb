{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='model-selection-and-evaluation'></a> 3. [**S√©lection et √©valuation de mod√®le**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#model-selection-and-evaluation)</br>([*Model selection and evaluation*](https://scikit-learn.org/stable/model_selection.html#model-selection-and-evaluation))\n",
    "\n",
    "# 3.2. [**R√©glage des hyper-param√®tres d'un estimateur**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#tuning-the-hyper-parameters-of-an-estimator)<br/>([_Tuning the hyper-parameters of an estimator_](https://scikit-learn.org/stable/model_selection.html#tuning-the-hyper-parameters-of-an-estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 18 pages, 9 exemples, 3 papiers\n",
    "- 3.2.1. [**Recherche exhaustive en grille**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#exhaustive-grid-search)<br/>([_Exhaustive Grid Search_](https://scikit-learn.org/stable/model_selection.html#exhaustive-grid-search))\n",
    "- 3.2.2. [**Optimisation al√©atoire des param√®tres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#randomized-parameter-optimization)<br/>([_Randomized Parameter Optimization_](https://scikit-learn.org/stable/model_selection.html#randomized-parameter-optimization))\n",
    "- 3.2.3. [**Recherche de param√®tres optimaux par halving successifs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#searching-for-optimal-parameters-with-successive-halving)<br/>([_Searching for optimal parameters with successive halving_](https://scikit-learn.org/stable/model_selection.html#searching-for-optimal-parameters-with-successive-halving))\n",
    "- 3.2.4. [**Conseils pour la recherche de param√®tres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#tips-for-parameter-search)<br/>([_Tips for parameter search_](https://scikit-learn.org/stable/model_selection.html#tips-for-parameter-search))\n",
    "- 3.2.5. [**Alternatives √† la recherche de param√®tres par force brute**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/3_model_selection_and_evaluation.ipynb#alternatives-to-brute-force-parameter-search)<br/>([_Alternatives to brute force parameter search_](https://scikit-learn.org/stable/model_selection.html#alternatives-to-brute-force-parameter-search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les hyperparam√®tres sont des param√®tres qui ne sont pas directement appris au sein des estimateurs. Dans scikit-learn, ils sont transmis en tant qu'arguments au constructeur des classes d'estimateur. Des exemples typiques incluent `C`, `kernel` et `gamma` pour le classifieur √† vecteurs de support, `alpha` pour Lasso, etc.\n",
    "\n",
    "Il est possible et recommand√© d'explorer l'espace des hyperparam√®tres pour obtenir le meilleur score de [**validation crois√©e** (3.1)](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).\n",
    "\n",
    "Tout param√®tre fourni lors de la construction d'un estimateur peut √™tre optimis√© de cette mani√®re. Pour trouver les noms et les valeurs actuelles de tous les param√®tres pour un estimateur donn√©, utilisez :\n",
    "\n",
    "```python\n",
    "estimator.get_params()\n",
    "```\n",
    "\n",
    "Une recherche comprend :\n",
    "- un estimateur (r√©gresseur ou classifieur tel que `sklearn.svm.SVC()`);\n",
    "- un espace de param√®tres ;\n",
    "- une m√©thode pour rechercher ou √©chantillonner des candidats ;\n",
    "- un sch√©ma de validation crois√©e ; et\n",
    "- une [**fonction de score** (3.2.4.1)](https://scikit-learn.org/stable/modules/grid_search.html#gridsearch-scoring).\n",
    "\n",
    "Deux approches g√©n√©riques de recherche de param√®tres sont fournies dans scikit-learn : pour des valeurs donn√©es, [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) consid√®re exhaustivement toutes les combinaisons de param√®tres, tandis que [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) peut √©chantillonner un nombre donn√© de candidats dans un espace de param√®tres avec une distribution sp√©cifi√©e. Ces deux outils ont des contreparties successives, [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) et [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html), qui peuvent √™tre beaucoup plus rapides pour trouver une bonne combinaison de param√®tres.\n",
    "\n",
    "Apr√®s avoir d√©crit ces outils, nous d√©taillons les [**meilleures pratiques** (3.2.4)](https://scikit-learn.org/stable/modules/grid_search.html#grid-search-tips) applicables √† ces approches. Certains mod√®les permettent des strat√©gies de recherche de param√®tres sp√©cialis√©es et efficaces, d√©crites dans [**Alternatives to brute force parameter search** (3.2.5)](https://scikit-learn.org/stable/modules/grid_search.html#alternative-cv).\n",
    "\n",
    "Notez qu'il est courant qu'un petit sous-ensemble de ces param√®tres puisse avoir un impact important sur les performances pr√©dictives ou calculatoires du mod√®le, tandis que d'autres peuvent √™tre laiss√©s √† leurs valeurs par d√©faut. Il est recommand√© de lire la documentation de la classe d'estimateur pour mieux comprendre leur comportement attendu, √©ventuellement en lisant la r√©f√©rence contenue dans la documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='exhaustive-grid-search'></a> 3.2.1. Recherche exhaustive en grille\n",
    "\n",
    "La recherche en grille fournie par [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) g√©n√®re de mani√®re exhaustive des candidats √† partir d'une grille de valeurs de param√®tres sp√©cifi√©e avec le param√®tre `param_grid`. Par exemple, la grille suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'instance [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) impl√©mente l'API habituelle de l'estimateur : lorsqu'elle est \"ajust√©e\" sur un ensemble de donn√©es, toutes les combinaisons possibles de valeurs de param√®tres sont √©valu√©es et la meilleure combinaison est conserv√©e.\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**Strat√©gie personnalis√©e de r√©ajustement d'une recherche en grille avec validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_digits.ipynb)<br/>([_Custom refit strategy of a grid search with cross-validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html))\n",
    "\n",
    "Un exemple de calcul de recherche en grille sur l'ensemble de donn√©es \"digits\".\n",
    "\n",
    "#### [**Exemple de pipeline pour l'extraction et l'√©valuation de caract√©ristiques de texte**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_text_feature_extraction.ipynb)<br/>([_Sample pipeline for text feature extraction and evaluation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_text_feature_extraction.html))\n",
    "Un exemple d'utilisation de la recherche en grille couplant des param√®tres d'un extracteur de caract√©ristiques de documents texte (comptage des n-grammes et transformation TF-IDF) avec un classifieur (ici un SVM lin√©aire entra√Æn√© avec SGD avec soit une r√©gularisation de type elastic net, soit une r√©gularisation de type L2) √† l'aide d'une instance `pipeline.Pipeline`.\n",
    "\n",
    "#### [**Validation crois√©e imbriqu√©e vs. non-imbriqu√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_nested_cross_validation_iris.ipynb)<br/>([_Nested versus non-nested cross-validation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html))\n",
    "\n",
    "Un exemple de recherche en grille dans une boucle de validation crois√©e sur l'ensemble de donn√©es \"Iris\". Il s'agit de la meilleure pratique pour √©valuer les performances d'un mod√®le avec la recherche en grille.\n",
    "\n",
    "#### [**D√©monstration de l'√©valuation multi-m√©trique sur `cross_val_score` et `GridSearchCV`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_multi_metric_evaluation.ipynb)<br/>([_Demonstration of multi-metric evaluation on `cross_val_score` and `GridSearchCV`_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html))\n",
    "\n",
    "Un exemple d'utilisation de [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) pour √©valuer simultan√©ment plusieurs m√©triques.\n",
    "\n",
    "#### [**√âquilibrer la complexit√© du mod√®le et le score valid√© par validation crois√©e**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_refit_callable.ipynb)<br/>([_Balance model complexity and cross-validated score_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_refit_callable.html))\n",
    "\n",
    "Un exemple d'utilisation de l'interface `refit=callable` dans [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). L'exemple montre comment cette interface ajoute une certaine flexibilit√© pour identifier le meilleur estimateur. Cette interface peut √©galement √™tre utilis√©e dans l'√©valuation de plusieurs m√©triques.\n",
    "\n",
    "#### [**Comparaison statistique des mod√®les √† l'aide de la recherche en grille**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_stats.ipynb)<br/>([_Statistical comparison of models using grid search_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_stats.html))\n",
    "\n",
    "Un exemple de comparaison statistique des r√©sultats de [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='randomized-parameter-optimization'></a> 3.2.2. Optimisation de param√®tres al√©atoire\n",
    "\n",
    "Bien que l'utilisation d'une grille de param√®tres soit actuellement la m√©thode la plus largement utilis√©e pour l'optimisation des param√®tres, d'autres m√©thodes de recherche pr√©sentent des propri√©t√©s plus favorables. [**`RandomizedSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) met en ≈ìuvre une recherche al√©atoire des param√®tres, o√π chaque param√®tre est √©chantillonn√© √† partir d'une distribution de valeurs de param√®tres possibles. Cela pr√©sente deux avantages principaux par rapport √† une recherche exhaustive :\n",
    "\n",
    "- Un budget peut √™tre choisi ind√©pendamment du nombre de param√®tres et des valeurs possibles.\n",
    "- L'ajout de param√®tres qui n'influencent pas les performances n'affecte pas l'efficacit√©.\n",
    "\n",
    "La sp√©cification de la mani√®re dont les param√®tres doivent √™tre √©chantillonn√©s est effectu√©e √† l'aide d'un dictionnaire, tr√®s similaire √† la sp√©cification des param√®tres pour [**`GridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). De plus, un budget de calcul, repr√©sent√© par le nombre de candidats √©chantillonn√©s ou d'it√©rations d'√©chantillonnage, est sp√©cifi√© √† l'aide du param√®tre `n_iter`. Pour chaque param√®tre, il est possible de sp√©cifier soit une distribution de valeurs possibles, soit une liste de choix discrets (qui seront √©chantillonn√©s uniform√©ment) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "{\n",
    "    'C': scipy.stats.expon(scale=100),\n",
    "    'gamma': scipy.stats.expon(scale=.1),\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight':['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet exemple utilise le module `scipy.stats`, qui contient de nombreuses distributions utiles pour l'√©chantillonnage des param√®tres, telles que `expon`, `gamma`, `uniform`, `loguniform` ou `randint`.\n",
    "\n",
    "En principe, n'importe quelle fonction peut √™tre utilis√©e, pourvu qu'elle fournisse une m√©thode `rvs` (√©chantillonnage de variable al√©atoire) pour √©chantillonner une valeur. Un appel √† la fonction `rvs` doit fournir des √©chantillons al√©atoires ind√©pendants √† partir des valeurs de param√®tres possibles lors des appels cons√©cutifs.\n",
    "\n",
    "> **Attention:** Les distributions dans `scipy.stats` avant la version scipy 0.16 ne permettent pas de sp√©cifier un √©tat al√©atoire. √Ä la place, elles utilisent l'√©tat al√©atoire global de numpy, qui peut √™tre initialis√© via `np.random.seed` ou d√©fini √† l'aide de `np.random.set_state`. Cependant, √† partir de scikit-learn 0.18, le module [**`sklearn.model_selection`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) d√©finira l'√©tat al√©atoire fourni par l'utilisateur si scipy >= 0.16 est √©galement disponible.\n",
    "\n",
    "Pour les param√®tres continus, tels que `C` ci-dessus, il est important de sp√©cifier une distribution continue pour tirer pleinement parti de la randomisation. De cette fa√ßon, l'augmentation de `n_iter` conduira toujours √† une recherche plus fine.\n",
    "\n",
    "Une variable al√©atoire continue uniforme logarithmique est la version continue d'un param√®tre r√©parti logarithmiquement. Par exemple, pour sp√©cifier l'√©quivalent de `C` ci-dessus, on peut utiliser `loguniform(1, 100)` au lieu de `[1, 10, 100]`.\n",
    "\n",
    "En suivant l'exemple ci-dessus de recherche en grille, nous pouvons sp√©cifier une variable al√©atoire continue r√©partie de mani√®re logarithmique entre `1e0` et `1e3` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import loguniform\n",
    "{\n",
    "    'C': loguniform(1e0, 1e3),\n",
    "    'gamma': loguniform(1e-4, 1e-3),\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight':['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### [**Comparaison de la recherche al√©atoire et de la recherche en grille pour l'estimation d'hyperparam√®tres**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_randomized_search.ipynb)<br/>([_Comparing randomized search and grid search for hyperparameter estimation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html))\n",
    "\n",
    "Compare l'utilisation et l'efficacit√© de la recherche al√©atoire et de la recherche en grille."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©f√©rences\n",
    "\n",
    "üî¨ Bergstra, J. and Bengio, Y., [**‚ÄúRandom search for hyper-parameter optimization‚Äù**](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf), The Journal of Machine Learning Research (2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='searching-for-optimal-parameters-with-successive-halving'></a> 3.2.3. Searching for optimal parameters with successive halving\n",
    "\n",
    "Scikit-learn also provides the [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) and [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) estimators that can be used to search a parameter space using successive halving [1] [2]. Successive halving (SH) is like a tournament among candidate parameter combinations. SH is an iterative selection process where all candidates (the parameter combinations) are evaluated with a small amount of resources at the first iteration. Only some of these candidates are selected for the next iteration, which will be allocated more resources. For parameter tuning, the resource is typically the number of training samples, but it can also be an arbitrary numeric parameter such as `n_estimators` in a random forest.\n",
    "\n",
    "As illustrated in the figure below, only a subset of candidates ‚Äòsurvive‚Äô until the last iteration. These are the candidates that have consistently ranked among the top-scoring candidates across all iterations. Each iteration is allocated an increasing amount of resources per candidate, here the number of samples.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_successive_halving_iterations_001.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "We here briefly describe the main parameters, but each parameter and their interactions are described in more details in the sections below. The `factor` (> 1) parameter controls the rate at which the resources grow, and the rate at which the number of candidates decreases. In each iteration, the number of resources per candidate is multiplied by `factor` and the number of candidates is divided by the same factor. Along with `resource` and `min_resources`, factor is the most important parameter to control the search in our implementation, though a value of 3 usually works well. `factor` effectively controls the number of iterations in [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) and the number of candidates (by default) and iterations in [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html). `aggressive_elimination=True` can also be used if the number of available resources is small. More control is available through tuning the `min_resources` parameter.\n",
    "\n",
    "These estimators are still experimental: their predictions and their API might change without any deprecation cycle. To use them, you need to explicitly import `enable_halving_search_cv`:\n",
    "\n",
    "```python\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "```\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Comparison between grid search and successive halving\n",
    "#### Successive Halving Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='searching-for-optimal-parameters-with-successive-halving'></a> 3.2.3. Recherche des param√®tres optimaux avec le \"Successive Halving\"\n",
    "\n",
    "Scikit-learn propose √©galement les estimateurs [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) et [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) qui peuvent √™tre utilis√©s pour rechercher dans un espace de param√®tres en utilisant le \"Successive Halving\" [1] [2]. Le \"Successive Halving\" (SH) est comme un tournoi entre les combinaisons de param√®tres candidates. Le SH est un processus de s√©lection it√©ratif o√π toutes les combinaisons candidates (les combinaisons de param√®tres) sont √©valu√©es avec une petite quantit√© de ressources lors de la premi√®re it√©ration. Seules certaines de ces combinaisons candidates sont s√©lectionn√©es pour la prochaine it√©ration, qui b√©n√©ficiera de plus de ressources. Pour l'optimisation des param√®tres, la ressource est g√©n√©ralement le nombre d'√©chantillons d'entra√Ænement, mais elle peut √©galement √™tre un param√®tre num√©rique arbitraire tel que `n_estimators` dans une for√™t al√©atoire.\n",
    "\n",
    "Comme illustr√© dans la figure ci-dessous, seuls certains candidats \"survivent\" jusqu'√† la derni√®re it√©ration. Ce sont les candidats qui se sont constamment class√©s parmi les meilleurs candidats en termes de score lors de toutes les it√©rations. √Ä chaque it√©ration, une quantit√© croissante de ressources par candidat est allou√©e, ici le nombre d'√©chantillons.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_successive_halving_iterations_001.png\"\n",
    "    alt=\"Flux de travail de recherche en grille\"\n",
    "    style=\"max-width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "Nous d√©crivons bri√®vement ici les principaux param√®tres, mais chaque param√®tre et leurs interactions sont d√©crits plus en d√©tail dans les sections suivantes. Le param√®tre `factor` (> 1) contr√¥le le taux de croissance des ressources et le taux de diminution du nombre de candidats. √Ä chaque it√©ration, le nombre de ressources par candidat est multipli√© par `factor` et le nombre de candidats est divis√© par le m√™me facteur. Avec `resource` et `min_resources`, le param√®tre `factor` est le param√®tre le plus important pour contr√¥ler la recherche dans notre impl√©mentation, bien qu'une valeur de 3 fonctionne g√©n√©ralement bien. `factor` contr√¥le efficacement le nombre d'it√©rations dans [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) et le nombre de candidats (par d√©faut) et d'it√©rations dans [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html). `aggressive_elimination=True` peut √©galement √™tre utilis√© si le nombre de ressources disponibles est faible. Un contr√¥le plus pr√©cis est possible en ajustant le param√®tre `min_resources`.\n",
    "\n",
    "Ces estimateurs sont encore **exp√©rimentaux** : leurs pr√©dictions et leur API peuvent changer sans aucun cycle de d√©pr√©ciation. Pour les utiliser, vous devez importer explicitement `enable_halving_search_cv` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples\n",
    "\n",
    "#### [**Comparaison entre la recherche en grille et le \"Successive Halving\"**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_successive_halving_heatmap.ipynb)<br/>([_Comparison between grid search and successive halving_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_successive_halving_heatmap.html))\n",
    "\n",
    "#### [**It√©rations du \"Successive Halving\"**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_successive_halving_iterations.ipynb)<br/>([_Successive Halving Iterations_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_successive_halving_iterations.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='choosing-min-resources-and-the-number-of-candidates'></a> 3.2.3.1. Choix de `min_resources` et du nombre de candidats\n",
    "\n",
    "Outre le param√®tre `factor`, les deux principaux param√®tres qui influencent le comportement d'une recherche \"successive halving\" sont le param√®tre `min_resources` et le nombre de candidats (ou combinaisons de param√®tres) √©valu√©s. `min_resources` correspond √† la quantit√© de ressources allou√©es √† chaque candidat lors de la premi√®re it√©ration. Le nombre de candidats est sp√©cifi√© directement dans [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) et est d√©termin√© √† partir du param√®tre `param_grid` de [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html).\n",
    "\n",
    "Consid√©rons un cas o√π la ressource est le nombre d'√©chantillons et o√π nous avons 1000 √©chantillons. En th√©orie, avec `min_resources=10` et `factor=2`, nous pouvons effectuer **au maximum** 7 it√©rations avec le nombre d'√©chantillons suivant : `[10, 20, 40, 80, 160, 320, 640]`.\n",
    "\n",
    "Cependant, en fonction du nombre de candidats, nous pourrions ex√©cuter moins de 7 it√©rations : si nous commen√ßons avec un nombre **r√©duit** de candidats, la derni√®re it√©ration pourrait utiliser moins de 640 √©chantillons, ce qui signifie que toutes les ressources disponibles (√©chantillons) ne sont pas utilis√©es. Par exemple, si nous commen√ßons avec 5 candidats, nous n'avons besoin que de 2 it√©rations : 5 candidats pour la premi√®re it√©ration, puis `5 // 2 = 2` candidats √† la deuxi√®me it√©ration, apr√®s quoi nous saurons quel candidat est le meilleur (donc nous n'avons pas besoin d'une troisi√®me it√©ration). Nous n'utiliserions que 20 √©chantillons au maximum, ce qui serait une perte car nous avons 1000 √©chantillons √† disposition. D'autre part, si nous commen√ßons avec un nombre **√©lev√©** de candidats, nous pourrions nous retrouver avec beaucoup de candidats lors de la derni√®re it√©ration, ce qui peut ne pas toujours √™tre id√©al : cela signifie que de nombreux candidats fonctionneront avec toutes les ressources, r√©duisant ainsi essentiellement la proc√©dure √† une recherche standard.\n",
    "\n",
    "Dans le cas de [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html), le nombre de candidats est d√©fini par d√©faut de mani√®re √† ce que la derni√®re it√©ration utilise autant de ressources disponibles que possible. Pour [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html), le nombre de candidats est d√©termin√© par le param√®tre `param_grid`. Le fait de modifier la valeur de `min_resources` aura un impact sur le nombre d'it√©rations possibles et, par cons√©quent, aura √©galement un effet sur le nombre id√©al de candidats.\n",
    "\n",
    "Un autre facteur √† prendre en compte lors du choix de `min_resources` est de savoir s'il est facile ou non de distinguer entre les bons et les mauvais candidats avec une petite quantit√© de ressources. Par exemple, si vous avez besoin de beaucoup d'√©chantillons pour distinguer entre de bons et de mauvais param√®tres, il est recommand√© d'utiliser une valeur √©lev√©e pour `min_resources`. En revanche, si la distinction est claire m√™me avec une petite quantit√© d'√©chantillons, une petite valeur de `min_resources` peut √™tre pr√©f√©rable car cela acc√©l√©rerait le calcul.\n",
    "\n",
    "Remarquez dans l'exemple ci-dessus que la derni√®re it√©ration n'utilise pas la quantit√© maximale de ressources disponibles : 1000 √©chantillons sont disponibles, mais seuls 640 sont utilis√©s au maximum. Par d√©faut, √† la fois [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) et [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) essaient d'utiliser autant de ressources que possible lors de la derni√®re it√©ration, avec la contrainte que cette quantit√© de ressources doit √™tre un multiple √† la fois de `min_resources` et `factor` (cette contrainte sera expliqu√©e dans la prochaine section). [**`HalvingRandomSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html) atteint cet objectif en √©chantillonnant la bonne quantit√© de candidats, tandis que [**`HalvingGridSearchCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) y parvient en fixant correctement `min_resources`. Pour plus de d√©tails, veuillez consulter [**√âpuisement des ressources disponibles** (3.2.3.4)](https://scikit-learn.org/stable/modules/grid_search.html#exhausting-the-resources)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
