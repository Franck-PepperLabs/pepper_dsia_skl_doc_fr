{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\\. [**Transformations d'ensembles de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/6_dataset_transformations.ipynb)</br>([*Dataset transformations*](https://scikit-learn.org/stable/data_transforms.html))\n",
    "\n",
    "scikit-learn fournit une bibliothèque de transformateurs, qui peuvent nettoyer (voir [6.3. Prétraitement des données](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)), réduire (voir [6.5. Réduction de dimensionnalité non supervisée](https://scikit-learn.org/stable/modules/unsupervised_reduction.html#data-reduction)), étendre (voir [6.7. Approximation du noyau](https://scikit-learn.org/stable/modules/kernel_approximation.html#kernel-approximation)) ou générer (voir [6.2. Extraction de caractéristiques](https://scikit-learn.org/stable/modules/feature_extraction.html#feature-extraction)) des représentations d'entités.\n",
    "\n",
    "Comme d'autres estimateurs, ceux-ci sont représentés par des classes avec une méthode d'ajustement `fit`, qui apprend les paramètres du modèle (par exemple, la moyenne et l'écart type pour la normalisation) à partir d'un ensemble d'apprentissage, et une méthode de transformation `transform` qui applique ce modèle de transformation à de nouvelles données. `fit_transform` peut être plus pratique et efficace pour modéliser et transformer simultanément les données d'apprentissage.\n",
    "\n",
    "La combinaison de tels transformateurs, en parallèle ou en série, est traitée dans [6.1. Pipelines et estimateurs composites](https://scikit-learn.org/stable/modules/compose.html#combining-estimators). [6.8. Les métriques par paires, es Affinités et les Noyaux](https://scikit-learn.org/stable/modules/metrics.html#metrics) couvrent la transformation des espaces de caractéristiques en matrices d'affinité, tandis que la [6.9. transformation de la cible de prédiction (y)](https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets) considère les transformations de l'espace cible (par exemple, les étiquettes catégorielles) à utiliser dans scikit-learn.\n",
    "\n",
    "✔ 6.1. Pipelines et estimateurs composites\n",
    "* ✔ 6.1.1. Pipeline : estimateurs de chaînage\n",
    "* ✔ 6.1.2. Transformer la cible en régression\n",
    "* ✔ 6.1.3. FeatureUnion : espaces d'entités composites\n",
    "* ✔ 6.1.4. ColumnTransformer pour les données hétérogènes\n",
    "* ✔ 6.1.5. Visualisation des estimateurs composites\n",
    "\n",
    "✔ 6.2. Extraction de caractéristiques\n",
    "* ✔ 6.2.1. Chargement de caractéristiques à partir de dicts\n",
    "* ✔ 6.2.2. Hachage des caractéristiques\n",
    "* ✔ 6.2.3. Extraction de caractéristiques de texte\n",
    "* ✔ 6.2.4. Extraction de caractéristiques d'image\n",
    "\n",
    "6.3. Prétraitement des données\n",
    "* 6.3.1. Standardisation, ou suppression de la moyenne et mise à l'échelle de la variance\n",
    "* 6.3.2. Transformation non linéaire\n",
    "* 6.3.3. Normalisation\n",
    "* ✔ 6.3.4. Encodage des caractéristiques catégorielles\n",
    "* 6.3.5. Discrétisation\n",
    "* 6.3.6. Imputation des valeurs manquantes\n",
    "* 6.3.7. Génération de caractéristiques polynomiales\n",
    "* 6.3.8. Transformateurs personnalisés\n",
    "\n",
    "6.4. Imputation des valeurs manquantes\n",
    "* 6.4.1. Imputation univariée vs imputation multivariée\n",
    "* 6.4.2. Imputation de caractéristique univariée\n",
    "* 6.4.3. Imputation de caractéristiques multivariées\n",
    "* 6.4.4. Références\n",
    "* 6.4.5. Imputation des plus proches voisins\n",
    "* 6.4.6. Marquage des valeurs imputées\n",
    "* 6.4.7. Estimateurs qui gèrent les valeurs NaN\n",
    "\n",
    "6.5. Réduction de dimensionnalité non supervisée\n",
    "* 6.5.1. ACP : analyse en composantes principales\n",
    "* 6.5.2. Projections aléatoires\n",
    "* 6.5.3. Agglomération de caractéristiques\n",
    "\n",
    "6.6. Projection aléatoire\n",
    "* 6.6.1. Le lemme de Johnson-Lindenstrauss\n",
    "* 6.6.2. Projection aléatoire gaussienne\n",
    "* 6.6.3. Projection aléatoire clairsemée\n",
    "* 6.6.4. Transformation inverse\n",
    "\n",
    "6.7. Approximation du noyau\n",
    "* 6.7.1. Méthode Nystroem pour l'approximation du noyau\n",
    "* 6.7.2. Noyau de fonction de base radiale\n",
    "* 6.7.3. Additif Chi Squared Kernel\n",
    "* 6.7.4. Noyau au carré de chi asymétrique\n",
    "* 6.7.5. Approximation du noyau polynomial via Tensor Sketch\n",
    "* 6.7.6. Détails mathématiques\n",
    "\n",
    "6.8. Métriques par paires, affinités et noyaux\n",
    "* 6.8.1. Similitude cosinus\n",
    "* 6.8.2. Noyau linéaire\n",
    "* 6.8.3. Noyau polynomial\n",
    "* 6.8.4. Noyau sigmoïde\n",
    "* 6.8.5. Noyau RBF\n",
    "* 6.8.6. Noyau laplacien\n",
    "* 6.8.7. Noyau du chi carré\n",
    "\n",
    "✔ 6.9. Transformer la cible de prédiction (y)\n",
    "* ✔ 6.9.1. Binarisation des étiquettes\n",
    "* ✔ 6.9.2. Encodage des étiquettes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aff9e50adfaa9e30c910fb3872ffdc72747acb5f50803ca0504f00e980f7c25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
