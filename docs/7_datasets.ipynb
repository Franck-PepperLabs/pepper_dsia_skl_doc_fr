{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7\\. [**Utilitaires de chargement de jeux de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb)</br>([*Dataset loading utilities*](https://scikit-learn.org/stable/datasets.html))\n",
    "\n",
    "Le package `sklearn.datasets` intègre certains petits jeux de données de démonstration, comme introduits dans la section [**Premiers pas**](https://scikit-learn.org/stable/tutorial/basic/tutorial.html#loading-example-dataset).\n",
    "\n",
    "Ce package propose également des fonctions d'aide pour télécharger des jeux de données plus volumineux, couramment utilisés par la communauté de l'apprentissage automatique pour évaluer les algorithmes sur des données provenant du \"monde réel\".\n",
    "\n",
    "Pour évaluer l'impact de l'échelle du jeu de données (`n_samples` et `n_features`) tout en contrôlant les propriétés statistiques des données (typiquement la corrélation et l'informativité des caractéristiques), il est également possible de générer des données synthétiques.\n",
    "\n",
    "**API générale des jeux de données.** Il existe trois principaux types d'interfaces de jeux de données qui peuvent être utilisées pour obtenir des jeux de données en fonction du type souhaité.\n",
    "\n",
    "**Les chargeurs de jeux de données.** Ils permettent de charger de petits jeux de données standard, décrits dans la section [**Jeux de données jouets** (7.1)](https://scikit-learn.org/stable/datasets/toy_dataset.html).\n",
    "\n",
    "**Les téléchargeurs de jeux de données.** Ils permettent de télécharger et de charger des jeux de données plus volumineux, décrits dans la section [**Jeux de données du monde réel** (7.2)](https://scikit-learn.org/stable/datasets/real_world.html).\n",
    "\n",
    "Les fonctions de chargeurs et de téléchargeurs renvoient toutes deux un objet [**`Bunch`**](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html) contenant au moins deux éléments : un tableau de forme `n_samples * n_features` avec la clé `data` (sauf pour `20newsgroups`) et un tableau Numpy de longueur `n_samples` contenant les valeurs cibles, avec la clé `target`.\n",
    "\n",
    "L'objet Bunch est un dictionnaire qui expose ses clés en tant qu'attributs. Pour plus d'informations sur l'objet Bunch, consultez la documentation sur [**`Bunch`**](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html).\n",
    "\n",
    "Il est également possible, pour presque toutes ces fonctions, de contraindre la sortie à être un tuple contenant uniquement les données et la cible, en définissant le paramètre `return_X_y` sur `True`.\n",
    "\n",
    "Les jeux de données contiennent également une description complète dans leur attribut `DESCR` et certains contiennent `feature_names` et `target_names`. Consultez les descriptions des jeux de données ci-dessous pour plus de détails.\n",
    "\n",
    "**Les fonctions de génération de jeux de données.** Elles permettent de générer des jeux de données synthétiques contrôlés, décrits dans la section [**Jeux de données générés** (7.3)](https://scikit-learn.org/stable/datasets/sample_generators.html).\n",
    "\n",
    "Les fonctions de génération de jeux de données. Elles peuvent être utilisées pour générer des jeux de données synthétiques contrôlés, décrits dans la section \"Jeux de données générés\".\n",
    "\n",
    "Ces fonctions renvoient un tuple `(X, y)` composé d'un tableau Numpy `X` de forme `n_samples * n_features` et d'un tableau de longueur `n_samples` contenant les cibles `y`.\n",
    "\n",
    "De plus, il existe également des outils divers pour charger des jeux de données au format ou à partir d'emplacements autres, décrits dans la section [**Chargement d'autres jeux de données**](https://scikit-learn.org/stable/datasets/loading_other_datasets.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Volume** : 35 pages, 6 exemples, 28 papiers\n",
    "\n",
    "Attention, les exemples sont sous-estimés. Pour parcourir l'ensemble des exemples utilisant tel ou tel jeu de données intégré, consulter la page de documentation de chaque méthode de chargement.\n",
    "\n",
    "✔ 7.1. [**Jeux de données jouets**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#toy_dataset)\n",
    "([*Toy datasets*](https://scikit-learn.org/stable/datasets/toy_dataset.html))\n",
    "* **Volume** : 11 pages, 0 exemples, 22 papiers\n",
    "* ✔ 7.1.1. [**Jeu de données des plantes d'Iris**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#iris-plants-dataset)\n",
    "([*Iris plants dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-plants-dataset))\n",
    "* ✔ 7.1.2. [**Jeu de données sur le diabète**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#diabetes-dataset)\n",
    "([*Diabetes dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset))\n",
    "* ✔ 7.1.3. [**Jeu de données de reconnaissance optique de chiffres écrits à la main**](https://scikit-learn.org/stable/datasets/toy_dataset.html#optical-recognition-of-handwritten-digits-dataset)\n",
    "([*Optical recognition of handwritten digits dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#optical-recognition-of-handwritten-digits-dataset))\n",
    "* ✔ 7.1.4. [**Jeu de données de Linnerrud**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#linnerrud-dataset)\n",
    "([*Linnerrud dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#linnerrud-dataset))\n",
    "* ✔ 7.1.5. [**Jeu de données de reconnaissance de vins**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#wine-recognition-dataset)\n",
    "([*Wine recognition dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset))\n",
    "* ✔ 7.1.6. [**Jeu de données du Wisconsin pour le diagnostic du cancer du sein**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#breast-cancer-wisconsin-diagnostic-dataset)\n",
    "([*Breast cancer Wisconsin (diagnostic) dataset*](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset))\n",
    "\n",
    "✔ 7.2. [**Jeux de données du monde réel**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#real-world-datasets)\n",
    "([*Real world datasets*](https://scikit-learn.org/stable/datasets/real_world.html#real-world-datasets))\n",
    "* **Volume** : 15 pages, 5 exemples, 5 papiers\n",
    "* ✔ 7.2.1. [**Jeu de données des visages Olivetti**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-olivetti-faces-dataset)\n",
    "([*The Olivetti faces dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-olivetti-faces-dataset))\n",
    "* ✔ 7.2.2. [**Jeu de données de texte des 20 newsgroups**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-20-newsgroups-text-dataset)\n",
    "([*The 20 newsgroups text dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset))\n",
    "* ✔ 7.2.3. [**Jeu de données de reconnaissance faciale Labeled Faces in the Wild**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#the-labeled-faces-in-the-wild-face-recognition-dataset)\n",
    "([*The Labeled Faces in the Wild face recognition dataset*](https://scikit-learn.org/stable/datasets/real_world.html#the-labeled-faces-in-the-wild-face-recognition-dataset))\n",
    "* ✔ 7.2.4. [**Jeu de données des types de couverture forestière**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#forest-covertypes)\n",
    "([*Forest covertypes*](https://scikit-learn.org/stable/datasets/real_world.html#forest-covertypes))\n",
    "* ✔ 7.2.5. [**Jeu de données RCV1**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#rcv1-dataset)\n",
    "([*RCV1 dataset*](https://scikit-learn.org/stable/datasets/real_world.html#rcv1-dataset))\n",
    "* ✔ 7.2.6. [**Jeu de données Kddcup 99**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#kddcup-99-dataset)\n",
    "([*Kddcup 99 dataset*](https://scikit-learn.org/stable/datasets/real_world.html#kddcup-99-dataset))\n",
    "* ✔ 7.2.7. [**Jeu de données de l'immobilier californien**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#california-housing-dataset)\n",
    "([*California Housing dataset*](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset))\n",
    "\n",
    "✔ 7.3. [**Jeux de données générés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generated-datasets)\n",
    "([*Generated datasets*](https://scikit-learn.org/stable/datasets/sample_generators.html#generated-datasets))\n",
    "* **Volume** : 3 pages, 0 exemples, 0 papiers\n",
    "* ✔ 7.3.1. [**Générateurs pour la classification et le clustering**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-classification-and-clustering)\n",
    "([*Generators for classification and clustering*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-classification-and-clustering))\n",
    "* ✔ 7.3.2. [**Générateurs pour la régression**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-regression)\n",
    "([*Generators for regression*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-regression))\n",
    "* ✔ 7.3.3. [**Générateurs pour l'apprentissage de variétés**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-manifold-learning)\n",
    "([*Generators for manifold learning*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-manifold-learning))\n",
    "* ✔ 7.3.4. [**Générateurs pour la décomposition**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#generators-for-decomposition)\n",
    "([*Generators for decomposition*](https://scikit-learn.org/stable/datasets/sample_generators.html#generators-for-decomposition))\n",
    "\n",
    "✔ 7.4. [**Chargement d'autres jeux de données**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#loading-other-datasets)\n",
    "([*Loading other datasets*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#loading-other-datasets))\n",
    "* **Volume** : 6 pages, 1 exemples, 1 papiers\n",
    "* ✔ 7.4.1. [**Images d'exemple**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#sample-images)\n",
    "([*Sample images*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#sample-images))\n",
    "* ✔ 7.4.2. [**Jeux de données au format svmlight / libsvm**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#datasets-in-svmlight-libsvm-format)\n",
    "([*Datasets in svmlight / libsvm format*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#datasets-in-svmlight-libsvm-format))\n",
    "* ✔ 7.4.3. [**Téléchargement de jeux de données depuis le dépôt openml.org**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#downloading-datasets-from-the-openml-org-repository)\n",
    "([*Downloading datasets from the openml.org repository*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#downloading-datasets-from-the-openml-org-repository))\n",
    "* ✔ 7.4.4. [**Chargement depuis des jeux de données externes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/7_datasets.ipynb#loading-from-external-datasets)\n",
    "([*Loading from external datasets*](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#loading-from-external-datasets))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toy-datasets'></a> 7.1. Jeux de données jouets\n",
    "\n",
    "scikit-learn est livré avec quelques petits jeux de données standards qui ne nécessitent pas de téléchargement depuis un site externe.\n",
    "\n",
    "Ils peuvent être chargés à l'aide des fonctions suivantes :\n",
    "\n",
    "* [**`load_iris`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)`(*[, return_X_y, as_frame])` : Charge et renvoie le jeu de données iris (classification) [40 exemples].\n",
    "* [**`load_diabetes`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html)`(*[, return_X_y, as_frame, scaled])` : Charge et renvoie le jeu de données diabetes (régression) [15 exemples].\n",
    "* [**`load_digits`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)`(*[, n_class, return_X_y, as_frame])` : Charge et renvoie le jeu de données digits (classification) [27 exemples].\n",
    "* [**`load_linnerud`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html)`(*[, return_X_y, as_frame])` : Charge et renvoie le jeu de données Linnerud sur l'exercice physique [aucun exemple].\n",
    "* [**`load_wine`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)`(*[, return_X_y, as_frame])` : Charge et renvoie le jeu de données wine (classification) [3 exemples].\n",
    "* [**`load_breast_cancer`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)`(*[, return_X_y, as_frame])` : Charge et renvoie le jeu de données breast cancer wisconsin (classification) [3 exemples].\n",
    "\n",
    "Ces jeux de données sont utiles pour illustrer rapidement le comportement des différents algorithmes implémentés dans scikit-learn. Cependant, ils sont souvent trop petits pour être représentatifs des tâches d'apprentissage automatique du monde réel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='iris-plants-dataset'></a> 7.1.1. Jeu de données des plantes Iris\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "* **Nombre d'instances** : 150 (50 dans chacune des trois classes)\n",
    "* **Nombre d'attributs** : 4 attributs numériques prédictifs et la classe\n",
    "* **Informations sur les attributs** :\n",
    "    * longueur du sépale en cm\n",
    "    * largeur du sépale en cm\n",
    "    * longueur du pétale en cm\n",
    "    * largeur du pétale en cm\n",
    "    * classe :\n",
    "        * Iris-Setosa\n",
    "        * Iris-Versicolour\n",
    "        * Iris-Virginica\n",
    "* **Statistiques sommaires** :\n",
    "    * longueur du sépale : 4.3, 7.9, 5.84, 0.83, 0.7826\n",
    "    * largeur du sépale : 2.0, 4.4, 3.05, 0.43, -0.4194\n",
    "    * longueur du pétale : 1.0, 6.9, 3.76, 1.76, 0.9490  (élevé !)\n",
    "    * largeur du pétale : 0.1, 2.5, 1.20, 0.76, 0.9565  (élevé !)\n",
    "* **Valeurs manquantes** : Aucune\n",
    "* **Répartition des classes** : 33,3 % pour chacune des 3 classes.\n",
    "* **Créateur** : R.A. Fisher\n",
    "* **Donateur** : Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
    "* **Date** : Juillet 1988\n",
    "\n",
    "La célèbre [base de données Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set), utilisée pour la première fois par Sir [R.A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher). Le jeu de données est extrait de l'article de Fisher. Notez qu'il est identique à celui utilisé dans R, mais différent de celui du référentiel [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php), qui comporte deux points de données incorrects.\n",
    "\n",
    "Il s'agit peut-être de la base de données la plus connue dans la littérature de la reconnaissance de formes. L'article de Fisher est un classique dans le domaine et est encore fréquemment cité à ce jour (voir, par exemple, Duda & Hart). Le jeu de données contient 3 classes de 50 instances chacune, où chaque classe correspond à un type de plante iris. Une classe est linéairement séparable des deux autres ; ces dernières ne sont PAS linéairement séparables entre elles.\n",
    "\n",
    "### Références\n",
    "\n",
    "- Fisher, R.A. [“**The use of multiple measurements in taxonomic problems**](http://syllabus.cs.manchester.ac.uk/pgt/2021/COMP61021/reference/Fisher-DA.pdf)[”](https://drive.google.com/file/d/1GQ4BDycNnyCgqlB3nNVEEmf4Mw45YBk2/view?usp=drive_link) Annual Eugenics, 7, Part II, 179-188 (1936); également dans \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950).\n",
    "- <mark>[BOOK]</mark> Duda, R.O., & Hart, P.E. (1973) [“**Pattern Classification and Scene Analysis**](https://www.semanticscholar.org/paper/Pattern-classification-and-scene-analysis-Duda-Hart/b07ce649d6f6eb636872527104b0209d3edc8188)” (Q327.D83) John Wiley & Sons. ISBN 0-471-22361-1. Voir la page 218.\n",
    "- Dasarathy, B.V. (1980) [“**Nosing Around the Neighborhood: A New System Structure and Classification Rule for Recognition in Partially Exposed Environments**](https://www.computer.org/csdl/journal/tp/1980/01/04766972/13rRUIIVldy)[”](https://drive.google.com/file/d/1Qh0f9PhjrO2Zgyk9Nm7VJPgeUQBx7bz7/view?usp=drive_link).\n",
    "- Gates, G.W. (1972) [“**The Reduced Nearest Neighbor Rule**](https://sci2s.ugr.es/keel/pdf/algorithm/articulo/gates1972.pdf)[”](https://drive.google.com/file/d/1tlYe9MtAtqZi6JF2mqhWPnlcopFpJ0Jb/view?usp=drive_link). IEEE Transactions on Information Theory, May 1972, 431-433.\n",
    "- Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., and Freeman, D. 1988. [“**AUTOCLASS: A bayesian classification system**](https://www.semanticscholar.org/paper/AutoClass%3A-A-Bayesian-Classification-System-Cheeseman-Kelly/9f48079c278b02decf14f71b9f94c6ce1756940b)[”](https://drive.google.com/file/d/1zctxXudfRggAW4Mpoe9uPxaaFmiJTDOf/view?usp=drive_link) In Proceedings of the Fifth International Conference on Machine Learning (ICML-88), pp. 54–64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='diabetes-dataset'></a> 7.1.2. Jeu de données sur le diabète\n",
    "\n",
    "Dix variables de base, l'âge, le sexe, l'indice de masse corporelle, la pression artérielle moyenne et six mesures de sérum sanguin, ont été obtenues pour chacun des n = 442 patients atteints de diabète, ainsi que la variable d'intérêt, une mesure quantitative de la progression de la maladie un an après le début.\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "* **Nombre d'instances** : 442\n",
    "* **Nombre d'attributs** : Les 10 premières colonnes sont des valeurs prédictives numériques\n",
    "* **Cible** : La colonne 11 est une mesure quantitative de la progression de la maladie un an après le début\n",
    "* **Informations sur les attributs** :\n",
    "    * âge en années\n",
    "    * sexe\n",
    "    * indice de masse corporelle (IMC)\n",
    "    * pression artérielle moyenne\n",
    "    * s1 tc, cholestérol total du sérum sanguin\n",
    "    * s2 ldl, lipoprotéines de basse densité (LDL)\n",
    "    * s3 hdl, lipoprotéines de haute densité (HDL)\n",
    "    * s4 tch, cholestérol total / HDL\n",
    "    * s5 ltg, possiblement le logarithme du niveau de triglycérides sériques\n",
    "    * s6 glu, taux de sucre dans le sang\n",
    "\n",
    "Remarque : Chacune de ces 10 variables prédictives a été centrée sur la moyenne et mise à l'échelle par l'écart-type multiplié par la racine carrée de `n_samples` (c'est-à-dire que la somme des carrés de chaque colonne est égale à 1).\n",
    "\n",
    "URL source : https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "\n",
    "### Références\n",
    "\n",
    "- Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) [“**Least Angle Regression**](https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)[”](https://drive.google.com/file/d/1PiEY8K3fr7CiFGDrqsMIgx33j431nO3d/view?usp=drive_link), Annals of Statistics (with discussion), 407-499."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='optical-recognition-of-handwritten-digits-dataset'></a> 7.1.3. Jeu de données de reconnaissance optique des chiffres manuscrits\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "* **Nombre d'instances** : 1797\n",
    "* **Nombre d'attributs** : 64\n",
    "* **Informations sur les attributs** : Image 8x8 de pixels entiers dans la plage de 0 à 16.\n",
    "* **Valeurs d'attributs manquantes** : Aucune\n",
    "* **Créateur** : Alpaydin (alpaydin ‘@’ boun.edu.tr)\n",
    "* **Date** : Juillet 1998\n",
    "\n",
    "Il s'agit d'une copie de l'ensemble de test des jeux de données de chiffres manuscrits de l'UCI ML (https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits).\n",
    "\n",
    "Le jeu de données contient des images de chiffres manuscrits : 10 classes où chaque classe correspond à un chiffre.\n",
    "\n",
    "Des programmes de prétraitement mis à disposition par le NIST ont été utilisés pour extraire des images normalisées de chiffres manuscrits à partir d'un formulaire pré-imprimé. Sur un total de 43 personnes, 30 ont contribué à l'ensemble d'entraînement et 13 autres à l'ensemble de test. Les images de 32x32 pixels sont divisées en blocs non superposés de 4x4 pixels et le nombre de pixels allumés est compté dans chaque bloc. Cela génère une matrice d'entrée de 8x8 où chaque élément est un entier dans la plage de 0 à 16. Cela réduit la dimensionnalité et confère une invariance aux petites distorsions.\n",
    "\n",
    "Pour plus d'informations sur les routines de prétraitement du NIST, voir M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, [“**NIST Form-Based Handprint Recognition System**](https://www.semanticscholar.org/paper/NIST-form-based-handprint-recognition-system-Garris/d06230cc44f0c67c00121799751bc64e190ac798)[”](https://drive.google.com/file/d/1Txhzp-Lypw6dWZfvVJxdQVMKng7UxzJA/view?usp=drive_link), NISTIR 5469, 1994.\n",
    "\n",
    "### Références\n",
    "\n",
    "- M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, [“**NIST Form-Based Handprint Recognition System**](https://www.semanticscholar.org/paper/NIST-form-based-handprint-recognition-system-Garris/d06230cc44f0c67c00121799751bc64e190ac798)[”](https://drive.google.com/file/d/1Txhzp-Lypw6dWZfvVJxdQVMKng7UxzJA/view?usp=drive_link), NISTIR 5469, 1994.\n",
    "- C. Kaynak (1995) [“**Methods of Combining Multiple Classifiers and Their Applications to Handwritten Digit Recognition**](https://www.semanticscholar.org/paper/Methods-of-combining-multiple-classifiers-and-their-Xu-Krzy%C5%BCak/ec25da04ef7f09396ca00da3f9b5f2d9670cb6fc)[”](https://drive.google.com/file/d/1k9WPdLGye7aELn-GH7g-C0Wv-p-ADrPD/view?usp=drive_link), MSc Thesis, Institute of Graduate Studies in Science and Engineering, Bogazici University.\n",
    "- Alpaydin, C. Kaynak (1998) [“**Cascading Classifiers**](https://www.kybernetika.cz/content/1998/4/369/paper.pdf)[”](https://drive.google.com/file/d/1mfkx92CXNYxRQ6W-9ET-5yRuX96XQuPk/view?usp=drive_link), Kybernetika.\n",
    "- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. [“**Linear dimensionality reduction using relevance weighted LDA**](https://www.semanticscholar.org/paper/Linear-dimensionality-reduction-using-relevance-LDA-Tang-Suganthan/a380817fb24ff67ae988d4cb2326573f6b7ccb02)[”](https://drive.google.com/file/d/16-phdK_Kevv3IgvE5-nUDp08okgdRHEe/view?usp=drive_link). School of Electrical and Electronic Engineering Nanyang Technological University. 2005.\n",
    "- Claudio Gentile. [“**A New Approximate Maximal Margin Classification Algorithm**](https://www.jmlr.org/papers/volume2/gentile01a/gentile01a.pdf)[”](https://drive.google.com/file/d/1FPAOkg1HBwMEMcP_evQ3xWyw6k2hxB8r/view?usp=drive_link). NIPS. 2000."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='linnerrud-dataset'></a> 7.1.4. Jeu de données Linnerrud\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "* **Nombre d'instances** : 20\n",
    "* **Nombre d'attributs** : 3\n",
    "* **Valeurs d'attributs manquantes** : Aucune\n",
    "\n",
    "Le jeu de données Linnerrud est un jeu de données de régression multi-sortie. Il se compose de trois variables d'exercice (données) et de trois variables physiologiques (cibles) collectées auprès de vingt hommes d'âge moyen dans un club de fitness :\n",
    "* **Physiologique - Fichier CSV contenant 20 observations sur 3 variables physiologiques** :\n",
    "    * Poids, Tour de taille et Pouls.\n",
    "* **Exercice - Fichier CSV contenant 20 observations sur 3 variables d'exercice** :\n",
    "    * Tractions, Redressements assis et Sauts.\n",
    "\n",
    "### Références\n",
    "\n",
    "- <mark>[**BOOK**]</mark> Tenenhaus, M. (1998). [“**La régression PLS : théorie et pratique**”](https://www.editionstechnip.com/en/catalogue-detail/625/regression-pls-la.html). Paris : Éditions Technic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='wine-recognition-dataset'></a> 7.1.5. Jeu de données Wine Recognition\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "- **Nombre d'instances** : 178\n",
    "- **Nombre d'attributs** : 13 (numériques) + la classe\n",
    "- **Information sur les attributs**\n",
    "    - Les attributs représentent différentes mesures chimiques des vins.\n",
    "    - Alcohol (Alcool)\n",
    "    - Malic acid (Acide malique)\n",
    "    - Ash (Cendres)\n",
    "    - Alcalinity of ash (Alcalinité des cendres)\n",
    "    - Magnesium (Magnésium)\n",
    "    - Total phenols (Phénols totaux)\n",
    "    - Flavanoids (Flavonoïdes)\n",
    "    - Nonflavanoid phenols (Phénols non flavonoïdes)\n",
    "    - Proanthocyanins (Proanthocyanidines)\n",
    "    - Color intensity (Intensité de la couleur)\n",
    "    - Hue (Teinte)\n",
    "    - OD280/OD315 of diluted wines (OD280/OD315 des vins dilués)\n",
    "    - Proline\n",
    "- Il n'y a aucune valeur manquante dans le jeu de données.\n",
    "- **Répartition des classes** : class_0 (59), class_1 (71), class_2 (48).\n",
    "\n",
    "**Résumé statistique** :\n",
    "|Attribut|Minimum|Maximum|Moyenne|Écart type|\n",
    "|---|---|---|---|---|\n",
    "|Alcohol|11.0|14.8|13.0|0.8|\n",
    "|Malic Acid|0.74|5.80|2.34|1.12|\n",
    "|Ash|1.36|3.23|2.36|0.27|\n",
    "|Alcalinity of Ash|10.6|30.0|19.5|3.3|\n",
    "|Magnesium|70.0|162.0|99.7|14.3|\n",
    "|Total Phenols|0.98|3.88|2.29|0.63|\n",
    "|Flavanoids|0.34|5.08|2.03|1.00|\n",
    "|Nonflavanoid Phenols|0.13|0.66|0.36|0.12|\n",
    "|Proanthocyanins|0.41|3.58|1.59|0.57|\n",
    "|Colour Intensity|1.3|13.0|5.1|2.3|\n",
    "|Hue|0.48|1.71|0.96|0.23|\n",
    "|OD280/OD315 of diluted wines|1.27|4.00|2.61|0.71|\n",
    "|Proline|278|1680|746|315|\n",
    "\n",
    "Ce jeu de données est une copie des ensembles de données UCI ML Wine Recognition (https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data). Il présente les résultats d'une analyse chimique de vins cultivés dans la même région en Italie par trois producteurs différents. Il existe treize mesures différentes pour les différents constituants des trois types de vin.\n",
    "\n",
    "### Auteurs d'origine\n",
    "\n",
    "- Forina, M. et al, [“**PARVUS: An Extendible Package for Data Exploration, Classification and Correlation**](https://www.semanticscholar.org/paper/PARVUS%3A-An-extendable-package-of-programs-for-data-Vandeginste/582727b66f210d2399383d7d213941fde93e7143)[”](https://drive.google.com/file/d/1p8SmxxEfkH2RTdbET_bM1K4eyVucmL3w/view?usp=drive_link). Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.\n",
    "\n",
    "### Citation\n",
    "\n",
    "- Lichman, M. (2013). UCI Machine Learning Repository [https://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "### Références\n",
    "\n",
    "- S. Aeberhard, D. Coomans and O. de Vel, [“**Comparative analysis of statistical pattern recognition methods in high dimensional settings**](https://www.semanticscholar.org/paper/Comparative-analysis-of-statistical-pattern-methods-Aeberhard-Coomans/83dc3e4030d7b9fbdbb4bde03ce12ab70ca10528)[”](https://drive.google.com/file/d/1vRWkfHxs7QF_A8NDwHy3buKALch4C5E3/view?usp=drive_link), Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of Mathematics and Statistics, James Cook University of North Queensland. (Also submitted to Technometrics).\n",
    "\n",
    "Les données ont été utilisées avec de nombreuses autres pour comparer différents classificateurs. Les classes sont séparables, bien que seule la méthode RDA ait atteint une classification correcte à 100%. (RDA : 100%, QDA : 99,4%, LDA : 98,9%, 1NN : 96,1% (données transformées selon la z-transformation)) (Tous les résultats obtenus en utilisant la technique leave-one-out).\n",
    "\n",
    "- S. Aeberhard, D. Coomans and O. de Vel, [**“Improvements to the classification performance of RDA**](https://www.semanticscholar.org/paper/Improvements-to-the-classification-performance-of-Aeberhard-Coomans/19fcf3bd90af749db28390d751b6040466b03097)[”](https://drive.google.com/file/d/15iw0I_cLxGre-Va0LW8zwZFjrKyQprhE/view?usp=drive_link) Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of Mathematics and Statistics, James Cook University of North Queensland. (Also submitted to Journal of Chemometrics)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='wine-recognition-dataset'></a> 7.1.6. Jeu de données du cancer du sein du Wisconsin (diagnostic)\n",
    "\n",
    "Caractéristiques de l'ensemble de données :\n",
    "- **Nombre d'instances** : 569\n",
    "- **Nombre d'attributs** : 30 attributs numériques prédictifs et la classe\n",
    "- **Informations sur les attributs** :\n",
    "    - rayon (moyenne des distances du centre aux points sur le périmètre)\n",
    "    - texture (écart-type des valeurs d'échelle de gris)\n",
    "    - périmètre\n",
    "    - surface\n",
    "    - lissage (variation locale des longueurs de rayon)\n",
    "    - compacité (périmètre^2 / surface - 1.0)\n",
    "    - concavité (gravité des parties concaves du contour)\n",
    "    - points concaves (nombre de parties concaves du contour)\n",
    "    - symétrie\n",
    "    - dimension fractale (\"approximation de la ligne côtière\" - 1)\n",
    "\n",
    "Les moyennes, les erreurs standard et les \"pires\" ou les plus grandes valeurs (moyenne des trois pires/plus grandes valeurs) de ces caractéristiques ont été calculées pour chaque image, donnant ainsi 30 caractéristiques. Par exemple, le champ 0 correspond au rayon moyen, le champ 10 au rayon SE et le champ 20 au pire rayon.\n",
    "\n",
    "- **Classes** :\n",
    "    - WDBC-Maligne\n",
    "    - WDBC-Bénigne\n",
    "- **Valeurs manquantes d'attributs** : Aucune\n",
    "- **Répartition des classes** :\n",
    "    - 212 - Maligne\n",
    "    - 357 - Bénigne\n",
    "- **Créateurs** :\n",
    "    - Dr. William H. Wolberg\n",
    "    - W. Nick Street\n",
    "    - Olvi L. Mangasarian\n",
    "- **Donateur** : Nick Street\n",
    "- **Date** : Novembre 1995\n",
    "\n",
    "Il s'agit d'une copie des ensembles de données [UCI ML Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)). Les caractéristiques sont calculées à partir d'une image numérisée d'une aspiration à l'aiguille fine (FNA) d'une masse mammaire. Elles décrivent les caractéristiques des noyaux cellulaires présents dans l'image.\n",
    "\n",
    "Le plan de séparation décrit ci-dessus a été obtenu à l'aide de la méthode Multisurface Method-Tree (MSM-T) [K. P. Bennett, [**“Decision Tree Construction Via Linear Programming**](https://minds.wisconsin.edu/bitstream/handle/1793/59564/TR1067.pdf?sequence=1)[”](https://drive.google.com/file/d/1yxgViM7xsJfuCzNBRgRkMOzW96QqwSQf/view?usp=drive_link) Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], une méthode de classification qui utilise la programmation linéaire pour construire un arbre de décision. Les caractéristiques pertinentes ont été sélectionnées en effectuant une recherche exhaustive dans l'espace des 1 à 4 caractéristiques et des 1 à 3 plans de séparation.\n",
    "\n",
    "Le programme linéaire réel utilisé pour obtenir le plan de séparation dans l'espace tridimensionnel est décrit dans [K. P. Bennett et O. L. Mangasarian : [**“Robust Linear Programming Discrimination of Two Linearly Inseparable Sets**](https://minds.wisconsin.edu/bitstream/handle/1793/59538/TR1054.pdf;jsessionid=95537C3C7CFA33DA92F10133F54B2B09?sequence=1)[”](https://drive.google.com/file/d/138okBFIXGV495sxE1PfuQ0uUQiIbdZmZ/view?usp=drive_link), Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "Cette base de données est également disponible via le serveur FTP de l'UW CS :\n",
    "\n",
    "    ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "### Références\n",
    "\n",
    "- K. P. Bennett et O. L. Mangasarian : [**“Robust Linear Programming Discrimination of Two Linearly Inseparable Sets**](https://minds.wisconsin.edu/bitstream/handle/1793/59538/TR1054.pdf;jsessionid=95537C3C7CFA33DA92F10133F54B2B09?sequence=1)[”](https://drive.google.com/file/d/138okBFIXGV495sxE1PfuQ0uUQiIbdZmZ/view?usp=drive_link), Optimization Methods and Software 1, 1992, 23-34.\n",
    "- W.N. Street, W.H. Wolberg et O.L. Mangasarian. [**“Nuclear feature extraction for breast tumor diagnosis**](https://minds.wisconsin.edu/bitstream/handle/1793/59692/TR1131.pdf?sequence=1&isAllowed=y)[”](https://drive.google.com/file/d/16HuAA8m4mHrLTCgkPPlTlQ7daIZs4wob/view?usp=drive_link). IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
    "- O.L. Mangasarian, W.N. Street and W.H. Wolberg. [**“Breast Cancer Diagnosis and Prognosis via Linear Programming**](https://minds.wisconsin.edu/bitstream/handle/1793/64370/94-10.pdf?sequence=1)[”](https://drive.google.com/file/d/1pWddWQCCB3_zTLXgYmgS8z2ASLiXRtzE/view?usp=drive_link). Operations Research, 43(4), pages 570-577, July-August 1995.\n",
    "- W.H. Wolberg, W.N. Street, and O.L. Mangasarian. [**“Machine learning techniques to diagnose breast cancer from fine-needle aspirates**](https://pubmed.ncbi.nlm.nih.gov/8168063/)[”](https://drive.google.com/file/d/1ovmMtobsLQt1s2Hmjc_NtSjEFBMOSiHL/view?usp=drive_link). Cancer Letters 77 (1994) 163-171."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='real-world-datasets'></a> 7.2. Jeux de données du monde réel\n",
    "\n",
    "scikit-learn fournit des outils pour charger des jeux de données plus volumineux, en les téléchargeant si nécessaire.\n",
    "\n",
    "Ils peuvent être chargés à l'aide des fonctions suivantes :\n",
    "\n",
    "* [**`fetch_olivetti_faces`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html)`(*[, data_home, ...])` : Charge et renvoie le jeu de données des visages Olivetti d'AT&T (classification).\n",
    "* [**`fetch_20newsgroups`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html)`(*[, data_home, subset, ...])` : Charge les noms de fichiers et les données du jeu de données des 20 newsgroups (classification).\n",
    "* [**`fetch_20newsgroups_vectorized`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html)`(*[, subset, ...])` : Charge et vectorise le jeu de données des 20 newsgroups (classification).\n",
    "* [**`fetch_lfw_people`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)`(*[, data_home, funneled, ...])` : Charge le jeu de données des visages étiquetés \"Labeled Faces in the Wild\" (LFW) (classification).\n",
    "* [**`fetch_lfw_pairs`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html)`(*[, subset, data_home, ...])` : Charge le jeu de données des paires d'images étiquetées \"Labeled Faces in the Wild\" (LFW) (classification).\n",
    "* [**`fetch_covtype`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html)`(*[, data_home, ...])` : Charge le jeu de données \"covertype\" (classification).\n",
    "* [**`fetch_rcv1`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_rcv1.html)`(*[, data_home, subset, ...])` : Charge le jeu de données multilibellé RCV1 (classification).\n",
    "* [**`fetch_kddcup99`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_kddcup99.html)`(*[, subset, data_home, ...])` : Charge le jeu de données kddcup99 (classification).\n",
    "* [**`fetch_california_housing`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)`(*[, data_home, ...])` : Charge le jeu de données du logement en Californie (régression).\n",
    "\n",
    "Ces jeux de données sont utiles pour travailler sur des tâches d'apprentissage automatique plus réalistes. Ils offrent une plus grande taille et complexité que les jeux de données jouets précédemment mentionnés."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='the-olivetti-faces-dataset'></a> 7.2.1. Le jeu de données des visages Olivetti\n",
    "\n",
    "[Ce jeu de données contient un ensemble d'images de visages](https://cam-orl.co.uk/facedatabase.html) prises entre avril 1992 et avril 1994 aux laboratoires AT&T de Cambridge. La fonction [**`sklearn.datasets.fetch_olivetti_faces`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html) est la fonction de récupération/dépôt en cache des données qui télécharge l'archive de données depuis AT&T.\n",
    "\n",
    "Comme décrit sur le site web d'origine :\n",
    "\n",
    "Il y a dix images différentes de chacun des 40 sujets distincts. Pour certains sujets, les images ont été prises à différents moments, variant l'éclairage, les expressions faciales (yeux ouverts/fermés, sourire/pas de sourire) et les détails du visage (lunettes/pas de lunettes). Toutes les images ont été prises sur un arrière-plan sombre et homogène, avec les sujets en position verticale et frontale (avec une tolérance pour un léger mouvement latéral).\n",
    "\n",
    "Caractéristiques de l'ensemble de données :\n",
    "* **Classes** :  40\n",
    "* **Total des échantillons** : 400\n",
    "* **Dimensionnalité** : 4 096\n",
    "* **Caractéristiques** : réelles, comprises entre 0 et 1\n",
    "\n",
    "L'image est quantifiée en 256 niveaux de gris et stockée en tant qu'entiers non signés de 8 bits ; le chargeur les convertira en valeurs flottantes sur l'intervalle [0, 1], ce qui est plus facile à manipuler pour de nombreux algorithmes.\n",
    "\n",
    "La \"cible\" de cette base de données est un entier de 0 à 39 indiquant l'identité de la personne représentée ; cependant, avec seulement 10 exemples par classe, ce jeu de données relativement petit est plus intéressant d'un point de vue non supervisé ou semi-supervisé.\n",
    "\n",
    "Le jeu de données d'origine était composé d'images de taille 92 x 112, tandis que la version disponible ici est composée d'images de 64x64.\n",
    "\n",
    "Lors de l'utilisation de ces images, veuillez donner crédit aux laboratoires AT&T de Cambridge."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='the-20-newsgroups-text-dataset'></a> 7.2.2. Le jeu de données des textes \"20 newsgroups\"\n",
    "\n",
    "Le jeu de données \"20 newsgroups\" comprend environ 18000 messages de groupes de discussion répartis en 20 sujets, divisés en deux sous-ensembles : un pour l'entraînement (ou le développement) et un autre pour les tests (ou l'évaluation des performances). La division entre l'ensemble d'entraînement et l'ensemble de test est basée sur les messages postés avant et après une date spécifique.\n",
    "\n",
    "Ce module contient deux chargeurs. Le premier, [**`sklearn.datasets.fetch_20newsgroups`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html), renvoie une liste de textes bruts pouvant être utilisés avec des extracteurs de caractéristiques textuelles tels que [**`CountVectorizer`**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) avec des paramètres personnalisés afin d'extraire des vecteurs de caractéristiques. Le second, [**`sklearn.datasets.fetch_20newsgroups_vectorized`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html), renvoie des caractéristiques prêtes à l'emploi, c'est-à-dire qu'il n'est pas nécessaire d'utiliser un extracteur de caractéristiques.\n",
    "\n",
    "Caractéristiques de l'ensemble de données :\n",
    "* **Classes** : 20\n",
    "* **Total des échantillons** : 18 846\n",
    "* **Dimensionnalité** : 1\n",
    "* **Caractéristiques** : texte\n",
    "\n",
    "### <a id='usage'></a> 7.2.2.1. Utilisation\n",
    "\n",
    "La fonction [**`sklearn.datasets.fetch_20newsgroups`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) est une fonction de récupération/dépôt en cache des données qui télécharge l'archive de données depuis le [site web original des \"20 newsgroups\"](http://qwone.com/~jason/20Newsgroups/), extrait le contenu de l'archive dans le dossier `~/scikit_learn_data/20news_home` et appelle [**`sklearn.datasets.load_files`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html) sur le dossier de l'ensemble d'entraînement ou de test, ou les deux :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n['alt.atheism',\\n 'comp.graphics',\\n 'comp.os.ms-windows.misc',\\n 'comp.sys.ibm.pc.hardware',\\n 'comp.sys.mac.hardware',\\n 'comp.windows.x',\\n 'misc.forsale',\\n 'rec.autos',\\n 'rec.motorcycles',\\n 'rec.sport.baseball',\\n 'rec.sport.hockey',\\n 'sci.crypt',\\n 'sci.electronics',\\n 'sci.med',\\n 'sci.space',\\n 'soc.religion.christian',\\n 'talk.politics.guns',\\n 'talk.politics.mideast',\\n 'talk.politics.misc',\\n 'talk.religion.misc']\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(list(newsgroups_train.target_names))\n",
    "\n",
    "\"\"\"\n",
    "['alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données réelles se trouvent dans les attributs `filenames` et `target`. L'attribut `target` est l'indice entier de la catégorie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape\n",
    "# (11314,)\n",
    "newsgroups_train.target.shape\n",
    "# (11314,)\n",
    "newsgroups_train.target[:10]\n",
    "# array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de charger uniquement une sous-sélection des catégories en passant la liste des catégories à charger à la fonction [**`sklearn.datasets.fetch_20newsgroups`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = ['alt.atheism', 'sci.space']\n",
    "# newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "list(newsgroups_train.target_names)\n",
    "# ['alt.atheism', 'sci.space']\n",
    "newsgroups_train.filenames.shape\n",
    "# (1073,)\n",
    "newsgroups_train.target.shape\n",
    "# (1073,)\n",
    "newsgroups_train.target[:10]\n",
    "# array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='converting-text-to-vectors'></a> 7.2.2.2. Conversion du texte en vecteurs\n",
    "\n",
    "Pour alimenter les modèles prédictifs ou de regroupement avec les données textuelles, il est d'abord nécessaire de transformer le texte en vecteurs de valeurs numériques adaptées à l'analyse statistique. Cela peut être réalisé à l'aide des utilitaires de `sklearn.feature_extraction.text` comme le montre l'exemple suivant qui extrait des vecteurs [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf) à partir d'un sous-ensemble de 20news :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 34118)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape\n",
    "# (2034, 34118)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les vecteurs TF-IDF extraits sont particulièrement creux, avec une moyenne de 159 composantes non nulles par échantillon dans un espace de plus de 30000 dimensions (moins de 0,5 % de caractéristiques non nulles) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159.0132743362832"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.nnz / float(vectors.shape[0])\n",
    "# 159.01327..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`sklearn.datasets.fetch_20newsgroups_vectorized`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html) est une fonction qui renvoie des caractéristiques de comptage de jetons prêtes à l'emploi au lieu des noms de fichiers.\n",
    "\n",
    "### <a id='filtering-text-for-more-realistic-training'></a> 7.2.2.3. Filtrage du texte pour un entraînement plus réaliste\n",
    "\n",
    "Il est facile pour un classifieur de surajuster sur des éléments particuliers qui apparaissent dans les données des \"20 Newsgroups\", tels que les en-têtes des newsgroups. De nombreux classifieurs atteignent des scores F très élevés, mais leurs résultats ne se généralisent pas à d'autres documents qui ne proviennent pas de cette fenêtre temporelle.\n",
    "\n",
    "Par exemple, examinons les résultats d'un classifieur bayésien naïf multinomial, qui est rapide à entraîner et atteint un score F décent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821359240272957"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(vectors, newsgroups_train.target)\n",
    "# MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
    "\n",
    "pred = clf.predict(vectors_test)\n",
    "metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
    "# 0.88213..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(L'exemple [**Classification des documents textuels à l'aide de caractéristiques creuses**](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html) mélange les données d'entraînement et de test, au lieu de les segmenter par temps, et dans ce cas, le classifieur bayésien naïf multinomial obtient un score F beaucoup plus élevé de 0,88. Êtes-vous déjà suspicieux de ce qui se passe à l'intérieur de ce classifieur ?)\n",
    "\n",
    "Jetons un coup d'œil aux caractéristiques les plus informatives :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: edu it and in you that is of to the\n",
      "comp.graphics: edu in graphics it is for and of to the\n",
      "sci.space: edu it that is in and space to of the\n",
      "talk.religion.misc: not it you in is that and to of the\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.feature_log_prob_[i])[-10:]  # Issue: .coeff_ is not an attribute\n",
    "        print(f'{category}: {\" \".join(feature_names[top10])}')\n",
    "\n",
    "show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
    "# show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
    "# alt.atheism: edu it and in you that is of to the\n",
    "# comp.graphics: edu in graphics it is for and of to the\n",
    "# sci.space: edu it that is in and space to of the\n",
    "# talk.religion.misc: not it you in is that and to of the"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant voir beaucoup de choses auxquelles ces caractéristiques se sont surajustées :\n",
    "- Presque chaque groupe est distingué par la fréquence d'apparition des en-têtes tels que `NNTP-Posting-Host:` et `Distribution:`.\n",
    "- Une autre caractéristique importante concerne si l'expéditeur est affilié à une université, comme indiqué soit par leurs en-têtes, soit par leur signature.\n",
    "- Le mot \"article\" est une caractéristique importante, en fonction de la fréquence à laquelle les gens citent des messages précédents comme ceci : `\"Dans l'article [ID de l'article], [nom] <[adresse e-mail]> a écrit :\"`.\n",
    "- D'autres caractéristiques correspondent aux noms et adresses e-mail de certaines personnes qui publiaient à l'époque.\n",
    "\n",
    "Avec une telle abondance d'indices qui distinguent les groupes de discussion, les classifieurs n'ont pratiquement pas besoin d'identifier les sujets à partir du texte, et ils fonctionnent tous au même niveau élevé.\n",
    "\n",
    "Pour cette raison, les fonctions qui chargent les données des 20 Newsgroups fournissent un paramètre appelé **remove**, qui indique quelles informations supprimer de chaque fichier. **remove** devrait être un tuple contenant tout sous-ensemble de (`'headers'`, `'footers'`, `'quotes'`), indiquant de supprimer respectivement les en-têtes, les blocs de signature et les blocs de citation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    categories=categories\n",
    ")\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "pred = clf.predict(vectors_test)\n",
    "metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
    "# 0.77310..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce classifieur a perdu une grande partie de son score F, simplement parce que nous avons supprimé des métadonnées qui ont peu à voir avec la classification des sujets. Il perd encore plus si nous supprimons également ces métadonnées des données d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    categories=categories)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(vectors, newsgroups_train.target)\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "pred = clf.predict(vectors_test)\n",
    "metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
    "# 0.76995..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certains autres classifieurs s'en sortent mieux avec cette version plus difficile de la tâche. Essayez l'[**Exemple de pipeline pour l'extraction et l'évaluation des caractéristiques textuelles**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_text_feature_extraction.ipynb), avec et sans l'option `remove`, pour comparer les résultats.\n",
    "\n",
    "#### Considérations sur les données\n",
    "\n",
    "Les Cleveland Indians sont une équipe de baseball de la Major League basée à Cleveland, Ohio, aux États-Unis. En décembre 2020, il a été rapporté que _\"après plusieurs mois de discussions suscitées par la mort de George Floyd et une prise de conscience nationale sur la race et le colonialisme, les Cleveland Indians ont décidé de changer leur nom\"_. Le propriétaire de l'équipe, Paul Dolan, _\"a clairement indiqué que l'équipe ne fera pas de son surnom informel - la Tribu - son nouveau nom d'équipe\"_. _\"Ce ne sera pas un demi-pas loin des Indiens\"_, a déclaré Dolan. _\"Nous n'aurons pas un nom à thème amérindien.\"_\n",
    "\n",
    "https://www.mlb.com/news/cleveland-indians-team-name-change\n",
    "\n",
    "#### Recommandation\n",
    "\n",
    "- Lors de l'évaluation des classifieurs de texte sur les données des 20 Newsgroups, vous devriez supprimer les métadonnées liées aux groupes de discussion. Dans scikit-learn, vous pouvez le faire en définissant `remove=('headers', 'footers', 'quotes')`. Le score F sera plus bas car il est plus réaliste.\n",
    "- Ce jeu de données textuelles contient des données qui peuvent être inappropriées pour certaines applications de traitement du langage naturel (NLP). Un exemple est donné dans la section \"Considérations sur les données\" ci-dessus. Le défi avec l'utilisation des ensembles de données textuelles actuels en NLP pour des tâches telles que la complétion de phrases, le regroupement et d'autres applications, est que le texte qui est culturellement biaisé et inflammatoire va propager des biais. Cela doit être pris en compte lors de l'utilisation du jeu de données, de l'examen des résultats et le biais doit être documenté.\n",
    "\n",
    "#### Exemples\n",
    "\n",
    "#####  [**Exemple de pipeline pour l'extraction et l'évaluation des caractéristiques textuelles**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/3_model_selection/plot_grid_search_text_feature_extraction.ipynb)<br/>([_Sample pipeline for text feature extraction and evaluation_](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_text_feature_extraction.html))\n",
    "\n",
    "#####  [**Classification de documents textuels à l'aide de caractéristiques creuses**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/text/plot_document_classification_20newsgroups.ipynb)<br/>([_Classification of text documents using sparse features_](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html))\n",
    "\n",
    "#####  [**Comparaison de `FeatureHasher` et `DictVectorizer`**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/text/plot_hashing_vs_dict_vectorizer.ipynb)<br/>([_`FeatureHasher` and `DictVectorizer` Comparison_](https://scikit-learn.org/stable/auto_examples/text/plot_hashing_vs_dict_vectorizer.html))\n",
    "\n",
    "##### [**Regroupement de documents textuels à l'aide de k-means**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/text/plot_document_clustering.ipynb)<br/>([_Clustering text documents using k-means_](https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='the-labeled-faces-in-the-wild-face-recognition-dataset'></a> 7.2.3. L'ensemble de données de reconnaissance faciale Labeled Faces in the Wild\n",
    "\n",
    "Cet ensemble de données est une collection de photos JPEG de personnes célèbres collectées sur Internet. Tous les détails sont disponibles sur le site officiel :\n",
    "\n",
    "http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "Chaque photo est centrée sur un seul visage. La tâche typique s'appelle la vérification de visage : étant donné une paire de deux photos, un classifieur binaire doit prédire si les deux images représentent la même personne.\n",
    "\n",
    "Une autre tâche, la reconnaissance faciale ou l'identification faciale, consiste à identifier le nom d'une personne inconnue en se référant à une galerie de photos précédemment vues de personnes identifiées.\n",
    "\n",
    "La vérification de visage et la reconnaissance de visage sont des tâches généralement effectuées sur les résultats d'un modèle entraîné pour effectuer la détection de visage. Le modèle le plus populaire pour la détection de visage s'appelle Viola-Jones et est implémenté dans la bibliothèque OpenCV. Les visages LFW ont été extraits par ce détecteur de visage à partir de différents sites web.\n",
    "\n",
    "Caractéristiques de l'ensemble de données :\n",
    "* **Classes** : 5 749\n",
    "* **Total des échantillons** : 13 233\n",
    "* **Dimensionnalité** : 5 828\n",
    "* **Caractéristiques** : réelles, comprises entre 0 et 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3.1. Utilisation\n",
    "\n",
    "scikit-learn fournit deux chargeurs qui téléchargeront automatiquement, mettront en cache, analyseront les fichiers de métadonnées, décoderont les fichiers JPEG et convertiront les parties intéressantes en tableaux numpy mappés en mémoire. La taille de cet ensemble de données est supérieure à 200 Mo. Le premier chargement prend généralement plus de quelques minutes pour décoder entièrement la partie pertinente des fichiers JPEG en tableaux numpy. Si l'ensemble de données a été chargé une fois, les chargements suivants prennent moins de 200 ms en utilisant une version mappée en mémoire sur le disque dans le dossier `~/scikit_learn_data/lfw_home/` en utilisant `joblib`.\n",
    "\n",
    "Le premier chargeur est utilisé pour la tâche d'identification de visage : une tâche de classification multi-classe (donc un apprentissage supervisé) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ariel Sharon\n",
      "Colin Powell\n",
      "Donald Rumsfeld\n",
      "George W Bush\n",
      "Gerhard Schroeder\n",
      "Hugo Chavez\n",
      "Tony Blair\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "for name in lfw_people.target_names:\n",
    "    print(name)\n",
    "    \n",
    "# Ariel Sharon\n",
    "# Colin Powell\n",
    "# Donald Rumsfeld\n",
    "# George W Bush\n",
    "# Gerhard Schroeder\n",
    "# Hugo Chavez\n",
    "# Tony Blair"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La découpe par défaut est une forme rectangulaire autour du visage, en supprimant la plupart de l'arrière-plan :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_people.data.dtype\n",
    "# dtype('float32')\n",
    "\n",
    "lfw_people.data.shape\n",
    "# (1288, 1850)\n",
    "\n",
    "lfw_people.images.shape\n",
    "# (1288, 50, 37)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chacun des `1140` visages est attribué à un identifiant unique de personne dans le tableau `target` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_people.target.shape\n",
    "# (1288,)\n",
    "\n",
    "list(lfw_people.target[:10])\n",
    "# [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le deuxième chargeur est généralement utilisé pour la tâche de vérification de visage : chaque échantillon est une paire de deux images appartenant ou non à la même personne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_pairs\n",
    "lfw_pairs_train = fetch_lfw_pairs(subset='train')\n",
    "\n",
    "list(lfw_pairs_train.target_names)\n",
    "# ['Different persons', 'Same person']\n",
    "\n",
    "lfw_pairs_train.pairs.shape\n",
    "# (2200, 2, 62, 47)\n",
    "\n",
    "lfw_pairs_train.data.shape\n",
    "# (2200, 5828)\n",
    "\n",
    "lfw_pairs_train.target.shape\n",
    "# (2200,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les fonctions [**`sklearn.datasets.fetch_lfw_people`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html) et [**`sklearn.datasets.fetch_lfw_pairs`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html), il est possible d'obtenir une dimension supplémentaire avec les canaux de couleur RVB en passant `color=True`, dans ce cas, la forme sera `(2200, 2, 62, 47, 3)`.\n",
    "\n",
    "L'ensemble de données [**`sklearn.datasets.fetch_lfw_pairs`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html) est subdivisé en 3 sous-ensembles : l'ensemble `train` de développement, l'ensemble de `test` de développement et un ensemble de validation `10_folds` destiné à calculer les mesures de performance en utilisant une validation croisée à 10 plis.\n",
    "\n",
    "### Références\n",
    "\n",
    "[**“Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments**](http://vis-www.cs.umass.edu/lfw/lfw.pdf)[”](https://drive.google.com/file/d/1tSKBkVVBohARKjVnLnPXlgga00XAivqy/view?usp=drive_link) Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller. University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\n",
    "\n",
    "### 7.2.3.2. Exemples\n",
    "\n",
    "#### [**Exemple de reconnaissance faciale utilisant des eigenfaces et des SVMs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_data-science_practising/blob/main/Sklearn/examples/applications/plot_face_recognition.ipynb)<br/>([*Faces recognition example using eigenfaces and SVMs*](https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='forest-covertypes'></a> 7.2.4. Types de couverture forestière\n",
    "\n",
    "Les échantillons de cet ensemble de données correspondent à des parcelles de forêt de 30x30 m aux États-Unis, collectées dans le but de prédire le type de couverture de chaque parcelle, c'est-à-dire l'espèce d'arbre dominante. Il existe sept types de couverture, ce qui en fait un problème de classification multiclasse. Chaque échantillon comporte 54 caractéristiques, décrites sur la [page d'accueil de l'ensemble de données](https://archive.ics.uci.edu/dataset/31/covertype). Certaines caractéristiques sont des indicateurs booléens, tandis que d'autres sont des mesures discrètes ou continues.\n",
    "\n",
    "Caractéristiques de l'ensemble de données :\n",
    "* **Classes** : 7\n",
    "* **Total des échantillons** : 581 012\n",
    "* **Dimensionnalité** : 54\n",
    "* **Caractéristiques** : int\n",
    "\n",
    "La fonction [**`sklearn.datasets.fetch_covtype`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html) chargera l'ensemble de données \"covtype\" ; elle renvoie un objet de type \"Bunch\" similaire à un dictionnaire, avec la matrice de caractéristiques dans le membre `data` et les valeurs cibles dans `target`. Si l'argument facultatif `as_frame` est défini sur `True`, il renverra `data` et `target` sous forme de dataframe pandas, et il y aura un membre supplémentaire `frame` également. L'ensemble de données sera téléchargé depuis le web si nécessaire."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='rcv1-dataset'></a> 7.2.5. Ensemble de données RCV1\n",
    "\n",
    "Reuters Corpus Volume I (RCV1) est une archive de plus de 800 000 brèves catégorisées manuellement mises à disposition par Reuters, Ltd. à des fins de recherche. L'ensemble de données est décrit en détail dans [1].\n",
    "\n",
    "Caractéristiques de l'ensemble de données :\n",
    "* **Classes** : 103\n",
    "* **Total des échantillons** : 804 414\n",
    "* **Dimensionnalité** : 47 236\n",
    "* **Caractéristiques** : réel, entre 0 et 1\n",
    "\n",
    "La fonction [**`sklearn.datasets.fetch_rcv1`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_rcv1.html) chargera la version suivante : RCV1-v2, vecteurs, ensembles complets, multilabels de sujets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "rcv1 = fetch_rcv1()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elle renvoie un objet de type similaire à un dictionnaire, avec les attributs suivants :\n",
    "\n",
    "`data` : La matrice de caractéristiques est une matrice CSR creuse de scipy, avec 804414 échantillons et 47236 caractéristiques. Les valeurs non nulles contiennent des vecteurs de TF-IDF normalisés par cosinus et logarithmes. Une répartition presque chronologique est proposée dans [1] : Les premiers 23149 échantillons constituent l'ensemble d'entraînement. Les derniers 781265 échantillons constituent l'ensemble de test. Cela suit la répartition chronologique officielle LYRL2004. Le tableau a 0,16 % de valeurs non nulles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804414, 47236)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv1.data.shape\n",
    "# (804414, 47236)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target` : Les valeurs cibles sont stockées dans une matrice CSR clairsemée de scipy, avec 804414 échantillons et 103 catégories. Chaque échantillon a une valeur de 1 dans ses catégories et de 0 dans les autres. Le tableau a 3,15 % de valeurs non nulles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804414, 103)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv1.target.shape\n",
    "# (804414, 103)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_id` : Chaque échantillon peut être identifié par son ID, allant (avec des lacunes) de 2286 à 810596 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2286, 2287, 2288], dtype=uint32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv1.sample_id[:3]\n",
    "# array([2286, 2287, 2288], dtype=uint32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target_names` : Les valeurs cibles sont les sujets de chaque échantillon. Chaque échantillon appartient à au moins un sujet et jusqu'à 17 sujets. Il y a 103 sujets, chacun représenté par une chaîne de caractères. Leurs fréquences dans le corpus varient sur cinq ordres de grandeur, de 5 occurrences pour 'GMIL' à 381327 pour 'CCAT' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C11', 'C12', 'C13']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv1.target_names[:3].tolist()  \n",
    "# ['E11', 'ECAT', 'M11']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble de données sera téléchargé depuis la [**page d'accueil de rcv1**](https://jmlr.csail.mit.edu/papers/volume5/lewis04a/) si nécessaire. La taille compressée est d'environ 656 Mo.\n",
    "\n",
    "### Références\n",
    "\n",
    "[1] Lewis, D. D., Yang, Y., Rose, T. G., & Li, F. (2004). [**“RCV1: A New Benchmark Collection for Text Categorization Research**](https://www.jmlr.org/papers/volume5/lewis04a/lewis04a.pdf)[”](https://drive.google.com/file/d/1tf6QpZfXQPXf8fn1iD2JSte8h09P_twJ/view?usp=drive_link). The Journal of Machine Learning Research, 5, 361-397."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='kddcup-99-dataset'></a> 7.2.6. Jeu de données Kddcup 99\n",
    "\n",
    "Le jeu de données KDD Cup '99 a été créé en traitant les parties tcpdump du jeu de données d'évaluation du système de détection d'intrusion (IDS) DARPA 1998, créé par le MIT Lincoln Lab [2]. Les données artificielles (décrites sur la [page d'accueil du jeu de données](https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)) ont été générées à l'aide d'un réseau fermé et d'attaques injectées manuellement pour produire un grand nombre de types d'attaques différents, avec une activité normale en arrière-plan. Étant donné que l'objectif initial était de produire un grand ensemble d'entraînement pour des algorithmes d'apprentissage supervisé, il y a une proportion importante (80,1 %) de données anormales qui est irréaliste dans le monde réel et inappropriée pour la détection d'anomalies non supervisée qui vise à détecter des données « anormales », c'est-à-dire :\n",
    "- qualitativement différentes des données normales\n",
    "- en minorité importante parmi les observations.\n",
    "\n",
    "Nous transformons donc le jeu de données KDD en deux ensembles de données différents : SA et SF.\n",
    "- SA est obtenu en sélectionnant simplement toutes les données normales et une petite proportion de données anormales pour obtenir une proportion d'anomalies de 1 %.\n",
    "- SF est obtenu comme décrit dans [3] en sélectionnant simplement les données dont l'attribut `logged_in` est positif, se concentrant ainsi sur l'attaque par intrusion, ce qui donne une proportion de 0,3 % d'attaques.\n",
    "- `http` et `smtp` sont deux sous-ensembles de SF correspondant à la troisième caractéristique égale à 'http' (resp. à 'smtp').\n",
    "\n",
    "Structure générale de KDD :\n",
    "- **Total des échantillons** : 4898431\n",
    "- **Dimensionnalité** : 41\n",
    "- **Caractéristiques** : discrètes (entier) ou continues (flottant)\n",
    "- **Cibles** : str, 'normal.' ou nom du type d'anomalie\n",
    "\n",
    "Structure de SA :\n",
    "- **Total des échantillons** : 976 158\n",
    "- **Dimensionnalité** : 41\n",
    "- **Caractéristiques** : discrètes (entier) ou continues (flottant)\n",
    "- **Cibles** : str, 'normal.' ou nom du type d'anomalie\n",
    "\n",
    "Structure de SF :\n",
    "- **Total des échantillons** : 699 691\n",
    "- **Dimensionnalité** : 4\n",
    "- **Caractéristiques** : discrètes (entier) ou continues (flottant)\n",
    "- **Cibles** : str, 'normal.' ou nom du type d'anomalie\n",
    "\n",
    "Structure de http :\n",
    "- **Total des échantillons** : 619 052\n",
    "- **Dimensionnalité** : 3\n",
    "- **Caractéristiques** : discrètes (entier) ou continues (flottant)\n",
    "- **Cibles** : str, 'normal.' ou nom du type d'anomalie\n",
    "\n",
    "Structure de smtp :\n",
    "- **Total des échantillons** : 95 373\n",
    "- **Dimensionnalité** : 3\n",
    "- **Caractéristiques** : discrètes (entier) ou continues (flottant)\n",
    "- **Cibles** : str, 'normal.' ou nom du type d'anomalie\n",
    "\n",
    "La fonction [**`sklearn.datasets.fetch_kddcup99`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_kddcup99.html) chargera le jeu de données kddcup99 ; elle renvoie un objet de type dictionnaire avec la matrice de caractéristiques dans la propriété `data` et les valeurs cibles dans `target`. L'argument optionnel `as_frame` convertit `data` en un DataFrame pandas et `target` en une Series pandas. Le jeu de données sera téléchargé depuis le web si nécessaire.\n",
    "\n",
    "### Références\n",
    "\n",
    "[2] Analysis and Results of [**“The 1999 DARPA Off-Line Intrusion Detection Evaluation**](https://cs.fit.edu/~pkc/id/related/lippmann-cn00.pdf)[”](https://drive.google.com/file/d/173j17kvtJbg2ygFUbQmM7hGloQXBzoFL/view?usp=drive_link), Richard Lippmann, Joshua W. Haines, David J. Fried, Jonathan Korba, Kumar Das.\n",
    "\n",
    "[3] K. Yamanishi, J.-I. Takeuchi, G. Williams, and P. Milne. [**“Online unsupervised outlier detection using finite mixtures with discounting learning algorithms**](https://dl.acm.org/doi/10.1145/347090.347160)[”](https://drive.google.com/file/d/1VzgFnoewAn41LGw4UsJiev2h-7KIIqy4/view?usp=drive_link). In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 320-324. ACM Press, 2000."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='california-housing-dataset'></a> 7.2.7. Jeu de données California Housing\n",
    "\n",
    "Caractéristiques du jeu de données :\n",
    "- **Nombre d'instances** : 20 640\n",
    "- **Nombre d'attributs** : 8 attributs numériques prédictifs et la variable cible\n",
    "- **Informations sur les attributs** :\n",
    "    - `MedInc` : revenu médian dans le groupe de pâtés de maisons\n",
    "    - `HouseAge` : âge médian des maisons dans le groupe de pâtés de maisons\n",
    "    - `AveRooms` : nombre moyen de pièces par ménage\n",
    "    - `AveBedrms` : nombre moyen de chambres par ménage\n",
    "    - `Population` : population du groupe de pâtés de maisons\n",
    "    - `AveOccup` : nombre moyen de membres par ménage\n",
    "    - `Latitude` : latitude du groupe de pâtés de maisons\n",
    "    - `Longitude` : longitude du groupe de pâtés de maisons\n",
    "- **Valeurs manquantes pour les attributs** : Aucune\n",
    "\n",
    "Ce jeu de données a été obtenu à partir du référentiel StatLib. https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
    "\n",
    "La variable cible est la valeur médiane des maisons pour les districts de Californie, exprimée en centaines de milliers de dollars (100 000 $).\n",
    "\n",
    "Ce jeu de données a été dérivé du recensement américain de 1990, en utilisant une ligne par groupe de pâtés de maisons. Un groupe de pâtés de maisons est l'unité géographique la plus petite pour laquelle le Bureau du recensement des États-Unis publie des données d'échantillonnage (un groupe de pâtés de maisons a généralement une population de 600 à 3 000 personnes).\n",
    "\n",
    "Un ménage est un groupe de personnes résidant dans une habitation. Étant donné que le nombre moyen de pièces et de chambres dans ce jeu de données est fourni par ménage, ces colonnes peuvent prendre des valeurs étonnamment élevées pour les groupes de pâtés de maisons avec peu de ménages et beaucoup de maisons vides, comme les complexes touristiques.\n",
    "\n",
    "Il peut être téléchargé/chargé à l'aide de la fonction [**`sklearn.datasets.fetch_california_housing`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html).\n",
    "\n",
    "### Références\n",
    "\n",
    "- Pace, R. Kelley et Ronald Barry, [**“Sparse Spatial Autoregressions**](https://www.sciencedirect.com/science/article/abs/pii/S016771529600140X)[”](https://drive.google.com/file/d/1JefCYZkcdvPMEC4wimtOhXvSiTTfyYRR/view?usp=drive_link), Statistics and Probability Letters, 33 (1997) 291-297"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='generated-datasets'></a> 7.3. Jeux de données générés\n",
    "\n",
    "De plus, scikit-learn inclut divers générateurs d'échantillons aléatoires qui peuvent être utilisés pour créer des jeux de données artificiels de taille et de complexité contrôlées.\n",
    "\n",
    "## <a id='classification-clustering-generators'></a> 7.3.1. Générateurs pour la classification et le regroupement\n",
    "\n",
    "Ces générateurs produisent une matrice de caractéristiques et les cibles discrètes correspondantes.\n",
    "\n",
    "### <a id='single-label'></a> 7.3.1.1. Étiquette unique\n",
    "\n",
    "Les fonctions [**`make_blobs`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html) et [**`make_classification`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) créent des jeux de données multiclasse en allouant à chaque classe un ou plusieurs amas de points distribués selon une distribution normale. [**`make_blobs`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html) offre un meilleur contrôle sur les centres et les écarts-types de chaque amas, et est utilisée pour illustrer le regroupement. [**`make_classification`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) est spécialisée dans l'introduction de bruit par le biais de caractéristiques corrélées, redondantes et non informatives, de plusieurs amas gaussiens par classe, et de transformations linéaires de l'espace des caractéristiques.\n",
    "\n",
    "[**`make_gaussian_quantiles`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_gaussian_quantiles.html) divise un seul amas gaussien en classes de taille presque égale séparées par des hypersphères concentriques. [**`make_hastie_10_2`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_hastie_10_2.html#sklearn.datasets.make_hastie_10_2) génère un problème binaire similaire à 10 dimensions.\n",
    "\n",
    "![Exemple de jeu de données généré aléatoirement](https://scikit-learn.org/stable/_images/sphx_glr_plot_random_dataset_001.png)\n",
    "\n",
    "[**`make_circles`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html#sklearn.datasets.make_circles) et [**`make_moons`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) génèrent des jeux de données de classification binaire en 2D qui sont difficiles pour certains algorithmes (par exemple, le regroupement basé sur les centroïdes ou la classification linéaire), y compris un bruit gaussien optionnel. Ils sont utiles pour la visualisation. [**`make_circles`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html#sklearn.datasets.make_circles) produit des données gaussiennes avec une frontière de décision sphérique pour la classification binaire, tandis que [**`make_moons`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) produit deux demi-cercles entrelacés.\n",
    "\n",
    "### <a id='multilabel'></a> 7.3.1.2. Multietiquette\n",
    "\n",
    "[**`make_multilabel_classification`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_multilabel_classification.html#sklearn.datasets.make_multilabel_classification) génère des échantillons aléatoires avec plusieurs étiquettes, reflétant un sac de mots tirés d'un mélange de sujets. Le nombre de sujets pour chaque document est tiré d'une distribution de Poisson, et les sujets eux-mêmes sont tirés d'une distribution aléatoire fixe. De même, le nombre de mots est tiré de Poisson, avec des mots tirés d'une distribution multinomiale, où chaque sujet définit une distribution de probabilité sur les mots. Les simplifications par rapport aux véritables mélanges de sacs de mots comprennent :\n",
    "* Les distributions de mots par sujet sont tirées de manière indépendante, alors qu'en réalité, toutes seraient affectées par une distribution de base creuse et seraient corrélées.\n",
    "* Pour un document généré à partir de plusieurs sujets, tous les sujets sont pondérés de manière égale pour générer son sac de mots.\n",
    "* Les documents sans étiquettes tirent des mots au hasard, plutôt que d'une distribution de base.\n",
    "\n",
    "![Exemple de jeu de données multietiquette généré aléatoirement](https://scikit-learn.org/stable/_images/sphx_glr_plot_random_multilabel_dataset_001.png)\n",
    "\n",
    "### <a id='biclustering'></a> 7.3.1.3. Biclustering\n",
    "\n",
    "* [**`make_biclusters`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_biclusters.html)`(shape, n_clusters, *)` : Génère une structure en blocs diagonale constante pour le biclustering.\n",
    "* [**`make_checkerboard`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_checkerboard.html)`(shape, n_clusters, *)` : Génère un tableau avec une structure en damier de blocs pour le biclustering.\n",
    "\n",
    "## <a id='regression-generators'></a> 7.3.2. Générateurs pour la régression\n",
    "\n",
    "* [**`make_regression`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) produit des cibles de régression en tant que combinaison linéaire aléatoire, éventuellement parcimonieuse, de caractéristiques aléatoires, avec du bruit. Ses caractéristiques informatives peuvent être non corrélées ou de faible rang (quelques caractéristiques expliquent la plupart de la variance).\n",
    "\n",
    "D'autres générateurs de régression génèrent des fonctions de manière déterministe à partir de caractéristiques aléatoires. [**`make_sparse_uncorrelated`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_uncorrelated.html) produit une cible en tant que combinaison linéaire de quatre caractéristiques avec des coefficients fixes. D'autres encodent des relations explicitement non linéaires : [**`make_friedman1`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman1.html) est liée par des transformations polynomiales et trigonométriques ; [**`make_friedman2`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman2.html) inclut la multiplication et la réciprocité des caractéristiques ; et [**`make_friedman3`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman3.html) est similaire avec une transformation arctangente sur la cible.\n",
    "\n",
    "## <a id='manifold-learning-generators'></a> 7.3.3. Générateurs pour l'apprentissage des variétés\n",
    "\n",
    "* [**`make_s_curve`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_s_curve.html)`([n_samples, noise, random_state])` : Génère un jeu de données en forme de S.\n",
    "* [**`make_swiss_roll`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_swiss_roll.html)`([n_samples, noise, random_state])` : Génère un jeu de données en forme de \"Swiss roll\".\n",
    "\n",
    "## <a id='decomposition-generators'></a> 7.3.4. Générateurs pour la décomposition\n",
    "\n",
    "* [**`make_low_rank_matrix`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_low_rank_matrix.html)`([n_samples, ...])` : Génère une matrice principalement de faible rang avec des valeurs singulières en forme de cloche.\n",
    "* [**`make_sparse_coded_signal`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_coded_signal.html)`(n_samples, *, ...)` : Génère un signal sous forme de combinaison creuse d'éléments de dictionnaire.\n",
    "* [**`make_spd_matrix`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_spd_matrix.html)`(n_dim, *[, random_state])` : Génère une matrice symétrique définie positive aléatoire.\n",
    "* [**`make_sparse_spd_matrix`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_spd_matrix.html)`([dim, alpha, ...])` : Génère une matrice symétrique définie positive creuse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='loading-other-datasets'></a> 7.4. Chargement d'autres jeux de données\n",
    "\n",
    "## <a id='sample-images'></a> 7.4.1. Images d'échantillon\n",
    "\n",
    "Scikit-learn intègre également quelques images JPEG d'échantillon publiées sous licence Creative Commons par leurs auteurs. Ces images peuvent être utiles pour tester des algorithmes et des pipelines sur des données 2D.\n",
    "\n",
    "* [**`load_sample_images`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_images.html)`()` : Charge les images d'échantillon pour la manipulation d'images.\n",
    "* [**`load_sample_image`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_image.html)`(image_name)` : Charge le tableau Numpy d'une seule image d'échantillon.\n",
    "\n",
    "![Exemple de quantification des couleurs à l'aide de K-Means](https://scikit-learn.org/stable/_images/sphx_glr_plot_color_quantization_001.png)\n",
    "\n",
    "**Avertissement** : Le codage par défaut des images est basé sur le type de données `uint8` pour économiser de la mémoire. Souvent, les algorithmes d'apprentissage automatique fonctionnent mieux si l'entrée est d'abord convertie en une représentation en nombres flottants. De plus, si vous prévoyez d'utiliser `matplotlib.pyplot.imshow`, n'oubliez pas de mettre à l'échelle dans la plage 0 à 1, comme dans l'exemple suivant.\n",
    "\n",
    "### Exemples\n",
    "\n",
    "#### [**Quantification des couleurs à l'aide de K-Means**](https://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html#sphx-glr-auto-examples-cluster-plot-color-quantization-py)<br/>[_Color Quantization using K-Means_](https://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='datasets-in-svmlight-libsvm-format'></a> 7.4.2. Jeux de données au format `svmlight` / `libsvm`\n",
    "\n",
    "Scikit-learn inclut des fonctions utilitaires pour charger des jeux de données au format `svmlight` / `libsvm`. Dans ce format, chaque ligne prend la forme `<label> <id-de-caractéristique>:<valeur-de-caractéristique> <id-de-caractéristique>:<valeur-de-caractéristique> ...`. Ce format convient particulièrement aux jeux de données creux. Dans ce module, les matrices CSR éparses de Scipy sont utilisées pour `X` et les tableaux Numpy sont utilisés pour `y`.\n",
    "\n",
    "Vous pouvez charger un jeu de données comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "X_train, y_train = load_svmlight_file(\"/path/to/train_dataset.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez également charger deux (ou plusieurs) jeux de données en même temps :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_files\n",
    "X_train, y_train, X_test, y_test = load_svmlight_files(\n",
    "    (\"/chemin/vers/jeu_de_données_train.txt\", \"/chemin/vers/jeu_de_données_test.txt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cas, il est garanti que `X_train` et `X_test` ont le même nombre de caractéristiques. Une autre façon d'obtenir le même résultat est de fixer le nombre de caractéristiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_svmlight_file(\n",
    "    \"/path/to/test_dataset.txt\", n_features=X_train.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liens associés\n",
    "\n",
    "- Jeux de données publics au format `svmlight` / `libsvm` : https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets\n",
    "- Implémentation compatible avec l'API plus rapide : https://github.com/mblondel/svmlight-loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='downloading-datasets-from-the-openml-org-repository'></a> 7.4.3. Téléchargement d'ensembles de données à partir du référentiel `openml.org`\n",
    "\n",
    "`openml.org` est un référentiel public de données et d'expériences d'apprentissage automatique, qui permet à tout le monde de télécharger des ensembles de données ouverts.\n",
    "\n",
    "Le package `sklearn.datasets` est capable de télécharger des ensembles de données à partir du référentiel en utilisant la fonction [**`sklearn.datasets.fetch_openml`**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html).\n",
    "\n",
    "Par exemple, pour télécharger un ensemble de données d'expressions géniques dans les cerveaux de souris :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mice = fetch_openml(name='miceprotein', version=4, parser=\"auto\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour spécifier complètement un ensemble de données, vous devez fournir un nom et une version, bien que la version soit facultative, voir les Versions de l'ensemble de données (7.4.3.1) ci-dessous. L'ensemble de données contient un total de 1080 exemples appartenant à 8 classes différentes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice.data.shape\n",
    "# (1080, 77)\n",
    "mice.target.shape\n",
    "# (1080,)\n",
    "np.unique(mice.target)\n",
    "# array(['c-CS-m', 'c-CS-s', 'c-SC-m', 'c-SC-s', 't-CS-m', 't-CS-s', 't-SC-m', 't-SC-s'], dtype=object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez obtenir plus d'informations sur l'ensemble de données en consultant les attributs `DESCR` et `details` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mice.DESCR) \n",
    "# **Author**: Clara Higuera, Katheleen J. Gardiner, Krzysztof J. Cios\n",
    "# **Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression) - 2015\n",
    "# **Please cite**: Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing\n",
    "# Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down\n",
    "# Syndrome. PLoS ONE 10(6): e0129126...\n",
    "\n",
    "mice.details\n",
    "# {'id': '40966', 'name': 'MiceProtein', 'version': '4', 'format': 'ARFF',\n",
    "# 'upload_date': '2017-11-08T16:00:15', 'licence': 'Public',\n",
    "# 'url': 'https://www.openml.org/data/v1/download/17928620/MiceProtein.arff',\n",
    "# 'file_id': '17928620', 'default_target_attribute': 'class',\n",
    "# 'row_id_attribute': 'MouseID',\n",
    "# 'ignore_attribute': ['Genotype', 'Treatment', 'Behavior'],\n",
    "# 'tag': ['OpenML-CC18', 'study_135', 'study_98', 'study_99'],\n",
    "# 'visibility': 'public', 'status': 'active',\n",
    "# 'md5_checksum': '3c479a6885bfa0438971388283a1ce32'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le champ `DESCR` contient une description en texte libre des données, tandis que `details` contient un dictionnaire de métadonnées stockées par openml, tel que l'identifiant de l'ensemble de données. Pour plus de détails, voir la [documentation OpenML](https://docs.openml.org/#data). Le `data_id` de l'ensemble de données de protéines de souris est `40966`, et vous pouvez l'utiliser (ou le nom) pour obtenir plus d'informations sur l'ensemble de données sur le site openml :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice.url\n",
    "# 'https://www.openml.org/d/40966'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le `data_id` identifie également de manière unique un ensemble de données à partir de OpenML :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = fetch_openml(data_id=40966, parser=\"auto\")\n",
    "mice.details \n",
    "# {'id': '4550', 'name': 'MiceProtein', 'version': '1', 'format': 'ARFF',\n",
    "# 'creator': ...,\n",
    "# 'upload_date': '2016-02-17T14:32:49', 'licence': 'Public', 'url':\n",
    "# 'https://www.openml.org/data/v1/download/1804243/MiceProtein.ARFF', 'file_id':\n",
    "# '1804243', 'default_target_attribute': 'class', 'citation': 'Higuera C,\n",
    "# Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins\n",
    "# Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6):\n",
    "# e0129126. [Web Link] journal.pone.0129126', 'tag': ['OpenML100', 'study_14',\n",
    "# 'study_34'], 'visibility': 'public', 'status': 'active', 'md5_checksum':\n",
    "# '3c479a6885bfa0438971388283a1ce32'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='dataset-versions'></a> 7.4.3.1. Versions de l'ensemble de données\n",
    "\n",
    "Un ensemble de données est spécifié de manière unique par son identifiant de données (`data_id`), mais pas nécessairement par son nom. Plusieurs \"versions\" différentes d'un ensemble de données portant le même nom peuvent exister et peuvent contenir des ensembles de données entièrement différents. Si une version particulière d'un ensemble de données a été jugée problématique, elle peut être désactivée. En utilisant un nom pour spécifier un ensemble de données, la plus ancienne version encore active de l'ensemble de données sera utilisée. Cela signifie que `fetch_openml(name=\"miceprotein\", parser=\"auto\")` peut renvoyer des résultats différents à différents moments si des versions antérieures deviennent inactives. Vous pouvez voir que l'ensemble de données avec l'identifiant de données 40966 que nous avons récupéré ci-dessus est la première version de l'ensemble de données \"miceprotein\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice.details['version']  \n",
    "# '1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fait, cet ensemble de données n'a qu'une seule version. En revanche, l'ensemble de données iris a plusieurs versions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = fetch_openml(name=\"iris\", parser=\"auto\")\n",
    "iris.details['version']  \n",
    "# '1'\n",
    "iris.details['id']  \n",
    "# '61'\n",
    "\n",
    "iris_61 = fetch_openml(data_id=61, parser=\"auto\")\n",
    "iris_61.details['version']\n",
    "# '1'\n",
    "iris_61.details['id']\n",
    "# '61'\n",
    "\n",
    "iris_969 = fetch_openml(data_id=969, parser=\"auto\")\n",
    "iris_969.details['version']\n",
    "# '3'\n",
    "iris_969.details['id']\n",
    "# '969'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spécifier l'ensemble de données par le nom \"iris\" renvoie la version la plus basse, la version 1, avec le `data_id` 61. Pour vous assurer d'obtenir toujours cet ensemble de données exact, il est préférable de le spécifier par le `data_id` de l'ensemble de données. L'autre ensemble de données, avec le `data_id` 969, est la version 3 (la version 2 est devenue inactive) et contient une version binarisée des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(iris_969.target)\n",
    "# array(['N', 'P'], dtype=object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez également spécifier à la fois le nom et la version, ce qui identifie également de manière unique l'ensemble de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_version_3 = fetch_openml(name=\"iris\", version=3, parser=\"auto\")\n",
    "iris_version_3.details['version']\n",
    "# '3'\n",
    "iris_version_3.details['id']\n",
    "# '969'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Références\n",
    "\n",
    "- Vanschoren, van Rijn, Bischl and Torgo. [“**OpenML: networked science in machine learning**](https://arxiv.org/abs/1407.7722)[”](https://drive.google.com/file/d/1iqKrw3MOU4PXwYM0aT5oHJUmZ33TBWQZ/view?usp=drive_link) ACM SIGKDD Explorations Newsletter, 15(2), 49-60, 2014."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='arff-parser'></a> 7.4.3.2. Analyseur ARFF\n",
    "\n",
    "À partir de la version 1.2, scikit-learn propose un nouvel argument facultatif `parser` qui offre plusieurs options pour analyser les fichiers ARFF fournis par OpenML. L'analyseur hérité (c'est-à-dire `parser='liac-arff'`) est basé sur le projet [LIAC-ARFF](https://github.com/renatopp/liac-arff). Cependant, cet analyseur est lent et consomme plus de mémoire que nécessaire. Un nouvel analyseur basé sur pandas (c'est-à-dire `parser='pandas'`) est à la fois plus rapide et plus efficace en termes de mémoire. Cependant, cet analyseur ne prend pas en charge les données creuses. Par conséquent, nous recommandons d'utiliser `parser='auto'` qui utilisera le meilleur analyseur disponible pour l'ensemble de données demandé.\n",
    "\n",
    "Les analyseurs `\"pandas\"` et `\"liac-arff\"` peuvent produire des types de données différents en sortie. Les différences notables sont les suivantes :\n",
    "- L'analyseur `\"liac-arff\"` encode toujours les caractéristiques catégorielles en objets `str`. En revanche, l'analyseur `\"pandas\"` infère le type pendant la lecture et les catégories numériques sont converties en entiers lorsque c'est possible.\n",
    "- L'analyseur `\"liac-arff\"` utilise `float64` pour encoder les caractéristiques numériques étiquetées `\"REAL\"` et `\"NUMERICAL\"` dans les métadonnées. L'analyseur `\"pandas\"`, quant à lui, détermine si ces caractéristiques numériques correspondent à des entiers et utilise le dtype étendu Integer de pandas.\n",
    "- En particulier, les ensembles de données de classification avec des catégories entières sont généralement chargés tels quels `(0, 1, ...)` avec l'analyseur `\"pandas\"`, tandis que `\"liac-arff\"` force l'utilisation d'étiquettes de classe encodées en tant que chaînes, telles que `\"0\"`, `\"1\"`, et ainsi de suite.\n",
    "- L'analyseur `\"pandas\"` ne supprime pas les guillemets simples - c'est-à-dire `'` - des colonnes de chaînes de caractères. Par exemple, une chaîne `'ma chaîne'` sera conservée telle quelle, tandis que l'analyseur `\"liac-arff\"` supprimera les guillemets simples. Pour les colonnes catégorielles, les guillemets simples sont supprimés des valeurs.\n",
    "\n",
    "De plus, lorsque `as_frame=False` est utilisé, l'analyseur `\"liac-arff\"` renvoie des données codées de manière ordonnée où les catégories sont fournies dans l'attribut `categories` de l'instance `Bunch`. En revanche, `\"pandas\"` renvoie un tableau NumPy avec les catégories. Ensuite, il revient à l'utilisateur de concevoir un pipeline d'ingénierie des caractéristiques avec une instance de `OneHotEncoder` ou `OrdinalEncoder`, généralement enveloppée dans un `ColumnTransformer` pour prétraiter explicitement les colonnes catégorielles. Voir par exemple : [**Column Transformer with Mixed Types**](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='loading-from-external-datasets'></a> 7.4.4. Chargement à partir de jeux de données externes\n",
    "\n",
    "Scikit-learn fonctionne avec toutes les données numériques stockées sous forme de tableaux NumPy ou de matrices creuses Scipy. D'autres types de données convertibles en tableaux numériques, tels que les objets DataFrame de Pandas, sont également acceptables.\n",
    "\n",
    "Voici quelques méthodes recommandées pour charger des données tabulaires standard dans un format utilisable par scikit-learn :\n",
    "- [pandas.io](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) fournit des outils pour lire des données à partir de formats courants tels que CSV, Excel, JSON et SQL. Les DataFrames peuvent également être construits à partir de listes de tuples ou de dictionnaires. Pandas gère les données hétérogènes de manière transparente et propose des outils de manipulation et de conversion en un tableau numérique adapté à Scikit-learn.\n",
    "- [scipy.io](https://docs.scipy.org/doc/scipy/reference/io.html) est spécialisé dans les formats binaires couramment utilisés dans le contexte du calcul scientifique, tels que `.mat` et `.arff`.\n",
    "- [numpy/routines.io](https://numpy.org/doc/stable/reference/routines.io.html) pour le chargement standard de données tabulaires dans des tableaux Numpy.\n",
    "- `datasets.load_svmlight_file` de Scikit-learn pour le format svmlight ou le format creux libSVM.\n",
    "- `datasets.load_files` de Scikit-learn pour les répertoires de fichiers texte, où le nom de chaque répertoire correspond au nom de chaque catégorie et chaque fichier à l'intérieur de chaque répertoire correspond à un échantillon de cette catégorie.\n",
    "\n",
    "Pour certaines données diverses telles que les images, les vidéos et l'audio, vous pouvez vous référer à :\n",
    "- [skimage.io](https://scikit-image.org/docs/dev/api/skimage.io.html) ou [Imageio](https://imageio.readthedocs.io/en/stable/reference/core_v3.html) pour charger des images et des vidéos dans des tableaux Numpy.\n",
    "- [scipy.io.wavfile.read](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html) pour lire des fichiers WAV dans un tableau Numpy.\n",
    "\n",
    "Les caractéristiques catégorielles (ou nominales) stockées sous forme de chaînes de caractères (courantes dans les objets DataFrame de pandas) devront être converties en caractéristiques numériques à l'aide de [**`OneHotEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), [**`OrdinalEncoder`**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) ou des méthodes similaires. Voir la section [**Prétraitement des données** (6.3)](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n",
    "\n",
    "**Note** : si vous gérez vos propres données numériques, il est recommandé d'utiliser un format de fichier optimisé tel que HDF5 pour réduire les temps de chargement des données. Diverses bibliothèques comme H5Py, PyTables et Pandas fournissent une interface Python pour la lecture et l'écriture de données dans ce format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aff9e50adfaa9e30c910fb3872ffdc72747acb5f50803ca0504f00e980f7c25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
