{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='supervised-learning'></a> 1. [**Apprentissage supervis√©**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/1_supervised_learning.ipynb#supervised-learning)</br>([*Supervised learning*](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning))\n",
    "\n",
    "# <a id='probability-calibration'></a> 1.16. [**√âtalonnage de probabilit√©**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/1_16_calibration.ipynb)<br/>([_Probability calibration_](https://scikit-learn.org/stable/modules/calibration.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "- **Volume** : 6 pages, 4 exemples, 8 papiers\n",
    "- 1.16.1. [**Courbes d'√©talonnage**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/1_16_calibration.ipynb#calibration-curves)<br/>([_Calibration curves_](https://scikit-learn.org/stable/modules/calibration.html#calibration-curves))\n",
    "- 1.16.2. [**√âtalonnage d'un classifieur**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/1_16_calibration.ipynb#calibrating-a-classifier)<br/>([_Calibrating a classifier_](https://scikit-learn.org/stable/modules/calibration.html#calibrating-a-classifier))\n",
    "- 1.16.3. [**Utilisation**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/1_16_calibration.ipynb#usage)<br/>([_Usage_](https://scikit-learn.org/stable/modules/calibration.html#usage))\n",
    "    - 1.16.3.1. [**Sigmo√Øde**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/1_16_calibration.ipynb#sigmoid)<br/>([_Sigmoid_](https://scikit-learn.org/stable/modules/calibration.html#isotonic))\n",
    "    - 1.16.3.2. [**Isotone**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/1_16_calibration.ipynb#sigmoid)<br/>([_Isotonic_](https://scikit-learn.org/stable/modules/calibration.html#isotonic))\n",
    "    - 1.16.3.3. [**Support multi-classes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/1_16_calibration.ipynb#multiclass-support)<br/>([_Multiclass support_](https://scikit-learn.org/stable/modules/calibration.html#multiclass-support))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='probability-calibration'></a> 1.16. **√âtalonnage de probabilit√©**<br/>([_Probability calibration_](https://scikit-learn.org/stable/modules/calibration.html))\n",
    "\n",
    "Lorsque vous effectuez une classification, vous souhaitez souvent non seulement pr√©dire l'√©tiquette de classe, mais aussi obtenir une probabilit√© de l'√©tiquette respective. Cette probabilit√© vous donne une sorte de confiance dans la pr√©diction. Certains mod√®les peuvent vous donner de mauvaises estimations des probabilit√©s de classe, et certains ne prennent m√™me pas en charge la pr√©diction de probabilit√© (par exemple, certaines instances de [**`SGDClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)). Le module d'√©talonnage vous permet d'√©talonner plus finement les probabilit√©s d'un mod√®le donn√© ou d'ajouter la prise en charge de la pr√©diction de probabilit√©.\n",
    "\n",
    "Les classifieurs bien √©talonn√©s sont des classifieurs probabilistes pour lesquels la sortie de la m√©thode [**`predict_proba`**](https://scikit-learn.org/stable/glossary.html#term-predict_proba) peut √™tre directement interpr√©t√©e comme un niveau de confiance. Par exemple, un classifieur binaire bien √©talonn√© devrait classer les √©chantillons de telle sorte que parmi les √©chantillons auxquels il a attribu√© une valeur de `predict_proba` proche, disons, de 0,8, environ 80 % appartiennent r√©ellement √† la classe positive.\n",
    "\n",
    "Avant de montrer comment r√©-√©talonner un classifieur, nous avons d'abord besoin d'une m√©thode pour d√©tecter √† quel point un classifieur est bien √©talonn√©.\n",
    "\n",
    "> **Remarque :** Les r√®gles d'√©valuation strictement appropri√©es pour les pr√©dictions probabilistes, telles que [**`sklearn.metrics.brier_score_loss`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss) et [**`sklearn.metrics.log_loss`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss), √©valuent simultan√©ment l'√©talonnage (la fiabilit√©) et la puissance discriminatoire (la r√©solution) d'un mod√®le, ainsi que le caract√®re al√©atoire des donn√©es (l'incertitude). Cela d√©coule de la fameuse d√©composition de Murphy du score de Brier [1]. Comme le terme dominant n'est pas clairement identifiable, le score est d'une utilit√© limit√©e pour √©valuer l'√©talonnage seul (√† moins que l'on ne calcule chaque terme de la d√©composition). Une perte de Brier plus faible, par exemple, ne signifie pas n√©cessairement un mod√®le mieux √©talonn√©, et pourrait m√™me signifier un mod√®le moins bien √©talonn√© avec beaucoup plus de puissance discriminatoire, par exemple en utilisant de nombreuses autres caract√©ristiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='calibration-curves'></a> 1.16.1. **Courbes d'√©talonnage**<br/>([_Calibration curves_](https://scikit-learn.org/stable/modules/calibration.html#calibration-curves))\n",
    "\n",
    "Les courbes d'√©talonnage, √©galement appel√©es _diagrammes de fiabilit√©_ (Wilks 1995 [2]), permettent de comparer la qualit√© de l'√©talonnage des pr√©dictions probabilistes d'un classifieur binaire. Elles tracent la fr√©quence de l'√©tiquette positive (plus pr√©cis√©ment, une estimation de la _probabilit√© conditionnelle d'un √©v√©nement_ $P(Y=1|\\text{predict\\_proba})$) sur l'axe des ordonn√©es par rapport √† la probabilit√© pr√©dite [**`predict_proba`**](https://scikit-learn.org/stable/glossary.html#term-predict_proba) d'un mod√®le sur l'axe des abscisses. La partie d√©licate consiste √† obtenir des valeurs pour l'axe des ordonn√©es. Dans scikit-learn, cela est accompli en regroupant les pr√©dictions de mani√®re √† ce que l'axe des abscisses repr√©sente la probabilit√© pr√©dite moyenne dans chaque groupe. L'axe des ordonn√©es est alors la _fraction de positifs_ √©tant donn√© les pr√©dictions de ce groupe, c'est-√†-dire la proportion d'√©chantillons dont la classe est la classe positive (dans chaque groupe).\n",
    "\n",
    "Le graphique de la courbe d'√©talonnage sup√©rieure est cr√©√© avec [**`CalibrationDisplay.from_estimator`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibrationDisplay.html#sklearn.calibration.CalibrationDisplay.from_estimator), qui utilise [**`calibration_curve`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html#sklearn.calibration.calibration_curve) pour calculer les probabilit√©s moyennes pr√©dites par groupe et la fraction de positifs. [**`CalibrationDisplay.from_estimator`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibrationDisplay.html#sklearn.calibration.CalibrationDisplay.from_estimator) prend en entr√©e un classifieur ajust√©, qui est utilis√© pour calculer les probabilit√©s pr√©dites. Le classifieur doit donc avoir une m√©thode `predict_proba`. Pour les rares classifieurs qui n'ont pas de m√©thode [**predict_proba**](https://scikit-learn.org/stable/glossary.html#term-predict_proba), il est possible d'utiliser [**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV) pour √©talonner les sorties du classifieur en probabilit√©s.\n",
    "\n",
    "L'histogramme inf√©rieur donne un aper√ßu du comportement de chaque classifieur en montrant le nombre d'√©chantillons dans chaque groupe de probabilit√©s pr√©dites.\n",
    "\n",
    "<div style=\"background-color: white; color: black; text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_compare_calibration_001.png\"\n",
    "    alt=\"Courbes d'√©talonnage\"\n",
    "    style=\"max-width: 75%; height; auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`LogisticRegression`**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) retourne par d√©faut des pr√©dictions bien √©talonn√©es, car il poss√®de une fonction de liaison canonique pour sa perte, c'est-√†-dire la fonction de liaison logit pour la [**Perte logarithmique** (3.3.2.12)](https://scikit-learn.org/stable/modules/model_evaluation.html#log-loss). Cela conduit √† ce que l'on appelle la **propri√©t√© d'√©quilibre**, voir [8] et [**R√©gression logistique** (1.1.11)](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression). En revanche, les autres mod√®les pr√©sent√©s renvoient des probabilit√©s biais√©es, avec des biais diff√©rents pour chaque mod√®le.\n",
    "\n",
    "[**`GaussianNB`**](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) (Naive Bayes) a tendance √† pousser les probabilit√©s vers 0 ou 1 (notez les d√©comptes dans les histogrammes). Cela est principalement d√ª au fait qu'il suppose que les caract√©ristiques sont conditionnellement ind√©pendantes √©tant donn√© la classe, ce qui n'est pas le cas dans cet ensemble de donn√©es qui contient 2 caract√©ristiques redondantes.\n",
    "\n",
    "[**`RandomForestClassifier`**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) montre un comportement oppos√© : les histogrammes montrent des pics de probabilit√©s d'environ 0,2 et 0,9, tandis que les probabilit√©s proches de 0 ou 1 sont tr√®s rares. Niculescu-Mizil et Caruana [3] en donnent une interpr√©tation : _\"Les m√©thodes telles que le bagging et les for√™ts al√©atoires qui moyennent les pr√©dictions √† partir d'un ensemble de mod√®les de base peuvent avoir des difficult√©s √† faire des pr√©dictions pr√®s de 0 et 1, car la variance des mod√®les de base sous-jacents biaisera les pr√©dictions qui devraient √™tre pr√®s de z√©ro ou de un, les √©loignant de ces valeurs. √âtant donn√© que les pr√©dictions sont limit√©es √† l'intervalle [0,1], les erreurs caus√©es par la variance ont tendance √† √™tre unilat√©rales pr√®s de z√©ro et de un. Par exemple, si un mod√®le devrait pr√©dire p = 0 pour un cas, la seule fa√ßon pour le bagging d'y parvenir est que tous les arbres mis en sac pr√©disent z√©ro. Si nous ajoutons du bruit aux arbres sur lesquels repose le bagging, ce bruit fera que certains arbres pr√©disent des valeurs sup√©rieures √† 0 pour ce cas, d√©pla√ßant ainsi la pr√©diction moyenne de l'ensemble mis en sac loin de z√©ro. Nous observons cet effet de mani√®re plus marqu√©e avec les for√™ts al√©atoires car les arbres de niveau de base form√©s avec les for√™ts al√©atoires ont une variance relativement √©lev√©e en raison de la s√©lection de caract√©ristiques.\"_ En cons√©quence, la courbe d'√©talonnage montre une forme sigmo√Øde caract√©ristique, indiquant que le classifieur pourrait avoir davantage confiance en son \"intuition\" et renvoyer des probabilit√©s g√©n√©ralement plus proches de 0 ou 1.\n",
    "\n",
    "[**`LinearSVC`**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) (SVC) montre une courbe encore plus sigmo√Øde que la for√™t al√©atoire, ce qui est typique des m√©thodes √† marge maximale (comparez avec Niculescu-Mizil et Caruana [3]), qui se concentrent sur les √©chantillons difficiles √† classer qui sont proches de la fronti√®re de d√©cision (les vecteurs de support)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='calibrating-a-classifier'></a> 1.16.2. **√âtalonnage d'un classifieur**<br/>([_Calibrating a classifier_](https://scikit-learn.org/stable/modules/calibration.html#calibrating-a-classifier))\n",
    "\n",
    "L'√©talonnage d'un classifieur consiste √† ajuster un r√©gresseur (appel√© √©talonneur) qui fait correspondre la sortie du classifieur (telle qu'elle est fournie par la m√©thode [**`decision_function`**](https://scikit-learn.org/stable/glossary.html#term-decision_function) ou [**`predict_proba`**](https://scikit-learn.org/stable/glossary.html#term-predict_proba)) √† une probabilit√© √©talonn√©e dans l'intervalle $[0, 1]$. En notant la sortie du classifieur pour un √©chantillon donn√© par $f_i$, l'√©talonneur tente de pr√©dire la probabilit√© conditionnelle de l'√©v√©nement $P(y_i = 1 | f_i)$.\n",
    "\n",
    "Id√©alement, l'√©talonneur est ajust√© sur un ensemble de donn√©es ind√©pendant de l'ensemble d'entra√Ænement utilis√© pour ajuster le classifieur en premier lieu. Cela est d√ª au fait que les performances du classifieur sur ses donn√©es d'entra√Ænement seraient meilleures que pour de nouvelles donn√©es. Utiliser la sortie du classifieur des donn√©es d'entra√Ænement pour ajuster l'√©talonneur aboutirait ainsi √† un √©talonneur biais√© qui renverrait des probabilit√©s plus proches de 0 et 1 qu'il ne le devrait."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='usage'></a> 1.16.3. **Utilisation**<br/>([_Usage_](https://scikit-learn.org/stable/modules/calibration.html#usage))\n",
    "\n",
    "La classe [**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV) est utilis√©e pour √©talonner un classifieur.\n",
    "\n",
    "[**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV) utilise une approche de validation crois√©e pour garantir que des donn√©es non biais√©es sont toujours utilis√©es pour ajuster l'√©talonneur. Les donn√©es sont divis√©es en $k$ couples `(train_set, test_set)` (tels que d√©termin√©s par `cv`). Lorsque `ensemble=True` (par d√©faut), la proc√©dure suivante est r√©p√©t√©e ind√©pendamment pour chaque division de validation crois√©e : un clone de `base_estimator` est d'abord entra√Æn√© sur le sous-ensemble d'entra√Ænement. Ensuite, ses pr√©dictions sur le sous-ensemble de test sont utilis√©es pour ajuster un √©talonneur (un r√©gresseur sigmo√Øde ou isotone). Cela r√©sulte en un ensemble de $k$ couples `(classifieur, √©talonneur)` o√π chaque √©talonneur fait correspondre la sortie de son classifieur correspondant dans l'intervalle $[0, 1]$. Chaque couple est expos√© dans l'attribut `calibrated_classifiers_`, o√π chaque entr√©e est un classifieur √©talonn√© avec une m√©thode [**`predict_proba`**](https://scikit-learn.org/stable/glossary.html#term-predict_proba) qui renvoie des probabilit√©s √©talonn√©es. La sortie de `predict_proba` pour l'instance principale de [**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV) correspond √† la moyenne des probabilit√©s pr√©dites des $k$ estimateurs de la liste `calibrated_classifiers_`. La sortie de `predict` est la classe ayant la probabilit√© la plus √©lev√©e.\n",
    "\n",
    "Lorsque `ensemble=False`, la validation crois√©e est utilis√©e pour obtenir des pr√©dictions \"non biais√©es\" pour l'ensemble des donn√©es, via [**`cross_val_predict`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict). Ces pr√©dictions non biais√©es sont ensuite utilis√©es pour entra√Æner l'√©talonneur. L'attribut `calibrated_classifiers_` se compose uniquement d'un couple `(classifieur, √©talonneur)` o√π le classifieur est le `base_estimator` entra√Æn√© sur l'ensemble des donn√©es. Dans ce cas, la sortie de [**`predict_proba`**](https://scikit-learn.org/stable/glossary.html#term-predict_proba) pour [**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV) correspond aux probabilit√©s pr√©dites obtenues √† partir de l'unique couple `(classifieur, √©talonneur)`.\n",
    "\n",
    "Le principal avantage de `ensemble=True` est de b√©n√©ficier de l'effet d'ensemble traditionnel (similaire √† [**Bagging meta-estimator** (1.11.3)](https://scikit-learn.org/stable/modules/ensemble.html#bagging)). L'ensemble r√©sultant devrait √† la fois √™tre bien √©talonn√© et l√©g√®rement plus pr√©cis qu'avec `ensemble=False`. Le principal avantage de l'utilisation de `ensemble=False` est d'ordre calculatoire : cela r√©duit le temps d'ajustement global en n'entra√Ænant qu'une seule paire de classifieur de base et d'√©talonneur, r√©duit la taille du mod√®le final et augmente la vitesse de pr√©diction.\n",
    "\n",
    "En outre, un classifieur d√©j√† ajust√© peut √™tre √©talonn√© en d√©finissant `cv=\"prefit\"`. Dans ce cas, les donn√©es ne sont pas divis√©es et l'ensemble des donn√©es est utilis√© pour ajuster le r√©gresseur. Il revient √† l'utilisateur de s'assurer que les donn√©es utilis√©es pour l'ajustement du classifieur sont disjointes des donn√©es utilis√©es pour l'ajustement du r√©gresseur.\n",
    "\n",
    "[**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV) prend en charge l'utilisation de deux techniques de r√©gression pour l'√©talonnage via le param√®tre `method` : `\"sigmoid\"` et `\"isotonic\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='sigmoid'></a> 1.16.3.1. **Sigmo√Øde**<br/>([_Sigmoid_](https://scikit-learn.org/stable/modules/calibration.html#isotonic))\n",
    "\n",
    "Le r√©gresseur sigmo√Øde, `method=\"sigmoid\"`, est bas√© sur le mod√®le logistique de Platt [4] :\n",
    "\n",
    "$$p(y_i = 1 | f_i) = \\frac{1}{1 + \\exp(A f_i + B)} \\,,$$\n",
    "\n",
    "o√π $y_i$ est la v√©ritable √©tiquette de l'√©chantillon $i$ et $f_i$ est la sortie du classifieur non √©talonn√© pour l'√©chantillon $i$. Les valeurs r√©elles de $A$ et $B$ sont d√©termin√©es lors de l'ajustement du r√©gresseur par maximum de vraisemblance.\n",
    "\n",
    "La m√©thode sigmo√Øde suppose que la [**courbe d'√©talonnage** (1.16.1)](https://scikit-learn.org/stable/modules/calibration.html#calibration-curve) peut √™tre corrig√©e en appliquant une fonction sigmo√Øde aux pr√©dictions brutes. Cette hypoth√®se a √©t√© justifi√©e empiriquement dans le cas des [**Machines √† Vecteurs de Support** (1.4)](https://scikit-learn.org/stable/modules/svm.html#svm) avec des fonctions noyau courantes sur divers jeux de donn√©es de r√©f√©rence √† la section 2.1 de Platt 1999 [4], mais cela ne s'applique pas n√©cessairement en g√©n√©ral. De plus, le mod√®le logistique fonctionne mieux si l'erreur d'√©talonnage est sym√©trique, c'est-√†-dire que la sortie du classifieur pour chaque classe binaire suit une distribution normale avec la m√™me variance [7]. Cela peut poser probl√®me pour des probl√®mes de classification fortement d√©s√©quilibr√©s, o√π les sorties n'ont pas une variance √©gale.\n",
    "\n",
    "En g√©n√©ral, cette m√©thode est la plus efficace pour les petites tailles d'√©chantillons ou lorsque le mod√®le non √©talonn√© manque de confiance et pr√©sente des erreurs d'√©talonnage similaires pour des sorties √©lev√©es et faibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='isotonic'></a> 1.16.3.2. **Isotone**<br/>([_Isotonic_](https://scikit-learn.org/stable/modules/calibration.html#isotonic))\n",
    "\n",
    "\n",
    "La m√©thode `method=\"isotonic\"` ajuste un r√©gresseur isotone non param√©trique, qui g√©n√®re une fonction croissante par morceaux, consultez [**`sklearn.isotonic`**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.isotonic). Il minimise :\n",
    "\n",
    "$$\\sum_{i=1}^{n} (y_i - \\hat{f}_i)^2$$\n",
    "\n",
    "sous r√©serve que $\\hat{f}_i \\geq \\hat{f}_j$ chaque fois que $f_i \\geq f_j$. $y_i$ est la v√©ritable √©tiquette de l'√©chantillon $i$ et $\\hat{f}_i$ est la sortie du classifieur √©talonn√© pour l'√©chantillon $i (c'est-√†-dire la probabilit√© √©talonn√©e). Cette m√©thode est plus g√©n√©rale que `\"sigmoid\"` car la seule restriction est que la fonction de correspondance soit monotone. Elle est donc plus puissante car elle peut corriger toute distorsion monotone du mod√®le non √©talonn√©. Cependant, elle est plus sujette au surajustement, en particulier sur de petits ensembles de donn√©es [6].\n",
    "\n",
    "Dans l'ensemble, `\"isotonic\"` donnera des performances aussi bonnes, voire meilleures, que `\"sigmoid\"` lorsqu'il y a suffisamment de donn√©es (plus de ~ 1000 √©chantillons) pour √©viter le surajustement [3].\n",
    "\n",
    "> **Remarque :** Impact sur les m√©triques de classement telles que l'AUC  \n",
    "> En g√©n√©ral, on s'attend √† ce que l'√©talonnage n'affecte pas les m√©triques de classement telles que l'ROC-AUC. Cependant, ces m√©triques peuvent diff√©rer apr√®s √©talonnage lors de l'utilisation de `method=\"isotonic\"` car la r√©gression isotone introduit des √©galit√©s dans les probabilit√©s pr√©dites. Cela peut √™tre interpr√©t√© comme une incertitude des pr√©dictions du mod√®le. Si vous souhaitez strictement conserver le classement et donc les scores AUC, utilisez `method=\"logistic\"`, qui est une transformation strictement monotone qui pr√©serve donc le classement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='multiclass-support'></a> 1.16.3.3. **Support multi-classes**<br/>([_Multiclass support_](https://scikit-learn.org/stable/modules/calibration.html#multiclass-support))\n",
    "\n",
    "Les r√©gresseurs isotone et sigmo√Øde prennent en charge uniquement les donn√©es √† une dimension (par exemple, la sortie d'une classification binaire), mais sont √©tendus pour la classification multi-classes si le `base_estimator` prend en charge les pr√©dictions multi-classes. Pour les pr√©dictions multi-classes, [**`CalibratedClassifierCV`**](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV) effectue l'√©talonnage pour chaque classe s√©par√©ment dans le style [**`OneVsRestClassifier`** (1.12.1.2)](https://scikit-learn.org/stable/modules/multiclass.html#ovr-classification) [5]. Lors de la pr√©diction des probabilit√©s, les probabilit√©s √©talonn√©es pour chaque classe sont pr√©dites s√©par√©ment. Comme ces probabilit√©s ne sont pas n√©cessairement normalis√©es de mani√®re √† ce que leur somme soit √©gale √† un, un post-traitement est effectu√© pour les normaliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemples\n",
    "\n",
    "### [**Courbes d'√©talonnage de probabilit√©**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_16_calibration/plot_calibration_curve.ipynb)<br/>([_Probability Calibration curves_](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html))\n",
    "\n",
    "### [**√âtalonnage de probabilit√© pour une classification √† 3 classes**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_16_calibration/plot_calibration_multiclass.ipynb)<br/>([_Probability Calibration for 3-class classification_](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_multiclass.html))\n",
    "\n",
    "### [**√âtalonnage des probabilit√©s des classifieurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_16_calibration/plot_calibration.ipynb)<br/>([_Probability calibration of classifiers_](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration.html))\n",
    "\n",
    "### [**Comparaison de l'√©talonnage de classifieurs**](https://nbviewer.org/github/Franck-PepperLabs/pepper_dsia_skl_doc_fr/blob/main/docs/examples/1_16_calibration/plot_compare_calibration.ipynb)<br/>([_Comparison of Calibration of Classifiers_](https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©f√©rences\n",
    "\n",
    "üî¨ [1] Allan H. Murphy (1973). [**‚ÄúA New Vector Partition of the Probability Score‚Äù**](https://journals.ametsoc.org/downloadpdf/journals/apme/12/4/1520-0450_1973_012_0595_anvpot_2_0_co_2.pdf) Journal of Applied Meteorology and Climatology\n",
    "\n",
    "üî¨ [2] [**‚ÄúOn the combination of forecast probabilities for consecutive precipitation periods‚Äù**](https://journals.ametsoc.org/downloadpdf/journals/wefo/5/4/1520-0434_1990_005_0640_otcofp_2_0_co_2.xml). Wea. Forecasting, 5, 640‚Äì650., Wilks, D. S., 1990a\n",
    "\n",
    "üî¨ [3] (1,2,3) [**‚ÄúPredicting Good Probabilities With Supervised Learning‚Äù**](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.7135&rep=rep1&type=pdf), A. Niculescu-Mizil & R. Caruana, ICML 2005\n",
    "\n",
    "üî¨ [4] (1,2) [**‚ÄúProbabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods‚Äù**](https://home.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf). J. Platt, (1999)\n",
    "\n",
    "üî¨ [5] [**‚ÄúTransforming Classifier Scores into Accurate Multiclass Probability Estimates‚Äù**](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=04e10f745a7267453788a22f5150b5a32b2b3951). B. Zadrozny & C. Elkan, (KDD 2002)\n",
    "\n",
    "üî¨ [6] [**‚ÄúPredicting accurate probabilities with a ranking loss‚Äù**](https://icml.cc/2012/papers/372.pdf). Menon AK, Jiang XJ, Vembu S, Elkan C, Ohno-Machado L. Proc Int Conf Mach Learn. 2012;2012:703-710\n",
    "\n",
    "üî¨ [7] [**‚ÄúBeyond sigmoids: How to obtain well-calibrated probabilities from binary classifiers with beta calibration‚Äù**](https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-11/issue-2/Beyond-sigmoids--How-to-obtain-well-calibrated-probabilities-from/10.1214/17-EJS1338SI.pdf) Kull, M., Silva Filho, T. M., & Flach, P. (2017).\n",
    "\n",
    "üìö [8] Mario V. W√ºthrich, Michael Merz (2023). [**‚ÄúStatistical Foundations of Actuarial Learning and its Applications‚Äù**](https://link.springer.com/book/10.1007/978-3-031-12409-9) Springer Actuarial"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
